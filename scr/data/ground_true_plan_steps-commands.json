{
    "softwares": {
        "software": [
            {
                "id": "1",
                "name": "AAAI-DISIM-UnivAQ/DALI",
                "url": "https://raw.githubusercontent.com/AAAI-DISIM-UnivAQ/DALI/master/README.md",
                "n_plans": 2,
                "plan_nodes": [
                    {
                        "type": "Source",
                        "plan_step": [
                            "Step 1: To download and install SICStus Prolog (it is needed), follow the instructions at https://sicstus.sics.se/download4.html.",
                            "Step 2: Then, you can download DALI and test it by running an example DALI MAS"
                        ],
                        "commands": [
                            "",
                            "git clone https://github.com/AAAI-DISIM-UnivAQ/DALI.git \n cd DALI/Examples/advanced \n bash startmas.sh"
                        ],
                        "operating_system": ["Linux"]
                    },
                    {
                        "type": "Source",
                        "plan_step": [
                            "Step 1: To download and install SICStus Prolog (it is needed), follow the instructions at https://sicstus.sics.se/download4.html.",
                            "Step 2: Then, you can download DALI and test it by running an example DALI MAS",
                            "Step 3: Unzip the repository go to the folder DALI/Examples/basic, and test if DALI works by duble clicking startmas.bat file (this will launch an example DALI MAS)"
                        ],
                        "commands": [
                            "",
                            "",
                            ""
                        ],
                        "operating_system": ["Windows"]
                    }
                ],
                "readme_instructions": "",
                "skip_content": ""
            },
            {
                "id": "2",
                "name": "BingqingCheng/cace",
                "url": "https://raw.githubusercontent.com/BingqingCheng/cace/main/README.md",
                "n_plans": 1,
                "plan_nodes": [
                    {
                        "type": "Source",
                        "plan_step": [
                            "Step 1: Refer to the `setup.py` file for installation instructions."
                        ],
                        "commands": [
                            ""
                        ],
                        "operating_system": []
                    }
                ],
                "readme_instructions": "",
                "skip_content":"requirements Python 3.6 or higher, Numpy, ASE (Atomic Simulation environment), Pytorch, matscipy"
            },
            {
                "id": "3",
                "name": "MelosY/CAM",
                "url": "https://raw.githubusercontent.com/MelosY/CAM/main/README.md",
                "n_plans": 1,
                "plan_nodes": [
                    {
                        "type": "Source",
                        "plan_step": [
                            "Step 1: Setup",
                            "Step 2: Run. Train",
                            "Step 3: Run. Evaluation. Modify the script/eval_tiny.sh, change the ''path_to_pth'' to your own path, which is similar to eval_nano.sh and eval_base.sh"
                        ],
                        "commands": [
                            "bash \n conda create -n cam python=3.8 -y \n conda activate cam \n  pip install -r requirements.txt`",
                            "bash script/train.sh",
                            "bash script/eval_tiny.sh"
                        ],
                        "operating_system": []
                    }
                ],
                "readme_instructions": "",
                "skip_content": ""
            },
            {
                "id": "4",
                "name": "less-and-less-bugs/Trust_TELLER",
                "url": "https://raw.githubusercontent.com/less-and-less-bugs/Trust_TELLER/main/README.md",
                "n_plans": 1,
                "plan_nodes": [
                    {
                        "type": "Source",
                        "plan_step": [
                            "Step 1: Download the dataset folder from onedrive by [data.zip](https://portland-my.sharepoint.com/:u:/g/personal/liuhui3-c_my_cityu_edu_hk/EfApQlFP3PhFjUW4527STo0BALMdP16zs-HPMNgwQVFWsA?e=zoHlW2). Unzip this folder into the project  directory.  You can find four orginal datasets,  pre-processed datasets (i.e., val.jsonl, test.jsonl, train.jsonl in each dataset folder) and the files incuding questions and answers.", 
                            "Step 2: Place the OpenAI key into the file named api_key.txt."
                        ],
                        "commands": [
                            "",
                            "openai.api_key = ''"
                        ],
                        "operating_system": []
                    }
                ],
                "readme_instructions": "",
                "skip_content": ""
            },
            {
                "id": "5",
                "name": "utiasASRL/steam_icp",
                "url": "https://raw.githubusercontent.com/utiasASRL/steam_icp/master/README.md",
                "n_plans": 1,
                "plan_nodes": [
                    {
                        "type": "Container",
                        "plan_step": [
                            "Step 1: Clone this repository and its submodules.",
                            "Step 2: We use docker to install dependencies The recommended way to build the docker image is",
                            "Step 3: When starting a container, remember to mount the code, dataset, and output directories to proper locations in the container. An example command to start a docker container with the image is",
                            "Step 4: (Inside Container) Go to the root directory of this repository and build STEAM-ICP"
                        ],
                        "commands": [
                            "docker build -t steam_icp  \n --build-arg USERID=$(id -u) \n--build-arg GROUPID=$(id -g) \n--build-arg USERNAME=$(whoami) \n --build-arg HOMEDIR=${HOME}.",
                            "",
                            "",
                            "bash build.sh"
                        ],
                        "operating_system": []
                    }
                ],
                "readme_instructions": "",
                "skip_content": ""
            },
            {
                "id": "6",
                "name": "PFischbeck/parameter-fitting-experiments",
                "url": "https://raw.githubusercontent.com/PFischbeck/parameter-fitting-experiments/main/Readme.md",
                "n_plans": 2,
                "plan_nodes": [
                    {
                        "type": "Source",
                        "plan_step": [
                            "Step 1: Make sure you have Python, Pip and R installed.",
                            "Step 2: Checkout this repository.",
                            "Step 3: Install the python dependencies with.",
                            "Step 4: Install the pygirgs package at https://github.com/PFischbeck/pygirgs.",
                            "Step 5: Install the R dependencies (used for plots) with",
                            "Step 6: Download the file at https://doi.org/10.5281/zenodo.10629451 and extract the content",
                            "Step optional: Download the file output-data.zip from Zenodo and extract its contents into the folder output_data. This way, you can access all experiment results without running them yourself."
                        ],
                        "commands": [
                            "",
                            "",
                            "pip3 install -r requirements.txt",
                            "R -e 'install.packages(c(ggplot2", "reshape2", "plyr", "dplyr", "scales), repos=https://cloud.r-project.org/",
                            "pip3 install -r requirements.txt",
                            "",
                            ""
                        ],
                        "operating_system": []
                    }
                ],
                "readme_instructions": "",
                "skip_content": ""
            },
            {
                "id": "7",
                "name": "gabbypinto/GET-Tok-Peru",
                "url": "https://raw.githubusercontent.com/gabbypinto/GET-Tok-Peru/main/README.md",
                "n_plans": 1,
                "plan_nodes": [
                    {
                        "type": "Source",
                        "plan_step": [
                            "Step 1: pip install -r requirements."
                        ],
                        "commands": [
                            "pip install -r requirements.txt"
                        ],
                        "operating_system": []
                    }
                ],
                "readme_instructions": "",
                "skip_content": "`Note: I did not us a virtual environment so the packages in the requirements.txt file are probably not reflective of all the packages used in this project. If some issues pop up please don't hesitate to email me at"
            },
            {
                "id": "8",
                "name": "jonarriza96/gsft",
                "url": "https://raw.githubusercontent.com/jonarriza96/gsft/main/README.md",
                "n_plans": 1,
                "plan_nodes": [
                    {
                        "type": "Source",
                        "plan_step": [
                            "Step 1: Initialize git submodules.",
                            "Step 2: Install the specific versions of every package from `requirements.txt` in a new conda environment",
                            "Step 3: To ensure that Python paths are properly defined, update the `~/.bashrc` by adding the following lines"
                        ],
                        "commands": [
                            "git submodule init | git submodule update",
                            "conda create --name gsft python=3.9 | conda activate gsft | pip install -r requirements.txt",
                            "export GSFT_PATH=/path_to_gsfc | export PYTHONPATH=$PYTHONPATH:/$GSFT_PATH"
                        ],
                        "operating_system": []
                    }
                ],
                "readme_instructions": "",
                "skip_content": ""
            },
            {
                "id": "9",
                "name": "EricssonResearch/Line-Based-Room-Segmentation-and-EDF",
                "url": "https://raw.githubusercontent.com/EricssonResearch/Line-Based-Room-Segmentation-and-EDF/release/README.md",
                "n_plans": 1,
                "plan_nodes": [
                    {
                        "type": "Source",
                        "plan_step": [
                            "Step 1: The project can be installed by running the following command in your terminal."
                        ],
                        "commands": [
                            "pip install -r requirements.txt"
                        ],
                        "operating_system":[]
                    }
                ],
                "readme_instructions": "",
                "skip_content": ""
            },
            {
                "id": "10",
                "name": "viralInformatics/VIGA",
                "url": "https://raw.githubusercontent.com/viralInformatics/VIGA/master/README.md",
                "n_plans": 1,
                "plan_nodes": [
                    {
                        "type": "Source",
                        "plan_step": [
                            "Step 1: Download VIGA with Git from GitHub (or Download ZIP to local)",
                            "Step 2: Download taxdmp.zip [Index of /pub/taxonomy (nih.gov)](https://ftp.ncbi.nlm.nih.gov/pub/taxonomy/) and unzip taxdmp.zip and put it in ./db/.",
                            "Step 3: Download prot.accession2taxid file from https://ftp.ncbi.nlm.nih.gov/pub/taxonomy/accession2taxid/",
                            "Step 4: Download RefSeqVirusProtein file.",
                            "Step 5: Download nr file",
                            "Step 6: Use Diamond v2.0.11.149 to create two separate databases as the indexing libraries in the current version are incompatible with each other.",
                            "Step 7: In order to set up a reference database for DIAMOND, the `makedb` command needs to be executed with the following command line",
                            "Step 8: Installing Some Software Using Conda",
                            "Step 9: Python Dependencies"
                        ],
                        "commands": [
                            "git clone https://github.com/viralInformatics/VIGA.git",
                            "",
                            "",
                            "wget -c ftp.ncbi.nlm.nih.gov/refseq/release/viral/viral.1.protein.faa.gz | gzip -d viral.1.protein.faa.gz | mv viral.1.protein.faa RefSeqVirusProtein",
                            "wget -c ftp://ftp.ncbi.nlm.nih.gov/blast/db/FASTA/nr.gz -- or ascp -T  -i  asperaweb_id_dsa.openssh --host=ftp.ncbi.nih.gov --user=anonftp --mode=recv /blast/db/FASTA/nr.gz ./ -- gzip -d nr.gz",
                            "",
                            "diamond makedb --in YourPath/RefSeqVirusProtein  -d Diamond_RefSeqVirusProtein --taxonmap YourPath/prot.accession2taxid --taxonnodes YourPath/nodes.dmp | diamond makedb --in nr -d Dimond_nr --taxonmap YourPath/prot.accession2taxid --taxonnodes YourPath/nodes.dmp",
                            "conda install fastp=0.12.4 trinity=2.8.5 diamond=2.0.11.149 ragtag=2.1.0 quast=5.0.2",
                            "pip install pandas=1.1.5 numpy=1.19.5  matplotlib=3.3.4  biopython=1.79"
                        ],
                        "operating_system": []
                    }
                ],
                "readme_instructions": "",
                "skip_content": "rather looks substeps than steps"
            },
            {
                "id": "11",
                "name": "scimemia/NRN-EZ",
                "url": "https://raw.githubusercontent.com/scimemia/NRN-EZ/master/README.md",
                "n_plans": 3,
                "plan_nodes": [
                    {
                        "type": "Binary",
                        "plan_step": [
                            "Step 1: Installation instructions for Linux (Ubuntu and Pop!_OS): download the Linux zip file and, from the command window, run a bash command for the install.sh file, in the corresponding installation folder."
                        ],
                        "commands": [
                            ""
                        ],
                        "operating_system":["Linux"]
                    },
                    {
                        "type": "Binary",
                        "plan_step": [
                            "Step 1: Installation instructions for Mac OS: download the Mac zip file and copy the NRN-EZ app to the Applications folder."
                        ],
                        "commands": [
                            ""
                        ],
                        "operating_system":["Mac"]
                    },
                    {
                        "type": "Binary-Win",
                        "plan_step": [
                            "Step 1: Installation instructions for Windows: download the Win zip file and run the installation wizard."
                        ],
                        "commands": [
                            ""
                        ],
                        "operating_system": ["Windows"]
                    }
                ],
                "readme_instructions": "",
                "skip_content": "NRN-EZ was built with PyInstaller 3.6, and requires the following languages and libraries: Python 3.6.9 and higher (currently up to 3.10, PyQt 5.10.1, PyQtGraph 0.11.0"
            },
            {
                "id": "12",
                "name": "dyxstat/Reproduce_ViralCC",
                "url": "https://raw.githubusercontent.com/dyxstat/Reproduce_ViralCC/main/README.md",
                "n_plans": 1,
                "plan_nodes": [
                    {
                        "type": "Source",
                        "plan_step": [
                            "Step 1: Download and preprocess the raw data",
                            "Step 2: Assemble contigs and align processed Hi-C reads to contigs**",
                            "Step 3: Identify viral contigs from assembled contigs",
                            "Step 4: Run ViralCC",
                            "Step 5: Evaluation draft viral genomes using CheckV"
                        ],
                        "commands": [
                            "wget https://sra-downloadb.be-md.ncbi.nlm.nih.gov/sos2/sra-pub-run-13/ERR2282092/ERR2282092.1 \n wget https://sra-downloadb.be-md.ncbi.nlm.nih.gov/sos2/sra-pub-run-13/ERR2530126/ERR2530126.1 \n wget https://sra-downloadb.be-md.ncbi.nlm.nih.gov/sos2/sra-pub-run-13/ERR2530127/ERR2530127.1 \n fastq-dump --split-files --gzip ERR2282092.1 \n  fastq-dump --split-files --gzip ERR2530126.1 \n bbduk.sh  in1=ERR2282092.1_1.fastq.gz in2=ERR2282092.1_2.fastq.gz out1=COWSG1_AQ.fastq.gz out2=COWSG2_AQ.fastq.gz ref=/home1/yuxuandu/cmb/SOFTWARE/bbmap/resources/adapters.fa ktrim=r k=23 mink=11 hdist=1 minlen=50 tpe tbo \n bbduk.sh  in1=ERR2530126.1_1.fastq.gz in2=ERR2530126.1_2.fastq.gz out1=S3HIC1_AQ.fastq.gz out2=S3HIC2_AQ.fastq.gz ref=/home1/yuxuandu/cmb/SOFTWARE/bbmap/resources/adapters.fa ktrim=r k=23 mink=11 hdist=1 minlen=50 tpe tbo \n bbduk.sh  in1=ERR2530127.1_1.fastq.gz in2=ERR2530127.1_2.fastq.gz out1=M1HIC1_AQ.fastq.gz out2=M1HIC2_AQ.fastq.gz ref=/home1/yuxuandu/cmb/SOFTWARE/bbmap/resources/adapters.fa ktrim=r k=23 mink=11 hdist=1 minlen=50 tpe tbo \n bbduk.sh  in1=S3HIC1_AQ.fastq.gz in2=S3HIC2_AQ.fastq.gz out1=S3HIC1_CL.fastq.gz out2=S3HIC2_CL.fastq.gz trimq=10 qtrim=r ftm=5 minlen=50 \n bbduk.sh  in1=M1HIC1_AQ.fastq.gz in2=M1HIC2_AQ.fastq.gz out1=M1HIC1_CL.fastq.gz out2=M1HIC2_CL.fastq.gz trimq=10 qtrim=r ftm=5 minlen=50 \n bbduk.sh  in1=COWSG1_AQ.fastq.gz in2=COWSG2_AQ.fastq.gz out1=COWSG1_CL.fastq.gz out2=COWSG2_CL.fastq.gz trimq=10 qtrim=r ftm=5 minlen=50 \n bbduk.sh in1=S3HIC1_CL.fastq.gz in2=S3HIC2_CL.fastq.gz out1=S3HIC1_trim.fastq.gz out2=S3HIC2_trim.fastq.gz ftl=10 \n bbduk.sh in1=M1HIC1_CL.fastq.gz in2=M1HIC2_CL.fastq.gz out1=M1HIC1_trim.fastq.gz out2=M1HIC2_trim.fastq.gz ftl=10 \n clumpify.sh in1=S3HIC1_trim.fastq.gz in2=S3HIC2_trim.fastq.gz out1=S3HIC1_dedup.fastq.gz out2=S3HIC2_dedup.fastq.gz dedupe \n clumpify.sh in1=M1HIC1_trim.fastq.gz in2=M1HIC2_trim.fastq.gz out1=M1HIC1_dedup.fastq.gz out2=M1HIC2_dedup.fastq.gz dedupe \n cat S3HIC1_dedup.fastq.gz M1HIC1_dedup.fastq.gz > HIC1.fastq.gz \n cat S3HIC2_dedup.fastq.gz M1HIC2_dedup.fastq.gz > HIC2.fastq.gz",
                            "megahit -1 COWSG1_CL.fastq.gz -2 COWSG2_CL.fastq.gz -o COW_ASSEMBLY --min-contig-len 1000 --k-min 21 --k-max 141 --k-step 12 --merge-level 20,0.95 \n bwa index final.contigs.fa \n bwa mem -5SP final.contigs.fa HIC1.fastq.gz HIC2.fastq.gz > COW_MAP.sam \n samtools view -F 0x904 -bS COW_MAP.sam > COW_MAP_UNSORTED.bam \n samtools sort -n COW_MAP_UNSORTED.bam -o COW_MAP_SORTED.bam",
                            "perl removesmalls.pl 3000 final.contigs.fa > cow_3000.fa \n wrapper_phage_contigs_sorter_iPlant.pl -f cow_3000.fa --db 1 --wdir output_directory --ncpu 16 --data-dir /panfs/qcb-panasas/yuxuandu/virsorter-data \n Rscript find_viral_contig.R",
                            "python ./viralcc.py pipeline -v final.contigs.fa COW_MAP_SORTED.bam viral.txt out_cow",
                            "python concatenation.py -p out_cow/VIRAL_BIN -o viralCC_cow_bins.fa \n checkv end_to_end viralCC_cow_bins.fa output_checkv_viralcc_cow -t 16 -d /panfs/qcb-panasas/yuxuandu/checkv-db-v1.0"
                        ],
                        "operating_system": []
                    }
                ],
                "readme_instructions": "",
                "skip_content": "Note: NCBI may update its links for downloading the database. Please check the latest link at NCBI if you meet the download error."
            },
            {
                "id": "13",
                "name": "apple/ml-mgie",
                "url": "https://raw.githubusercontent.com/apple/ml-mgie/main/README.md",
                "n_plans": 1,
                "plan_nodes": [
                    {
                        "type": "Source",
                        "plan_step": [
                            "Step 1: Create conda environment.",
                            "Step 2: Activate environment",
                            "Step 3: Install dependencies.",
                            "Step 4: Git clone this repo",
                            "Step 5: Install the module",
                            "Step 6: Install other packages",
                            "Step 7: Go back to the folder directory",
                            "Step 8: Copy py script to the folder"
                        ],
                        "commands": [
                            "conda create -n mgie python=3.10 -y",
                            "conda activate mgie",
                            "conda update -n base -c defaults conda setuptools -y \n conda install -c conda-forge git git-lfs ffmpeg vim htop ninja gpustat -y \n conda clean -a -y \n pip install -U pip cmake cython==0.29.36 pydantic==1.10 numpy \n pip install -U gdown pydrive2 wget jupyter jupyterlab jupyterthemes ipython \n pip install -U sentencepiece transformers diffusers tokenizers datasets gradio==3.37 accelerate evaluate git+https://github.com/openai/CLIP.git \n pip install -U https://download.pytorch.org/whl/cu113/torch-1.12.0%2Bcu113-cp310-cp310-linux_x86_64.whl https://download.pytorch.org/whl/cu113/torchvision-0.13.0%2Bcu113-cp310-cp310-linux_x86_64.whl https://download.pytorch.org/whl/cu113/torchaudio-0.12.0%2Bcu113-cp310-cp310-linux_x86_64.whl \n pip install -U deepspeed",
                            "cd ml-mgie \n git submodule update --init --recursive \n cd LLaVA",
                            "pip install -e .",
                            "pip install -U https://download.pytorch.org/whl/cu113/torch-1.12.0%2Bcu113-cp310-cp310-linux_x86_64.whl https://download.pytorch.org/whl/cu113/torchvision-0.13.0%2Bcu113-cp310-cp310-linux_x86_64.whl https://download.pytorch.org/whl/cu113/torchaudio-0.12.0%2Bcu113-cp310-cp310-linux_x86_64.whl \n pip install -U ninja flash-attn==1.0.2 \n pip install -U pydrive2 gdown wget",
                            "cd ..",
                            "cp mgie_llava.py LLaVA/llava/model/llava.py \n cp mgie_train.py LLaVA/llava/train/train.py"
                        ],
                        "operating_system":[]
                    }
                ],
                "readme_instructions": "",
                "skip_content": "Put official LLaVA-7B in _ckpt/LLaVA-7B-v1 and download pre-trained ckpt (on IPr2Pr + MagicBrush) in _ckpt/mgie_7b"
            },
            {
                "id": "14",
                "name": "uclaml/SPIN",
                "url": "https://raw.githubusercontent.com/uclaml/SPIN/main/README.md",
                "n_plans": 1,
                "plan_nodes": [
                    {
                        "type": "Source",
                        "plan_step": [
                            "Step 1: Create a Python virtual environment with Conda.",
                            "Step 2: Install PyTorch `v2.1.0` with compatible cuda version, following instructions from [PyTorch Installation Page](https://pytorch.org/get-started/locally/). For example with cuda 11:",
                            "Step 3: Install the following Python dependencies to run the codes.",
                            "Step 4: Login to your huggingface account for downloading models"
                        ],
                        "commands": [
                            "conda create -n myenv python=3.10 \n conda activate myenv",
                            "pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu118",
                            "python -m pip install . \n python -m pip install flash-attn --no-build-isolation",
                            "huggingface-cli login --token ${your_access_token}"
                        ],
                        "operating_system": []
                    }
                ],
                "readme_instructions": "",
                "skip_content": ""
            },
            {
                "id": "15",
                "name": "ncbi/GeneGPT",
                "url": "https://raw.githubusercontent.com/ncbi/GeneGPT/main/README.md",
                "n_plans": 4,
                "plan_nodes": [
                    {
                        "type": "Source",
                        "plan_step": [
                            "Step 1: The code has been tested with Python 3.9.13. Please first install the required packages by",
                            "Step 2: You also need an OpenAI API key to run GeneGPT with Codex. Replace the placeholder with your key in `config.py`.",
                            "Step 3: After setting up the environment, one can run GeneGPT on GeneTuring by.",
                            "Step 4: To run GeneGPT-slim, simply use"
                        ],
                        "commands": [
                            "pip install -r requirements.txt",
                            "$ cat config.py \n API_KEY = 'YOUR_OPENAI_API_KEY",
                            "python main.py 111111",
                            "python main.py 001001"
                        ],
                        "operating_system": []
                    }
                ],
                "readme_instructions": "",
                "skip_content": "attention, rather than steps, they look substeps"
            },
            {
                "id": "16",
                "name": "arplaboratory/learning-to-fly",
                "url": "https://raw.githubusercontent.com/arplaboratory/learning-to-fly/master/README.MD",
                "n_plans": 4,
                "plan_nodes": [
                    {
                        "type": "Container",
                        "plan_step": [
                            "Step 1: We provide a pre-built Docker image with a simple web interface that can be executed using a single command (given that Docker is already installed on your machine):",
                            "Step 2: After the container is running, navigate to [https://0.0.0.0:8000](https://0.0.0.0:8000) and you should see something like (after starting the training): <https>",
                            "Step 3: Detect objects in the edited image.",
                            "Step 4: Generate a video based on object detection description."
                        ],
                        "commands": [
                            "docker run -it --rm -p 8000:8000 arpllab/learning_to_fly",
                            "cmd $ dash",
                            "wget ttxr.",
                            "pip clone ."
                        ],
                        "operating_system": ["Docker (isolated"]
                    },
                    {
                        "type": "Container",
                        "plan_step": [
                            "Step 1: Install Docker on your machine. Then move to the original directory `learning_to_fly` and build the Docker image.",
                            "Step 2: If desired you can also build the container for building the firmware",
                            "Step 3: After that you can run it",
                            "Step 4: Navigate to https://0.0.0.0:8000 with your browser, and you should see something like in the screenshot above (after starting the training).",
                            "Step 5: Navigate to https://0.0.0.0:6006 with your browser to investigate the Tensorboard logs.",
                            "Step 6: If you would like to benchmark the training speed you can use."
                        ],
                        "commands": [
                            "docker build -t arpllab/learning_to_fly",
                            "docker build -t arpllab/learning_to_fly_build_firmware -f Dockerfile_build_firmware .",
                            "docker run -it --rm -p 8000:8000 arpllab/learning_to_fly",
                            "docker run -it --rm -p 6006:6006 arpllab/learning_to_fly training_headless",
                            "docker run -it --rm arpllab/learning_to_fly training_benchmark"
                        ],
                        "operating_system":["Docker installation(isolated"]
                    },
                    {
                        "type": "Source",
                        "plan_step": [
                            "Step 1: Clone this repository.",
                            "Step 2: Then instantiate the `RLtools` submodule.",
                            "Step 3: Instantiate some dependencies of `RLtools'.",
                            "Step 4: Install dependencies on Ubuntu",
                            "Step 5: As an alternative to openblas you can also install [Intel MKL](https://www.intel.com/content/www/us/en/developer/tools/oneapi/onemkl-download.html) which in our experience is significantly faster than OpenBLAS.",
                            "Step 6: Going back to the main directory (learning_to_fly), we can now configure the build of the code",
                            "Step 7: Finally, we can build the targets.",
                            "Step 8: After successfully building the targets, we can run the code (in the original directory learning_to_fly).",
                            "Step 9: To run the training with the UI, we download the JavaScript dependencies in the form of the two files three.module.js and OrbitControls.js",
                            "Step 10: After that we can execute the UI binary from the root folder.",
                            "Step 11: To run the benchmark (with UI, checkpointing and Tensorboard logging turned off)"
                        ],
                        "commands": [
                            "git clone https://github.com/arplaboratory/learning-to-fly learning_to_fly \n cd learning_to_fly",
                            "git submodule update --init -- external/rl_tools \n cd external/rl_tools",
                            "git submodule update --init -- external/cli11 external/highfive external/json/ external/tensorboard tests/lib/googletest/",
                            "sudo apt update && sudo apt install libhdf5-dev libopenblas-dev protobuf-compiler libprotobuf-dev libboost-all-dev"
                        ],
                        "operating_system":["Linux"]
                    },
                    {
                        "type": "Source",
                        "plan_step": [
                            "Step 1: Clone this repository.",
                            "Step 2: Then instantiate the `RLtools` submodule.",
                            "Step 3: Instantiate some dependencies of `RLtools'.",
                            "Step 4: Install dependencies on macOS",
                            "Step 5: Please make sure that `brew` links the libraries correctly. If not you might have to link e.g. `protobuf` manually using `brew link protobuf`.",
                            "Step 6: Going back to the main directory (`learning_to_fly`), we can now configure the build of the code.",
                            "Step 7: Finally, we can build the targets",
                            "Step 8: After successfully building the targets, we can run the code (in the original directory learning_to_fly).",
                            "Step 9: To run the training with the UI, we download the JavaScript dependencies in the form of the two files three.module.js and OrbitControls.js",
                            "Step 10: After that we can execute the UI binary from the root folder.",
                            "Step 11: To run the benchmark (with UI, checkpointing and Tensorboard logging turned off)"
                        ],
                        "commands": [
                            "git clone https://github.com/arplaboratory/learning-to-fly learning_to_fly \n cd learning_to_fly",
                            "git submodule update --init -- external/rl_tools \n cd external/rl_tools",
                            "git submodule update --init -- external/cli11 external/highfive external/json/ external/tensorboard tests/lib/googletest/",
                            "sudo apt update && sudo apt install libhdf5-dev libopenblas-dev protobuf-compiler libprotobuf-dev libboost-all-dev",
                            "",
                            "brew install hdf5 protobuf boost",
                            "cd ../../ \n mkdir build \n cd build - Ubuntu + OpenBLAS: `cmake .. -DCMAKE_BUILD_TYPE=Release -DRL_TOOLS_BACKEND_ENABLE_OPENBLAS:BOOL=ON` \n - Ubuntu + MKL: `cmake .. -DCMAKE_BUILD_TYPE=Release -DRL_TOOLS_BACKEND_ENABLE_MKL:BOOL=ON` \n - macOS (tested on Sonoma): `cmake .. -DCMAKE_BUILD_TYPE=Release`",
                            "cmake --build . -j8",
                            "cd .. \n cd .."
                        ],
                        "operating_system":["Mac"]
                    }
                ],
                "readme_instructions": "",
                "skip_content": "This is the fastest configuration, without logging, UI, checkpointing etc. (refering to Contanier type)"
            },
            {
                "id": "17",
                "name": "LargeWorldModel/LWM",
                "url": "https://raw.githubusercontent.com/LargeWorldModel/LWM/main/README.md",
                "n_plans": 1,
                "plan_nodes": [
                    {
                        "type": "Source",
                        "plan_step": [
                            "Step 1: Install the requirements.",
                            "Step optional: or set up TPU VM."
                        ],
                        "commands": [
                            "conda create -n lwm python=3.10 \n pip install -U jax[cuda12_pip]==0.4.23 -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html \n pip install -r requirements.txt",
                            "sh tpu_vm_setup.sh"
                        ],
                        "operating_system": ["linux"]
                    }
                ],
                "readme_instructions": "",
                "skip_content": "This codebase is supported on Ubuntu and has not been tested on Windows or macOS. We recommend using TPUs for training and inference, although it is also possible to use GPUs. On TPU, the code is highly optimized with Jax's Pallas and can achieve high MFUs with RingAttention at very large context sizes. On GPU, the code is based on XLA and is not as optimized as it is for TPU."
            },
            {
                "id": "18",
                "name": "microsoft/UFO",
                "url": "https://raw.githubusercontent.com/microsoft/UFO/main/README.md",
                "n_plans": 1,
                "plan_nodes": [
                    {
                        "type": "Source",
                        "plan_step": [
                            "Step 1: Installation.",
                            "Step 1: Step 2: Configure the LLMs",
                            "Step 2: Install requirements."
                        ],
                        "commands": [
                            "conda create -n ufo python=3.10 \n # conda activate ufo",
                            "git clone https://github.com/microsoft/UFO.git \n cd UFO",
                            "pip install -r requirements.txt",
                            "API_TYPE: openai \n OPENAI_API_BASE: https://api.openai.com/v1/chat/completions # The base URL for the OpenAI API \n OPENAI_API_KEY: YOUR_API_KEY  # Set the value to the openai key for the llm model \n OPENAI_API_MODEL: GPTV_MODEL_NAME  # The only OpenAI model by now that accepts visual input",
                            "API_TYPE: aoai \n OPENAI_API_BASE: YOUR_ENDPOINT # The AOAI API address. Format: https://{your-resource-name}.openai.azure.com/openai/deployments/{deployment-id}/chat/completions?api-version={api-version} \n OPENAI_API_KEY: YOUR_API_KEY  # Set the value to the openai key for the llm model \n OPENAI_API_MODEL: GPTV_MODEL_NAME  # The only OpenAI model by now that accepts visual input",
                            "# assume you are in the cloned UFO folder \n python -m ufo --task <your_task_name>"
                        ],
                        "operating_system":["Windows"]
                    }
                ],
                "readme_instructions": "",
                "skip_content": "getting started, subsection Step1.Installation and subsection Step2.Configure TO CHECK"
            },
            {
                "id": "19",
                "name": "catid/dora",
                "url": "https://raw.githubusercontent.com/catid/dora/main/README.md",
                "n_plans": 1,
                "plan_nodes": [
                    {
                        "type": "Source",
                        "plan_step": [
                            "Step 1: Install conda: https://docs.conda.io/projects/miniconda/en/latest/index.html."
                        ],
                        "commands": [
                            "",
                            "git clone https://github.com/catid/dora.git \n cd dora",
                            "conda create -n dora python=3.10 -y && conda activate dora",
                            "pip install -U -r requirements.txt",
                            "pip clone .",
                            "python dora.py"
                        ],
                        "operating_system": []
                    }
                ],
                "readme_instructions": "",
                "type": "complex"
            },
            {
                "id": "20",
                "name": "YOLO-World",
                "url": "https://raw.githubusercontent.com/AILab-CVC/YOLO-World/master/README.md",
                "n_plans": 1,
                "plan_nodes": [
                    {
                        "type": "Source",
                        "plan_step": [
                            "Step 1: Clone the project.",
                            "Step 2: Install."
                        ],
                        "commands": [
                            "git clone --recursive https://github.com/AILab-CVC/YOLO-World.git",
                            "pip install torch wheel -q \n pip install -e ."
                        ],
                        "operating_system": []
                    }
                ],
                "readme_instructions": "",
                "skip_content": "Getting Started. 1. Installation subsection..."
            },
            {
                "id": "21",
                "name": "tensorflow",
                "url": "https://raw.githubusercontent.com/tensorflow/tensorflow/master/README.md",
                "n_plans": 3,
                "plan_nodes": [
                    {
                        "type": "PackageManager",
                        "plan_step": [
                            "Step 1: To install the current release, which includes support for [CUDA-enabled GPU cards](https://www.tensorflow.org/install/gpu) and (Ubuntu and Windows)",
                            "Step 2: To update TensorFlow to the latest version, add `--upgrade` flag to the above commands."
                        ],
                        "commands": [
                            "pip install tensorflow",
                            ""
                        ],
                        "operating_system": ["Windows", "Linux"]
                    },
                    {
                        "type": "PackageManager",
                        "plan_step": [
                            "Step 1: Other devices (DirectX and MacOS-metal) are supported using Device plugins."
                        ],
                        "commands": [
                            "pip install tensorflow",
                            ""
                        ],
                        "operating_system": ["Mac"]
                    },
                    {
                        "type": "Binary",
                        "plan_step": [
                            "Step 1: Nightly binaries are available for testing at https://pypi.python.org/pypi/tf-nightly \n https://pypi.python.org/pypi/tf-nightly-cpu packages on PyPi."
                        ],
                        "commands": [
                            ""
                        ]
                    }
                ],
                "readme_instructions": "",
                "skip_content": "confusing readme_instruction!! to check"
            },
            {
                "id": "22",
                "name": "transformers",
                "url": "https://raw.githubusercontent.com/huggingface/transformers/main/README.md",
                "n_plans": 3,
                "plan_nodes": [
                    {
                        "type": "PackageManager",
                        "plan_step": [
                            "Step 1: Create a virtual environment with the version of Python you're going to use and activate it.",
                            "Step 2: Then, you will need to install at least one of Flax, PyTorch, or TensorFlow. Please refer to [TensorFlow installation page](https://www.tensorflow.org/install/), [PyTorch installation page](https://pytorch.org/get-started/locally/#start-locally) and/or [Flax](https://github.com/google/flax#quick-install) and [Jax](https://github.com/google/jax#installation) installation pages regarding the specific installation command for your platform.",
                            "Step 3: When one of those backends has been installed, Transformers can be installed using pip as follows"
                        ],
                        "commands": [
                            "",
                            "",
                            "pip install transformers",
                            "conda install conda-forge::transformers"
                        ],
                        "operating_system": ["pip"]
                    },
                    {
                        "type": "PackageManager",
                        "plan_step": [
                            "Step 1: Create a virtual environment with the version of Python you're going to use and activate it.",
                            "Step 2: Then, you will need to install at least one of Flax, PyTorch, or TensorFlow. Please refer to [TensorFlow installation page](https://www.tensorflow.org/install/), [PyTorch installation page](https://pytorch.org/get-started/locally/#start-locally) and/or [Flax](https://github.com/google/flax#quick-install) and [Jax](https://github.com/google/jax#installation) installation pages regarding the specific installation command for your platform.",
                            "Step 3: Transformer can be installed using conda as follows."
                        ],
                        "commands": [
                            "",
                            "",
                            "pip install transformers",
                            "conda install conda-forge::transformers"
                        ],
                        "operating_system":["Conda"]
                    }
                ],
                "readme_instructions": "This repository is tested on Python 3.8+, Flax 0.4.1+, PyTorch 1.11+, and TensorFlow 2.6+. You should install Transformers in a virtual environment. If you're unfamiliar with Python virtual environments, check out the user guide.",
                "skip_content": "complex"
            },
            {
                "id": "23",
                "name": "divelab/DIG",
                "url": "https://raw.githubusercontent.com/divelab/DIG/dig-stable/README.md",
                "n_plans": 2,
                "plan_nodes": [
                    {
                        "type": "PackageManager",
                        "plan_step": [
                            "Step 1: Install [PyTorch](https://pytorch.org/get-started/locally/) (>=1.10.0).",
                            "Step 2: Install [PyG](https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html#) (>=2.0.0)",
                            "Step 3: Install DIG: Dive into Graphs.",
                            "Step 4: After installation, you can check the version. You have successfully installed DIG: Dive into Graphs if no error occurs."
                        ],
                        "commands": [
                            "python -c import torch; print(torch.__version__)",
                            "python -c import torch_geometric; print(torch_geometric.__version__)",
                            "pip install dive-into-graphs",
                            "python print(version)"
                        ],
                        "operating_system": ["pip"]
                    },
                    {
                        "type": "source",
                        "plan_step": [
                            "Step 1: If you want to try the latest features that have not been released yet, you can install dig from source."
                        ],
                        "commands": [
                            ""
                        ],
                        "operating_system": []
                    }
                ],
                "readme_instructions": "",
                "skip_content": "complex"
            },
            {
                "id": "24",
                "name": "langchain-ai/langchain",
                "url": "https://raw.githubusercontent.com/langchain-ai/langchain/master/README.md",
                "n_plans": 2,
                "plan_nodes": [
                    {
                        "type": "PackageManager",
                        "plan_step": [
                            "Step 1: With pip."
                        ],
                        "commands": [
                            "pip install langchain"
                        ],
                        "operating_system": ["pip"]
                    },
                    {
                        "type": "PackageManager",
                        "plan_step": [
                            "Step 1: With conda."
                        ],
                        "commands": [
                            "conda install langchain -c conda-forge"
                        ],
                        "operating_system": ["conda"]
                    }
                ],
                "readme_instructions": "",
                "skip_content": ""
            },
            {
                "id": "25",
                "name": "",
                "url": "https://gitlab.com/ungetym/blender-camera-generator/-/raw/main/README.md?ref_type=heads",
                "n_plans": 1,
                "plan_nodes": [
                    {
                        "type": "Source",
                        "plan_step": [
                            "Step 1: Copy the `CamGen_v2` folder into the Blender [add-on folder](https://docs.blender.org/manual/en/latest/advanced/blender_directory_layout.html#platform-dependent-paths) that is right for your operating system, e.g. for Blender 4.0 under Linux ~/.config/blender/4.0/scripts/addons/.",
                            "Step 2: Open Blender and navigate to `Edit > Preferences > Add-ons`.",
                            "Step 3: Find and activate `Generic: Camera_Generator_v2` the list of available Add-ons. You will need to press *refresh* in the Add-ons panel if you do not see the Camera_Generator option..",
                            "Step 4 [Optional]: To enable experimental lens analysis operations and plotting of the results, additional packages have to be installed for Blender's bundled Python version."
                        ],
                        "commands": [
                            "",
                            "",
                            "",
                            "$BLENDERPATH/$VERSION/python/bin/python3.10 -m pip install matplotlib PyQt5'"
                        ],
                        "operating_system": []
                    }
                ],
                "readme_instructions": "",
                "skip_content": "Requirements Blender 4.0 or higher (should work with previous versions, but was not tested)"
            },
            {
                "id": "26",
                "name": "facebookresearch/jepa",
                "url": "https://raw.githubusercontent.com/facebookresearch/jepa/main/README.md",
                "n_plans": 1,
                "plan_nodes": [
                    {
                        "type": "Source",
                        "plan_step": [
                            "Step 1: Run"
                        ],
                        "commands": [
                            "conda create -n jepa python=3.9 pip \n conda activate jepa \n python setup.py install`"
                        ],
                        "operating_system": []
                    }
                ],
                "readme_instructions": "",
                "skip_content": ""
            },
            {
                "id": "27",
                "name": "facebookresearch/DiT",
                "url": "https://raw.githubusercontent.com/facebookresearch/DiT/main/README.md",
                "n_plans": 1,
                "plan_nodes": [
                    {
                        "type": "Source",
                        "plan_step": [
                            "Step 1: First, download and set up the repo.",
                            "Step 2: We provide an [`environment.yml`](environment.yml) file that can be used to create a Conda environment. If you only want to run pre-trained models locally on CPU, you can remove the `cudatoolkit` and `pytorch-cuda` requirements from the file."
                        ],
                        "commands": [
                            "git clone https://github.com/facebookresearch/DiT.git \n cd DiT",
                            "conda env create -f environment.yml \n conda activate DiT"
                        ],
                        "operating_system": []
                    }
                ],
                "readme_instructions": "",
                "skip_content": ""
            },
            {
                "id": "28",
                "name": "ml-stat-Sustech/TorchCP",
                "url": "https://raw.githubusercontent.com/ml-stat-Sustech/TorchCP/master/README.md",
                "n_plans": 1,
                "plan_nodes": [
                    {
                        "type": "PackageManager",
                        "plan_step": [
                            "Step 1: TorchCP is developed with Python 3.9 and PyTorch 2.0.1. To install TorchCP, simply run.",
                            "Step 2: To install from TestPyPI server, run"
                        ],
                        "commands": [
                            "pip install torchcp",
                            "pip install --index-url https://test.pypi.org/simple/ --no-deps torchcp"
                        ],
                        "operating_system": []
                    }
                ],
                "readme_instructions": "",
                "skip_content": ""
            },
            {
                "id": "29",
                "name": "NUS-HPC-AI-Lab/Neural-Network-Diffusion",
                "url": "https://raw.githubusercontent.com/NUS-HPC-AI-Lab/Neural-Network-Diffusion/main/README.md",
                "n_plans": 1,
                "plan_nodes": [
                    {
                        "type": "Source",
                        "plan_step": [
                            "Step 1: Clone the repository.",
                            "Step 2: Create a new Conda environment and activate it.",
                            "Step 3: (optional): or install necessary package by"
                        ],
                        "commands": [
                            "git clone https://github.com/NUS-HPC-AI-Lab/Neural-Network-Diffusion.git",
                            "conda env create -f environment.yml \n conda activate DiT \n conda activate pdiff",
                            "pip install -r requirements.txt"
                        ],
                        "operating_system": []
                    }
                ],
                "readme_instructions": "",
                "skip_content": "yml and pip same plans?"
            },
            {
                "id": "30",
                "name": "sanjay-810/",
                "url": "https://raw.githubusercontent.com/sanjay-810/AYDIV2/main/README.md",
                "n_plans": 1,
                "plan_nodes": [
                    {
                        "type": "Container",
                        "plan_step": [
                            "Step 1: Prepare for the running environment. You can use the docker image provided by [`OpenPCDet`](https://github.com/open-mmlab/OpenPCDet)",
                            "Step 2: Please prepare dataset as [`OpenPCDet`](https://github.com/open-mmlab/OpenPCDet).",
                            "Step 3  Setup"
                        ],
                        "commands": [
                            "",
                            "cd Aydiv \n python depth_to_lidar.py",
                            "",
                            "cd Aydiv \n python setup.py develop \n cd pcdet/ops/iou3d/cuda_op \n python setup.py develop \n cd ../../../.."
                        ],
                        "operating_system":[]
                    }
                ],
                "readme_instructions": "",
                "skip_content": ""
            },
            {
                "id": "31",
                "name": "nand1155/CausNet",
                "url": "https://raw.githubusercontent.com/nand1155/CausNet/main/README.md",
                "n_plans": 1,
                "plan_nodes": [
                    {
                        "type": "Source",
                        "plan_step": [
                            "Step 1: You can install the development version from GitHub with."
                        ],
                        "commands": [
                            "`r require('devtools') \n install_github(`https://github.com/nand1155/CausNet`)"
                        ],
                        "operating_system":[]
                    }
                ],
                "readme_instructions":"",
                "skip_content": ""
            },
            {
                "id": "32",
                "name": "FasterDecoding/BitDelta",
                "url": "https://raw.githubusercontent.com/FasterDecoding/BitDelta/main/README.md",
                "n_plans": 1,
                "plan_nodes": [
                    {
                        "type": "Source",
                        "plan_step": [
                            "Step 1: Clone the repo and navigate to BitDelta:.",
                            "Step 2: Set up environment."
                        ],
                        "commands": [
                            "git clone https://github.com/FasterDecoding/BitDelta /n cd BitDelta",
                            "conda create -yn bitdelta python=3.9 \n conda activate bitdelta \n pip install -e ."
                        ],
                        "operating_system": []
                    }
                ],
                "readme_instructions": "",
                "skip_content": ""
            },
            {
                "id": "33",
                "name": "XueyangFeng/ReHAC",
                "url": "https://raw.githubusercontent.com/XueyangFeng/ReHAC/main/README.md",
                "n_plans": 1,
                "plan_nodes": [
                    {
                        "type": "Source",
                        "plan_step": [
                            "Step 1: You can use following scripts to install related python package through pip."
                        ],
                        "commands": [
                            "git clone https://github.com/XueyangFeng/ReHAC.git \n cd ReHAC \n pip install -r requirements.txt"
                        ],
                        "operating_system": []
                    }
                ],
                "readme_instructions":"",
                "skip_content": ""
            }
        ]
    }
}