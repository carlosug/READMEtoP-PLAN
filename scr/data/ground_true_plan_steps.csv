readme,text,plan,label
https://raw.githubusercontent.com/AAAI-DISIM-UnivAQ/DALI/master/README.md,## Installation,,
https://raw.githubusercontent.com/AAAI-DISIM-UnivAQ/DALI/master/README.md,**OS X & Linux:**,,
https://raw.githubusercontent.com/AAAI-DISIM-UnivAQ/DALI/master/README.md,"1.  To download and install SICStus Prolog (it is needed), follow the instructions at https://sicstus.sics.se/download4.html.",binary,step1
https://raw.githubusercontent.com/AAAI-DISIM-UnivAQ/DALI/master/README.md,"2.  Then, you can download DALI and",,step2
https://raw.githubusercontent.com/AAAI-DISIM-UnivAQ/DALI/master/README.md,test it by running an example DALI MAS:,,step3
https://raw.githubusercontent.com/AAAI-DISIM-UnivAQ/DALI/master/README.md,git clone https://github.com/AAAI-DISIM-UnivAQ/DALI.git,,step3.cmd1
https://raw.githubusercontent.com/AAAI-DISIM-UnivAQ/DALI/master/README.md,cd DALI/Examples/advanced,,step3.cmd2
https://raw.githubusercontent.com/AAAI-DISIM-UnivAQ/DALI/master/README.md,bash startmas.sh,,step3.cmd3
https://raw.githubusercontent.com/AAAI-DISIM-UnivAQ/DALI/master/README.md,"3.  Unzip the repository, go to the folder ""DALI/Examples/basic"", and test if DALI works by duble clicking ""startmas.bat"" file (this will launch an example DALI MAS)",,step4
https://raw.githubusercontent.com/cfeng783/GTT/main/README.md,#### Install dependencies (with python 3.10) ,source,step1
https://raw.githubusercontent.com/cfeng783/GTT/main/README.md,pip install -r requirements.txt,,step1.cmd1
https://raw.githubusercontent.com/cfeng783/GTT/main/README.md,#### Run the zero-shot experiments,,step2
https://raw.githubusercontent.com/cfeng783/GTT/main/README.md,cd src,,step2.cmd1
https://raw.githubusercontent.com/cfeng783/GTT/main/README.md,python test_zeroshot.py --gpu [GPUs] --batch_size [BS] --mode [mode] --data [DS] --uni [uni],,step2.cmd2
https://raw.githubusercontent.com/cfeng783/GTT/main/README.md,#### Run the fine-tune experiments,,step3
https://raw.githubusercontent.com/cfeng783/GTT/main/README.md,cd experiments,,step3.cmd1
https://raw.githubusercontent.com/cfeng783/GTT/main/README.md,python test_finetune.py --gpu [GPUs] --batch_size [BS] --mode [mode] --data [DS] --uni [uni] --epochs [eps],source,step3.cmd2
https://raw.githubusercontent.com/sanjay-810/AYDIV2/main/README.md,1.  Prepare for the running environment. ,,step4
https://raw.githubusercontent.com/sanjay-810/AYDIV2/main/README.md,    You can use the docker image provided by [`OpenPCDet`](https://github.com/open-mmlab/OpenPCDet). Our experiments are based on the docker provided by Voxel-R-CNN and we use NVIDIA Tesla V100 to train our Aydiv.,,step4.extra.info
https://raw.githubusercontent.com/sanjay-810/AYDIV2/main/README.md,2. Prepare for the data.,,step5
https://raw.githubusercontent.com/sanjay-810/AYDIV2/main/README.md,    Convert Argoverse 2 (or) waymo open Dataset into kitti format [`converter`](https://github.com/sanjay-810/AYDIV_ICRA/tree/main/data_converter/convert),,step5.substep1
https://raw.githubusercontent.com/sanjay-810/AYDIV2/main/README.md,    Please prepare dataset as [`OpenPCDet`](https://github.com/open-mmlab/OpenPCDet).  ,,step5.substep2
https://raw.githubusercontent.com/sanjay-810/AYDIV2/main/README.md,    To generate depth_pseudo_rgbseguv_twise by yourself with depth_dense_twise as follows:,,step5.substep3
https://raw.githubusercontent.com/sanjay-810/AYDIV2/main/README.md,    cd Aydiv,,step5.substep3.cmd1
https://raw.githubusercontent.com/sanjay-810/AYDIV2/main/README.md,    python depth_to_lidar.py,,step5.substep3.cmd2
https://raw.githubusercontent.com/sanjay-810/AYDIV2/main/README.md,"    If you want to generate dense depth maps by yourself, it is recommended to use [`TWISE`](https://github.com/imransai/TWISE). The dense depth maps we provide are generated by TWISE. Anyway, you should have your dataset as follows:",,step6.cmd3
https://raw.githubusercontent.com/BingqingCheng/cace/main/README.md,Please refer to the `setup.py` file for installation instructions.,source,step1
https://raw.githubusercontent.com/less-and-less-bugs/Trust_TELLER/main/README.md,## Getting Started,,
https://raw.githubusercontent.com/less-and-less-bugs/Trust_TELLER/main/README.md,"Step 1: Download the dataset folder from onedrive by [data.zip](https://portland-my.sharepoint.com/:u:/g/personal/liuhui3-c_my_cityu_edu_hk/EfApQlFP3PhFjUW4527STo0BALMdP16zs-HPMNgwQVFWsA?e=zoHlW2). Unzip this folder into the project  directory.  You can find four orginal datasets,  pre-processed datasets (i.e., val.jsonl, test.jsonl, train.jsonl in each dataset folder) and the files incuding questions and answers ",source,step1
https://raw.githubusercontent.com/less-and-less-bugs/Trust_TELLER/main/README.md,Step 2: Place you OpenAI key into the file named api_key.txt. ,,step2
https://raw.githubusercontent.com/less-and-less-bugs/Trust_TELLER/main/README.md,"openai.api_key = """"",,step2.cmd1
https://raw.githubusercontent.com/utiasASRL/steam_icp/master/README.md,## Installation,,
https://raw.githubusercontent.com/utiasASRL/steam_icp/master/README.md,Clone this repository and its submodules.,container,step1
https://raw.githubusercontent.com/utiasASRL/steam_icp/master/README.md,We use docker to install dependencies. The recommended way to build the docker image is,,step2
https://raw.githubusercontent.com/utiasASRL/steam_icp/master/README.md,docker build -t steam_icp \,,step2.cmd1
https://raw.githubusercontent.com/utiasASRL/steam_icp/master/README.md,  --build-arg USERID=$(id -u) \,,step2.cmd2
https://raw.githubusercontent.com/utiasASRL/steam_icp/master/README.md,  --build-arg GROUPID=$(id -g) \,,step2.cmd3
https://raw.githubusercontent.com/utiasASRL/steam_icp/master/README.md,  --build-arg USERNAME=$(whoami) \,,step2.cmd4
https://raw.githubusercontent.com/utiasASRL/steam_icp/master/README.md,  --build-arg HOMEDIR=${HOME} .,,step2.cmd5
https://raw.githubusercontent.com/utiasASRL/steam_icp/master/README.md,"When starting a container, remember to mount the code, dataset, and output directories to proper locations in the container.",,step3
https://raw.githubusercontent.com/utiasASRL/steam_icp/master/README.md,An example command to start a docker container with the image is,,
https://raw.githubusercontent.com/utiasASRL/steam_icp/master/README.md,docker run -it --name steam_icp \,,step3.cmd1
https://raw.githubusercontent.com/utiasASRL/steam_icp/master/README.md,  --privileged \,,step3.cmd2
https://raw.githubusercontent.com/utiasASRL/steam_icp/master/README.md,  --network=host \,,step3.cmd3
https://raw.githubusercontent.com/utiasASRL/steam_icp/master/README.md,  -e DISPLAY=$DISPLAY \,,step3.cmd4
https://raw.githubusercontent.com/utiasASRL/steam_icp/master/README.md,  -v /tmp/.X11-unix:/tmp/.X11-unix \,,step3.cmd5
https://raw.githubusercontent.com/utiasASRL/steam_icp/master/README.md,  -v ${HOME}:${HOME}:rw \,,step3.cmd6
https://raw.githubusercontent.com/utiasASRL/steam_icp/master/README.md,  steam_icp,,step3.cmd7
https://raw.githubusercontent.com/utiasASRL/steam_icp/master/README.md,(Inside Container) Go to the root directory of this repository and build STEAM-ICP,,step4
https://raw.githubusercontent.com/utiasASRL/steam_icp/master/README.md,bash build.sh,,step4.cmd1
https://raw.githubusercontent.com/PFischbeck/parameter-fitting-experiments/main/Readme.md,# Installation,,
https://raw.githubusercontent.com/PFischbeck/parameter-fitting-experiments/main/Readme.md,"- Make sure you have Python, Pip and R installed.",source,step1
https://raw.githubusercontent.com/PFischbeck/parameter-fitting-experiments/main/Readme.md,- Checkout this repository,,step2
https://raw.githubusercontent.com/PFischbeck/parameter-fitting-experiments/main/Readme.md,- Install the python dependencies with,,step4
https://raw.githubusercontent.com/PFischbeck/parameter-fitting-experiments/main/Readme.md,pip3 install -r requirements.txt,,step4.cmd1
https://raw.githubusercontent.com/PFischbeck/parameter-fitting-experiments/main/Readme.md,- Install the `pygirgs` package at https://github.com/PFischbeck/pygirgs,,step5
https://raw.githubusercontent.com/PFischbeck/parameter-fitting-experiments/main/Readme.md,- Install the R dependencies (used for plots) with,,step6
https://raw.githubusercontent.com/PFischbeck/parameter-fitting-experiments/main/Readme.md,"R -e 'install.packages(c(""ggplot2"", ""reshape2"", ""plyr"", ""dplyr"", ""scales""), repos=""https://cloud.r-project.org/"")'",,step6.cmd
https://raw.githubusercontent.com/PFischbeck/parameter-fitting-experiments/main/Readme.md,- Download the file `konect-data.zip` from [Zenodo](https://doi.org/10.5281/zenodo.10629451) and extract its contents into the folder `input_data/konect`,,step7
https://raw.githubusercontent.com/PFischbeck/parameter-fitting-experiments/main/Readme.md,"- Optional: Download the file `output-data.zip` from [Zenodo](https://doi.org/10.5281/zenodo.10629451) and extract its contents into the folder `output_data`. This way, you can access all experiment results without running them yourself.",binary,step1.planal
https://raw.githubusercontent.com/gabbypinto/GET-Tok-Peru/main/README.md,## Installation,,
https://raw.githubusercontent.com/gabbypinto/GET-Tok-Peru/main/README.md,pip install -r requirements.txt ,source,step1
https://raw.githubusercontent.com/jonarriza96/gsft/main/README.md,*Note: I did not us a virtual environment so the packages in the requirements.txt file are probably not reflective of all the packages used in this project. If some issues pop up please don't hesitate to email me at: gpinto@usc.edu*,,
https://raw.githubusercontent.com/jonarriza96/gsft/main/README.md,## Installation,,
https://raw.githubusercontent.com/jonarriza96/gsft/main/README.md,### Dependencies,,
https://raw.githubusercontent.com/jonarriza96/gsft/main/README.md,Initialize git submodules with,source,step1
https://raw.githubusercontent.com/jonarriza96/gsft/main/README.md,    git submodule init,,step1.cmd1
https://raw.githubusercontent.com/jonarriza96/gsft/main/README.md,    git submodule update,,step1.cmd2
https://raw.githubusercontent.com/jonarriza96/gsft/main/README.md,### Python environment,,
https://raw.githubusercontent.com/jonarriza96/gsft/main/README.md,Install the specific versions of every package from `requirements.txt` in a new conda environment:,,step2
https://raw.githubusercontent.com/jonarriza96/gsft/main/README.md,conda create --name gsft python=3.9,,step2.cmd1
https://raw.githubusercontent.com/jonarriza96/gsft/main/README.md,conda activate gsft,,step2.cmd2
https://raw.githubusercontent.com/jonarriza96/gsft/main/README.md,pip install -r requirements.txt,,step3.cmd3
https://raw.githubusercontent.com/jonarriza96/gsft/main/README.md,"To ensure that Python paths are properly defined, update the `~/.bashrc` by adding the following lines",,step4
https://raw.githubusercontent.com/jonarriza96/gsft/main/README.md,export GSFT_PATH=/path_to_gsfc,,step4.cmd1
https://raw.githubusercontent.com/jonarriza96/gsft/main/README.md,export PYTHONPATH=$PYTHONPATH:/$GSFT_PATH,,step4.cmd2
https://raw.githubusercontent.com/EricssonResearch/Line-Based-Room-Segmentation-and-EDF/release/README.md,## Installation,,
https://raw.githubusercontent.com/EricssonResearch/Line-Based-Room-Segmentation-and-EDF/release/README.md,The project can be installed by running the following command in your terminal:,source,step1
https://raw.githubusercontent.com/EricssonResearch/Line-Based-Room-Segmentation-and-EDF/release/README.md,pip install -r requirements.txt,,step1.cmd1
https://raw.githubusercontent.com/viralInformatics/VIGA/master/README.md,## Installation,,
https://raw.githubusercontent.com/viralInformatics/VIGA/master/README.md,### Step1: Download VIGA,,step1
https://raw.githubusercontent.com/viralInformatics/VIGA/master/README.md,Download VIGA with Git from GitHub,source,step1.plan1
https://raw.githubusercontent.com/viralInformatics/VIGA/master/README.md,git clone https://github.com/viralInformatics/VIGA.git,,step1.plan1.cmd
https://raw.githubusercontent.com/viralInformatics/VIGA/master/README.md,or Download ZIP to local,binary,step1.plan2
https://raw.githubusercontent.com/viralInformatics/VIGA/master/README.md,### Step 2: Download Database,,step2
https://raw.githubusercontent.com/viralInformatics/VIGA/master/README.md,1. download taxdmp.zip [Index of /pub/taxonomy (nih.gov)](https://ftp.ncbi.nlm.nih.gov/pub/taxonomy/) and unzip taxdmp.zip and put it in ./db/,,step2.substep1
https://raw.githubusercontent.com/viralInformatics/VIGA/master/README.md,"2. download ""prot.accession2taxid"" file from https://ftp.ncbi.nlm.nih.gov/pub/taxonomy/accession2taxid/",,step2.substep2
https://raw.githubusercontent.com/viralInformatics/VIGA/master/README.md,"3. download ""RefSeqVirusProtein"" file from",,step2.substep3
https://raw.githubusercontent.com/viralInformatics/VIGA/master/README.md,wget -c ftp.ncbi.nlm.nih.gov/refseq/release/viral/viral.1.protein.faa.gz,,step2.substep3.cmd1
https://raw.githubusercontent.com/viralInformatics/VIGA/master/README.md,gzip -d viral.1.protein.faa.gz,,step2.substep3.cmd2
https://raw.githubusercontent.com/viralInformatics/VIGA/master/README.md,mv viral.1.protein.faa RefSeqVirusProtein,,step2.substep3.cmd3
https://raw.githubusercontent.com/viralInformatics/VIGA/master/README.md,"4. download ""nr"" file from",,step2.substep4
https://raw.githubusercontent.com/viralInformatics/VIGA/master/README.md,wget -c ftp://ftp.ncbi.nlm.nih.gov/blast/db/FASTA/nr.gz,,step2.substep4.cmd1
https://raw.githubusercontent.com/viralInformatics/VIGA/master/README.md,or ascp -T  -i  asperaweb_id_dsa.openssh --host=ftp.ncbi.nih.gov --user=anonftp --mode=recv /blast/db/FASTA/nr.gz ./,,step2.substep4.cmd2
https://raw.githubusercontent.com/viralInformatics/VIGA/master/README.md,gzip -d nr.gz,,step2.substep4.cmd3
https://raw.githubusercontent.com/viralInformatics/VIGA/master/README.md,5. Use Diamond v2.0.11.149 to create two separate databases as the indexing libraries in the current version are incompatible with each other.,,step2.substep5
https://raw.githubusercontent.com/viralInformatics/VIGA/master/README.md,"6. In order to set up a reference database for DIAMOND, the makedb command needs to be executed with the following command line:",,step2.substep6
https://raw.githubusercontent.com/viralInformatics/VIGA/master/README.md,diamond makedb --in YourPath/RefSeqVirusProtein  -d Diamond_RefSeqVirusProtein --taxonmap YourPath/prot.accession2taxid --taxonnodes YourPath/nodes.dmp,,step2.substep6.cmd1
https://raw.githubusercontent.com/viralInformatics/VIGA/master/README.md,diamond makedb --in nr -d Dimond_nr --taxonmap YourPath/prot.accession2taxid --taxonnodes YourPath/nodes.dmp,,step2.substep6.cmd2
https://raw.githubusercontent.com/viralInformatics/VIGA/master/README.md,### Step 3: Installation of dependent software,,step3
https://raw.githubusercontent.com/viralInformatics/VIGA/master/README.md,#### Installing Some Software Using Conda,,step3.substep1
https://raw.githubusercontent.com/viralInformatics/VIGA/master/README.md,conda install fastp=0.12.4 trinity=2.8.5 diamond=2.0.11.149 ragtag=2.1.0 quast=5.0.2,,step3.substep1.cmd1
https://raw.githubusercontent.com/viralInformatics/VIGA/master/README.md,#### Manual Installation of MetaCompass,,extra.info
https://raw.githubusercontent.com/viralInformatics/VIGA/master/README.md,https://github.com/marbl/MetaCompass,,extra.info
https://raw.githubusercontent.com/viralInformatics/VIGA/master/README.md,### Step 4: Python Dependencies,,step4
https://raw.githubusercontent.com/viralInformatics/VIGA/master/README.md,Base on python 3.6.8,,step4.extra.info
https://raw.githubusercontent.com/viralInformatics/VIGA/master/README.md,pip install pandas=1.1.5 numpy=1.19.5  matplotlib=3.3.4  biopython=1.79,,step4.cmd1
https://raw.githubusercontent.com/scimemia/NRN-EZ/master/README.md,**INSTALLATION FOR VERSION 1.1.6**,,
https://raw.githubusercontent.com/scimemia/NRN-EZ/master/README.md,"NRN-EZ was built with PyInstaller 3.6, and requires the following languages and libraries:",,extra.info
https://raw.githubusercontent.com/scimemia/NRN-EZ/master/README.md,•       Python 3.6.9 and higher (currently up to 3.10),,extra.info
https://raw.githubusercontent.com/scimemia/NRN-EZ/master/README.md,•       PyQt 5.10.1,,extra.info
https://raw.githubusercontent.com/scimemia/NRN-EZ/master/README.md,•       PyQtGraph 0.11.0,,extra.info
https://raw.githubusercontent.com/scimemia/NRN-EZ/master/README.md,Installation instructions for Linux (Ubuntu and Pop!_OS): download the Linux zip file,binary,step1.OS1
https://raw.githubusercontent.com/scimemia/NRN-EZ/master/README.md,"from the command window, run a bash command for the install.sh file, in the corresponding installation folder. ",,step2.OS1
https://raw.githubusercontent.com/scimemia/NRN-EZ/master/README.md,Installation instructions for Mac OS: download the Mac zip file,,step1.OS2
https://raw.githubusercontent.com/scimemia/NRN-EZ/master/README.md,and copy the NRN-EZ app to the Applications folder. ,,step2.OS2
https://raw.githubusercontent.com/scimemia/NRN-EZ/master/README.md,Installation instructions for Windows: download the Win zip file and,,step1.OS3
https://raw.githubusercontent.com/scimemia/NRN-EZ/master/README.md,run the installation wizard.,,step2.OS3
https://raw.githubusercontent.com/nand1155/CausNet/main/README.md,## Installation,,
https://raw.githubusercontent.com/nand1155/CausNet/main/README.md,You can install the development version from GitHub with:,source,step1
https://raw.githubusercontent.com/nand1155/CausNet/main/README.md,"require(""devtools"")",,step1.cmd1
https://raw.githubusercontent.com/nand1155/CausNet/main/README.md,"install_github(""https://github.com/nand1155/CausNet"")",,step1.cmd2
https://raw.githubusercontent.com/dyxstat/Reproduce_ViralCC/main/README.md,**Step 1 Download and preprocess the raw data**,,step1
https://raw.githubusercontent.com/dyxstat/Reproduce_ViralCC/main/README.md,Note: NCBI may update its links for downloading the database. Please check the latest link at [NCBI](https://www.ncbi.nlm.nih.gov/) if you meet the download error.,,step1.extra.info
https://raw.githubusercontent.com/dyxstat/Reproduce_ViralCC/main/README.md,wget https://sra-downloadb.be-md.ncbi.nlm.nih.gov/sos2/sra-pub-run-13/ERR2282092/ERR2282092.1,,step1.cmd1
https://raw.githubusercontent.com/dyxstat/Reproduce_ViralCC/main/README.md,wget https://sra-downloadb.be-md.ncbi.nlm.nih.gov/sos2/sra-pub-run-13/ERR2530126/ERR2530126.1,,step1.cmd2
https://raw.githubusercontent.com/dyxstat/Reproduce_ViralCC/main/README.md,wget https://sra-downloadb.be-md.ncbi.nlm.nih.gov/sos2/sra-pub-run-13/ERR2530127/ERR2530127.1,,step1.cmd3
https://raw.githubusercontent.com/dyxstat/Reproduce_ViralCC/main/README.md,fastq-dump --split-files --gzip ERR2282092.1,,step1.cmd4
https://raw.githubusercontent.com/dyxstat/Reproduce_ViralCC/main/README.md,fastq-dump --split-files --gzip ERR2530126.1,,step1.cmd5
https://raw.githubusercontent.com/dyxstat/Reproduce_ViralCC/main/README.md,fastq-dump --split-files --gzip ERR2530127.1,,step1.cmd6
https://raw.githubusercontent.com/dyxstat/Reproduce_ViralCC/main/README.md,bbduk.sh  in1=ERR2282092.1_1.fastq.gz in2=ERR2282092.1_2.fastq.gz out1=COWSG1_AQ.fastq.gz out2=COWSG2_AQ.fastq.gz ref=/home1/yuxuandu/cmb/SOFTWARE/bbmap/resources/adapters.fa ktrim=r k=23 mink=11 hdist=1 minlen=50 tpe tbo,,step1.cmd7
https://raw.githubusercontent.com/dyxstat/Reproduce_ViralCC/main/README.md,bbduk.sh  in1=ERR2530126.1_1.fastq.gz in2=ERR2530126.1_2.fastq.gz out1=S3HIC1_AQ.fastq.gz out2=S3HIC2_AQ.fastq.gz ref=/home1/yuxuandu/cmb/SOFTWARE/bbmap/resources/adapters.fa ktrim=r k=23 mink=11 hdist=1 minlen=50 tpe tbo,,step1.cmd8
https://raw.githubusercontent.com/dyxstat/Reproduce_ViralCC/main/README.md,bbduk.sh  in1=ERR2530127.1_1.fastq.gz in2=ERR2530127.1_2.fastq.gz out1=M1HIC1_AQ.fastq.gz out2=M1HIC2_AQ.fastq.gz ref=/home1/yuxuandu/cmb/SOFTWARE/bbmap/resources/adapters.fa ktrim=r k=23 mink=11 hdist=1 minlen=50 tpe tbo,,step1.cmd9
https://raw.githubusercontent.com/dyxstat/Reproduce_ViralCC/main/README.md,bbduk.sh  in1=S3HIC1_AQ.fastq.gz in2=S3HIC2_AQ.fastq.gz out1=S3HIC1_CL.fastq.gz out2=S3HIC2_CL.fastq.gz trimq=10 qtrim=r ftm=5 minlen=50,,step1.cmd10
https://raw.githubusercontent.com/dyxstat/Reproduce_ViralCC/main/README.md,bbduk.sh  in1=M1HIC1_AQ.fastq.gz in2=M1HIC2_AQ.fastq.gz out1=M1HIC1_CL.fastq.gz out2=M1HIC2_CL.fastq.gz trimq=10 qtrim=r ftm=5 minlen=50,,step1.cmd11
https://raw.githubusercontent.com/dyxstat/Reproduce_ViralCC/main/README.md,bbduk.sh  in1=COWSG1_AQ.fastq.gz in2=COWSG2_AQ.fastq.gz out1=COWSG1_CL.fastq.gz out2=COWSG2_CL.fastq.gz trimq=10 qtrim=r ftm=5 minlen=50,,step1.cmd12
https://raw.githubusercontent.com/dyxstat/Reproduce_ViralCC/main/README.md,bbduk.sh in1=S3HIC1_CL.fastq.gz in2=S3HIC2_CL.fastq.gz out1=S3HIC1_trim.fastq.gz out2=S3HIC2_trim.fastq.gz ftl=10,,step1.cmd13
https://raw.githubusercontent.com/dyxstat/Reproduce_ViralCC/main/README.md,bbduk.sh in1=M1HIC1_CL.fastq.gz in2=M1HIC2_CL.fastq.gz out1=M1HIC1_trim.fastq.gz out2=M1HIC2_trim.fastq.gz ftl=10,,step1.cmd14
https://raw.githubusercontent.com/dyxstat/Reproduce_ViralCC/main/README.md,clumpify.sh in1=S3HIC1_trim.fastq.gz in2=S3HIC2_trim.fastq.gz out1=S3HIC1_dedup.fastq.gz out2=S3HIC2_dedup.fastq.gz dedupe,,step1.cmd15
https://raw.githubusercontent.com/dyxstat/Reproduce_ViralCC/main/README.md,clumpify.sh in1=M1HIC1_trim.fastq.gz in2=M1HIC2_trim.fastq.gz out1=M1HIC1_dedup.fastq.gz out2=M1HIC2_dedup.fastq.gz dedupe,,step1.cmd16
https://raw.githubusercontent.com/dyxstat/Reproduce_ViralCC/main/README.md,cat S3HIC1_dedup.fastq.gz M1HIC1_dedup.fastq.gz > HIC1.fastq.gz,,step1.cmd17
https://raw.githubusercontent.com/dyxstat/Reproduce_ViralCC/main/README.md,cat S3HIC2_dedup.fastq.gz M1HIC2_dedup.fastq.gz > HIC2.fastq.gz,,step1.cmd18
https://raw.githubusercontent.com/dyxstat/Reproduce_ViralCC/main/README.md,**Step 2: Assemble contigs and align processed Hi-C reads to contigs**,,step2
https://raw.githubusercontent.com/dyxstat/Reproduce_ViralCC/main/README.md,"megahit -1 COWSG1_CL.fastq.gz -2 COWSG2_CL.fastq.gz -o COW_ASSEMBLY --min-contig-len 1000 --k-min 21 --k-max 141 --k-step 12 --merge-level 20,0.95",,step2.cmd1
https://raw.githubusercontent.com/dyxstat/Reproduce_ViralCC/main/README.md,bwa index final.contigs.fa,,step2.cmd2
https://raw.githubusercontent.com/dyxstat/Reproduce_ViralCC/main/README.md,bwa mem -5SP final.contigs.fa HIC1.fastq.gz HIC2.fastq.gz > COW_MAP.sam,,step2.cmd3
https://raw.githubusercontent.com/dyxstat/Reproduce_ViralCC/main/README.md,samtools view -F 0x904 -bS COW_MAP.sam > COW_MAP_UNSORTED.bam,,step2.cmd4
https://raw.githubusercontent.com/dyxstat/Reproduce_ViralCC/main/README.md,samtools sort -n COW_MAP_UNSORTED.bam -o COW_MAP_SORTED.bam,,step2.cmd5
https://raw.githubusercontent.com/dyxstat/Reproduce_ViralCC/main/README.md,**Step3: Identify viral contigs from assembled contigs**,,step3
https://raw.githubusercontent.com/dyxstat/Reproduce_ViralCC/main/README.md,perl removesmalls.pl 3000 final.contigs.fa > cow_3000.fa,,step3.cmd1
https://raw.githubusercontent.com/dyxstat/Reproduce_ViralCC/main/README.md,wrapper_phage_contigs_sorter_iPlant.pl -f cow_3000.fa --db 1 --wdir output_directory --ncpu 16 --data-dir /panfs/qcb-panasas/yuxuandu/virsorter-data,,step3.cmd2
https://raw.githubusercontent.com/dyxstat/Reproduce_ViralCC/main/README.md,Rscript find_viral_contig.R,,step3.cmd3
https://raw.githubusercontent.com/dyxstat/Reproduce_ViralCC/main/README.md,**Step4: Run ViralCC**,,step4
https://raw.githubusercontent.com/dyxstat/Reproduce_ViralCC/main/README.md,python ./viralcc.py pipeline -v final.contigs.fa COW_MAP_SORTED.bam viral.txt out_cow,,step4.cmd1
https://raw.githubusercontent.com/dyxstat/Reproduce_ViralCC/main/README.md,**Step5: Evaluation draft viral genomes using CheckV**,,step5
https://raw.githubusercontent.com/dyxstat/Reproduce_ViralCC/main/README.md,python concatenation.py -p out_cow/VIRAL_BIN -o viralCC_cow_bins.fa,,step5.cmd1
https://raw.githubusercontent.com/dyxstat/Reproduce_ViralCC/main/README.md,checkv end_to_end viralCC_cow_bins.fa output_checkv_viralcc_cow -t 16 -d /panfs/qcb-panasas/yuxuandu/checkv-db-v1.0,,step5.cmd2
https://raw.githubusercontent.com/apple/ml-mgie/main/README.md,## Requirements,,step1
https://raw.githubusercontent.com/apple/ml-mgie/main/README.md,conda create -n mgie python=3.10 -y,,step1.cmd1
https://raw.githubusercontent.com/apple/ml-mgie/main/README.md,conda activate mgie,,step1.cmd2
https://raw.githubusercontent.com/apple/ml-mgie/main/README.md,conda update -n base -c defaults conda setuptools -y,,step1.cmd3
https://raw.githubusercontent.com/apple/ml-mgie/main/README.md,conda install -c conda-forge git git-lfs ffmpeg vim htop ninja gpustat -y,,step1.cmd4
https://raw.githubusercontent.com/apple/ml-mgie/main/README.md,conda clean -a -y,,step1.cmd5
https://raw.githubusercontent.com/apple/ml-mgie/main/README.md,pip install -U pip cmake cython==0.29.36 pydantic==1.10 numpy,,step1.cmd6
https://raw.githubusercontent.com/apple/ml-mgie/main/README.md,pip install -U gdown pydrive2 wget jupyter jupyterlab jupyterthemes ipython,,step1.cmd7
https://raw.githubusercontent.com/apple/ml-mgie/main/README.md,pip install -U sentencepiece transformers diffusers tokenizers datasets gradio==3.37 accelerate evaluate git+https://github.com/openai/CLIP.git,,step1.cmd8
https://raw.githubusercontent.com/apple/ml-mgie/main/README.md,pip install -U https://download.pytorch.org/whl/cu113/torch-1.12.0%2Bcu113-cp310-cp310-linux_x86_64.whl https://download.pytorch.org/whl/cu113/torchvision-0.13.0%2Bcu113-cp310-cp310-linux_x86_64.whl https://download.pytorch.org/whl/cu113/torchaudio-0.12.0%2Bcu113-cp310-cp310-linux_x86_64.whl,,step1.cmd9
https://raw.githubusercontent.com/apple/ml-mgie/main/README.md,pip install -U deepspeed,,step1.cmd10
https://raw.githubusercontent.com/apple/ml-mgie/main/README.md,# git clone this repo,,step1.cmd11
https://raw.githubusercontent.com/apple/ml-mgie/main/README.md,cd ml-mgie,,step1.cmd12
https://raw.githubusercontent.com/apple/ml-mgie/main/README.md,git submodule update --init --recursive,,step1.cmd13
https://raw.githubusercontent.com/apple/ml-mgie/main/README.md,cd LLaVA,,step1.cmd14
https://raw.githubusercontent.com/apple/ml-mgie/main/README.md,pip install -e .,,step1.cmd15
https://raw.githubusercontent.com/apple/ml-mgie/main/README.md,pip install -U https://download.pytorch.org/whl/cu113/torch-1.12.0%2Bcu113-cp310-cp310-linux_x86_64.whl https://download.pytorch.org/whl/cu113/torchvision-0.13.0%2Bcu113-cp310-cp310-linux_x86_64.whl https://download.pytorch.org/whl/cu113/torchaudio-0.12.0%2Bcu113-cp310-cp310-linux_x86_64.whl,,step1.cmd16
https://raw.githubusercontent.com/apple/ml-mgie/main/README.md,pip install -U ninja flash-attn==1.0.2,,step1.cmd17
https://raw.githubusercontent.com/apple/ml-mgie/main/README.md,pip install -U pydrive2 gdown wget,,step1.cmd18
https://raw.githubusercontent.com/apple/ml-mgie/main/README.md,cd ..,,step1.cmd19
https://raw.githubusercontent.com/apple/ml-mgie/main/README.md,cp mgie_llava.py LLaVA/llava/model/llava.py,,step1.cmd20
https://raw.githubusercontent.com/apple/ml-mgie/main/README.md,cp mgie_train.py LLaVA/llava/train/train.py,,step1.cmd21
https://raw.githubusercontent.com/uclaml/SPIN/main/README.md,## Setup,,
https://raw.githubusercontent.com/uclaml/SPIN/main/README.md,The following steps provide the necessary setup to run our codes.,,
https://raw.githubusercontent.com/uclaml/SPIN/main/README.md,1. Create a Python virtual environment with Conda:,source,step1
https://raw.githubusercontent.com/uclaml/SPIN/main/README.md,conda create -n myenv python=3.10,,step1.cmd1
https://raw.githubusercontent.com/uclaml/SPIN/main/README.md,conda activate myenv,,step1.cmd2
https://raw.githubusercontent.com/uclaml/SPIN/main/README.md,"2. Install PyTorch `v2.1.0` with compatible cuda version, following instructions from [PyTorch Installation Page](https://pytorch.org/get-started/locally/). For example with cuda 11:",,step2
https://raw.githubusercontent.com/uclaml/SPIN/main/README.md,pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu118,,step2.cmd1
https://raw.githubusercontent.com/uclaml/SPIN/main/README.md,3. Install the following Python dependencies to run the codes.,,step3
https://raw.githubusercontent.com/uclaml/SPIN/main/README.md,python -m pip install .,,step3.cmd1
https://raw.githubusercontent.com/uclaml/SPIN/main/README.md,python -m pip install flash-attn --no-build-isolation,,step3.cmd2
https://raw.githubusercontent.com/uclaml/SPIN/main/README.md,4. Login to your huggingface account for downloading models,,step4
https://raw.githubusercontent.com/uclaml/SPIN/main/README.md,"huggingface-cli login --token ""${your_access_token}""",,step4.cmd1
https://raw.githubusercontent.com/ncbi/GeneGPT/main/README.md,## Requirements,source,step1
https://raw.githubusercontent.com/ncbi/GeneGPT/main/README.md,The code has been tested with Python 3.9.13. Please first install the required packages by:,source,step1.extra.info
https://raw.githubusercontent.com/ncbi/GeneGPT/main/README.md,pip install -r requirements.txt,,step1.cmd1
https://raw.githubusercontent.com/ncbi/GeneGPT/main/README.md,# Instructions to run the code,,step2
https://raw.githubusercontent.com/ncbi/GeneGPT/main/README.md,You also need an OpenAI API key to run GeneGPT with Codex. Replace the placeholder with your key in `config.py`:,,step2.extra.info
https://raw.githubusercontent.com/ncbi/GeneGPT/main/README.md,$ cat config.py ,,step2.cmd1
https://raw.githubusercontent.com/ncbi/GeneGPT/main/README.md,API_KEY = 'YOUR_OPENAI_API_KEY,,step2.cmd2
https://raw.githubusercontent.com/arplaboratory/learning-to-fly/master/README.MD,### Docker (isolated),Container,step1.plan1
https://raw.githubusercontent.com/arplaboratory/learning-to-fly/master/README.MD,We provide a pre-built Docker image with a simple web interface that can be executed using a single command (given that Docker is already installed on your machine):,,step1.plan1.extra.info
https://raw.githubusercontent.com/arplaboratory/learning-to-fly/master/README.MD,docker run -it --rm -p 8000:8000 arpllab/learning_to_fly,,step1.plan1.cmd1
https://raw.githubusercontent.com/arplaboratory/learning-to-fly/master/README.MD,"After the container is running, navigate to [https://0.0.0.0:8000](https://0.0.0.0:8000) and you should see something like (after starting the training): <https>",,step2.plan1
https://raw.githubusercontent.com/arplaboratory/learning-to-fly/master/README.MD,"Note that to make this Docker image compatible with a broad range of CPUs, some optimizations have been turned off. For full speed we recommend a [Native installation](#Native-installation). ",,step2.plan1.extra.info
https://raw.githubusercontent.com/arplaboratory/learning-to-fly/master/README.MD,### Docker installation (isolated),Container,step1.plan2
https://raw.githubusercontent.com/arplaboratory/learning-to-fly/master/README.MD,With the following instructions you can also easily build the Docker image yourself. If you want to run the code on bare metal jump [Native installation](#Native-installation).,,step1.plan2.extra.info
https://raw.githubusercontent.com/arplaboratory/learning-to-fly/master/README.MD,"First, install Docker on your machine. Then move to the original directory `learning_to_fly` and build the Docker image:",,step1.plan2
https://raw.githubusercontent.com/arplaboratory/learning-to-fly/master/README.MD,docker build -t arpllab/learning_to_fly .,,step1.plan2.cmd1
https://raw.githubusercontent.com/arplaboratory/learning-to-fly/master/README.MD,If desired you can also build the container for building the firmware:,,step1.plan2.extra.info
https://raw.githubusercontent.com/arplaboratory/learning-to-fly/master/README.MD,docker build -t arpllab/learning_to_fly_build_firmware -f Dockerfile_build_firmware .,,step1.plan2.extra.info.cmd1
https://raw.githubusercontent.com/arplaboratory/learning-to-fly/master/README.MD,After that you can run it using e.g.:,,step2.plan2
https://raw.githubusercontent.com/arplaboratory/learning-to-fly/master/README.MD,docker run -it --rm -p 8000:8000 arpllab/learning_to_fly,,step2.plan2.cmd1
https://raw.githubusercontent.com/arplaboratory/learning-to-fly/master/README.MD,This will open the port `8000` for the UI of the training program and run it inside the container.,,step3.plan2.extra.info
https://raw.githubusercontent.com/arplaboratory/learning-to-fly/master/README.MD,"Navigate to [https://0.0.0.0:8000](https://0.0.0.0:8000) with your browser, and you should see something like in the screenshot above (after starting the training).",,step4.plan2.action1
https://raw.githubusercontent.com/arplaboratory/learning-to-fly/master/README.MD,The training UI configuration does not log data by default. If you want to inspect the training data run:,,step5.plan2.extra.info
https://raw.githubusercontent.com/arplaboratory/learning-to-fly/master/README.MD,docker run -it --rm -p 6006:6006 arpllab/learning_to_fly training_headless,,step5.plan2.cmd1
https://raw.githubusercontent.com/arplaboratory/learning-to-fly/master/README.MD,Navigate to [https://0.0.0.0:6006](https://0.0.0.0:6006) with your browser to investigate the Tensorboard logs.,,step6.plan2.extra.info
https://raw.githubusercontent.com/arplaboratory/learning-to-fly/master/README.MD,If you would like to benchmark the training speed you can use:,,step7.plan2
https://raw.githubusercontent.com/arplaboratory/learning-to-fly/master/README.MD,docker run -it --rm arpllab/learning_to_fly training_benchmark,,step7.plan2.cmd1
https://raw.githubusercontent.com/arplaboratory/learning-to-fly/master/README.MD,"This is the fastest configuration, without logging, UI, checkpointing etc.",,step8.plan2.extra.info
https://raw.githubusercontent.com/arplaboratory/learning-to-fly/master/README.MD,### Native installation,source,
https://raw.githubusercontent.com/arplaboratory/learning-to-fly/master/README.MD,Clone this repository:,source,step1.plan3
https://raw.githubusercontent.com/arplaboratory/learning-to-fly/master/README.MD,git clone https://github.com/arplaboratory/learning-to-fly learning_to_fly,,step1.plan3.cmd1
https://raw.githubusercontent.com/arplaboratory/learning-to-fly/master/README.MD,cd learning_to_fly,,step1.plan3.cmd2
https://raw.githubusercontent.com/arplaboratory/learning-to-fly/master/README.MD,Then instantiate the `RLtools` submodule:,,step2.plan3
https://raw.githubusercontent.com/arplaboratory/learning-to-fly/master/README.MD,git submodule update --init -- external/rl_tools,,step2.plan3.cmd1
https://raw.githubusercontent.com/arplaboratory/learning-to-fly/master/README.MD,cd external/rl_tools,,step2.plan3.cmd2
https://raw.githubusercontent.com/arplaboratory/learning-to-fly/master/README.MD,"Then instantiate some dependencies of `RLtools` (for conveniences like checkpointing, Tensorboard logging, testing, etc.):",,step3.plan3
https://raw.githubusercontent.com/arplaboratory/learning-to-fly/master/README.MD,git submodule update --init -- external/cli11 external/highfive external/json/ external/tensorboard tests/lib/googletest/,,step3.plan3.cmd1
https://raw.githubusercontent.com/arplaboratory/learning-to-fly/master/README.MD,#### Install dependencies on Ubuntu,,step4.plan3.OS1
https://raw.githubusercontent.com/arplaboratory/learning-to-fly/master/README.MD,sudo apt update && sudo apt install libhdf5-dev libopenblas-dev protobuf-compiler libprotobuf-dev libboost-all-dev,,step4.plan3.OS1.cmd1
https://raw.githubusercontent.com/arplaboratory/learning-to-fly/master/README.MD,As an alternative to openblas you can also install [Intel MKL](https://www.intel.com/content/www/us/en/developer/tools/oneapi/onemkl-download.html) which in our experience is significantly faster than OpenBLAS.,,step4.plan3.OS1.extra.info
https://raw.githubusercontent.com/arplaboratory/learning-to-fly/master/README.MD,#### Install dependencies on macOS,,step4.plan3.OS2
https://raw.githubusercontent.com/arplaboratory/learning-to-fly/master/README.MD,brew install hdf5 protobuf boost,,step4.plan3.OS2.cmd1
https://raw.githubusercontent.com/arplaboratory/learning-to-fly/master/README.MD,Please make sure that `brew` links the libraries correctly. If not you might have to link e.g. `protobuf` manually using `brew link protobuf`.,,step5.plan3.OS2.extra.info
https://raw.githubusercontent.com/arplaboratory/learning-to-fly/master/README.MD,"Going back to the main directory (`learning_to_fly`), we can now configure the build of the code:",,step6.plan3.OS2
https://raw.githubusercontent.com/arplaboratory/learning-to-fly/master/README.MD,cd ../../,,step6.plan3.OS2.cmd1
https://raw.githubusercontent.com/arplaboratory/learning-to-fly/master/README.MD,mkdir build,,step6.plan3.OS2.cmd2
https://raw.githubusercontent.com/arplaboratory/learning-to-fly/master/README.MD,cd build,,step6.plan3.OS2.cmd3
https://raw.githubusercontent.com/arplaboratory/learning-to-fly/master/README.MD,- Ubuntu + OpenBLAS: `cmake .. -DCMAKE_BUILD_TYPE=Release -DRL_TOOLS_BACKEND_ENABLE_OPENBLAS:BOOL=ON`,,step6.plan3.OS1.cmd4
https://raw.githubusercontent.com/arplaboratory/learning-to-fly/master/README.MD,- Ubuntu + MKL: `cmake .. -DCMAKE_BUILD_TYPE=Release -DRL_TOOLS_BACKEND_ENABLE_MKL:BOOL=ON`,,step6.plan3.OS1.cmd5
https://raw.githubusercontent.com/arplaboratory/learning-to-fly/master/README.MD,- macOS (tested on Sonoma): `cmake .. -DCMAKE_BUILD_TYPE=Release`,,step6.plan3.OS2.cmd4
https://raw.githubusercontent.com/arplaboratory/learning-to-fly/master/README.MD,"Finally, we can build the targets:",,step7.plan3.OS2
https://raw.githubusercontent.com/arplaboratory/learning-to-fly/master/README.MD,cmake --build . -j8,,step7.plan3.OS2.cmd1
https://raw.githubusercontent.com/arplaboratory/learning-to-fly/master/README.MD,"After successfully building the targets, we can run the code (in the original directory `learning_to_fly`):",,step8.plan3.OS2
https://raw.githubusercontent.com/arplaboratory/learning-to-fly/master/README.MD,cd ..,,step8.plan3.OS2.cmd1
https://raw.githubusercontent.com/arplaboratory/learning-to-fly/master/README.MD,./build/src/training_headless ,,step8.plan3.OS2.cmd1
https://raw.githubusercontent.com/LargeWorldModel/LWM/main/README.md,## Setup,,
https://raw.githubusercontent.com/LargeWorldModel/LWM/main/README.md,"This codebase is supported on Ubuntu and has not been tested on Windows or macOS. We recommend using TPUs for training and inference, although it is also possible to use GPUs. On TPU, the code is highly optimized with Jax's Pallas and can achieve high MFUs with RingAttention at very large context sizes. On GPU, the code is based on XLA and is not as optimized as it is for TPU.",,extra.info
https://raw.githubusercontent.com/LargeWorldModel/LWM/main/README.md,Install the requirements with:,,step1
https://raw.githubusercontent.com/LargeWorldModel/LWM/main/README.md,conda create -n lwm python=3.10,,step1.plan1.cmd1
https://raw.githubusercontent.com/LargeWorldModel/LWM/main/README.md,"pip install -U ""jax[cuda12_pip]==0.4.23"" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html",,step1.plan1.cmd2
https://raw.githubusercontent.com/LargeWorldModel/LWM/main/README.md,pip install -r requirements.txt,,step1.plan1.cmd3
https://raw.githubusercontent.com/LargeWorldModel/LWM/main/README.md,or set up TPU VM with:,,plan1.extra.info
https://raw.githubusercontent.com/LargeWorldModel/LWM/main/README.md,sh tpu_vm_setup.sh,,plan1.extra.info.cmd1
https://raw.githubusercontent.com/microsoft/UFO/main/README.md,### 🛠️ Step 1: Installation,source,step1
https://raw.githubusercontent.com/microsoft/UFO/main/README.md,UFO requires **Python >= 3.10** running on **Windows OS >= 10**. It can be installed by running the following command:,,step1.extra.info
https://raw.githubusercontent.com/microsoft/UFO/main/README.md,# [optional to create conda environment],,step1.cmd1
https://raw.githubusercontent.com/microsoft/UFO/main/README.md,# conda create -n ufo python=3.10,,step1.cmd2
https://raw.githubusercontent.com/microsoft/UFO/main/README.md,# conda activate ufo,,step1.cmd3
https://raw.githubusercontent.com/microsoft/UFO/main/README.md,# clone the repository,,step1.cmd4
https://raw.githubusercontent.com/microsoft/UFO/main/README.md,git clone https://github.com/microsoft/UFO.git,,step1.cmd5
https://raw.githubusercontent.com/microsoft/UFO/main/README.md,cd UFO,,step1.cmd6
https://raw.githubusercontent.com/microsoft/UFO/main/README.md,# install the requirements,,step1.cmd7
https://raw.githubusercontent.com/microsoft/UFO/main/README.md,pip install -r requirements.txt,,step1.cmd8
https://raw.githubusercontent.com/microsoft/UFO/main/README.md,### ⚙️ Step 2: Configure the LLMs,,step2
https://raw.githubusercontent.com/microsoft/UFO/main/README.md,"Before running UFO, you need to provide your LLM configurations. You can configure `ufo/config/config.yaml` file as follows. ",,step2.extra.info
https://raw.githubusercontent.com/microsoft/UFO/main/README.md,#### OpenAI,,step2.KEY1
https://raw.githubusercontent.com/microsoft/UFO/main/README.md,```,,
https://raw.githubusercontent.com/microsoft/UFO/main/README.md,"API_TYPE: ""openai"" ",,step2.KEY1.cmd1
https://raw.githubusercontent.com/microsoft/UFO/main/README.md,"OPENAI_API_BASE: ""https://api.openai.com/v1/chat/completions"" # The base URL for the OpenAI API",,step2.KEY1.cmd2
https://raw.githubusercontent.com/microsoft/UFO/main/README.md,"OPENAI_API_KEY: ""YOUR_API_KEY""  # Set the value to the openai key for the llm model",,step2.KEY1.cmd3
https://raw.githubusercontent.com/microsoft/UFO/main/README.md,"OPENAI_API_MODEL: ""GPTV_MODEL_NAME""  # The only OpenAI model by now that accepts visual input",,step2.KEY1.cmd4
https://raw.githubusercontent.com/microsoft/UFO/main/README.md,#### Azure OpenAI (AOAI),,step2.KEY2
https://raw.githubusercontent.com/microsoft/UFO/main/README.md,"API_TYPE: ""aoai"" ",,step2.KEY2.cmd1
https://raw.githubusercontent.com/microsoft/UFO/main/README.md,"OPENAI_API_BASE: ""YOUR_ENDPOINT"" # The AOAI API address. Format: https://{your-resource-name}.openai.azure.com/openai/deployments/{deployment-id}/chat/completions?api-version={api-version}",,step2.KEY2.cmd2
https://raw.githubusercontent.com/microsoft/UFO/main/README.md,"OPENAI_API_KEY: ""YOUR_API_KEY""  # Set the value to the openai key for the llm model",,step2.KEY2.cmd3
https://raw.githubusercontent.com/microsoft/UFO/main/README.md,"OPENAI_API_MODEL: ""GPTV_MODEL_NAME""  # The only OpenAI model by now that accepts visual input",,step2.KEY2.cmd4
https://raw.githubusercontent.com/microsoft/UFO/main/README.md,### 🎉 Step 3: Start UFO,,step3
https://raw.githubusercontent.com/microsoft/UFO/main/README.md,#### ⌨️ You can execute the following on your Windows command Line (CLI):,,step3.extra.info1
https://raw.githubusercontent.com/microsoft/UFO/main/README.md,# assume you are in the cloned UFO folder,,step3.extra.info2
https://raw.githubusercontent.com/microsoft/UFO/main/README.md,python -m ufo --task <your_task_name>,,step3.cmd1
https://raw.githubusercontent.com/microsoft/UFO/main/README.md,This will start the UFO process and you can interact with it through the command line interface. ,,step3.extra.info3
https://raw.githubusercontent.com/microsoft/UFO/main/README.md,"If everything goes well, you will see the following message:",,step3.extra.info4
https://raw.githubusercontent.com/microsoft/UFO/main/README.md,"Welcome to use UFO🛸, A UI-focused Agent for Windows OS Interaction. ",,step3.extra.info5
https://raw.githubusercontent.com/microsoft/UFO/main/README.md,Please enter your request to be completed🛸:,,step3.substep1
https://raw.githubusercontent.com/microsoft/UFO/main/README.md,#### ⚠️Reminder:  ####,,
https://raw.githubusercontent.com/microsoft/UFO/main/README.md,"- Before UFO executing your request, please make sure the targeted applications are active on the system.",,step3.extra.info6
https://raw.githubusercontent.com/microsoft/UFO/main/README.md,"- The GPT-V accepts screenshots of your desktop and application GUI as input. Please ensure that no sensitive or confidential information is visible or captured during the execution process. For further information, refer to [DISCLAIMER.md](./DISCLAIMER.md).",,step3.extra.info7
https://raw.githubusercontent.com/microsoft/UFO/main/README.md,###  Step 4 🎥: Execution Logs ,,step4
https://raw.githubusercontent.com/microsoft/UFO/main/README.md,You can find the screenshots taken and request & response logs in the following folder:./ufo/logs/<your_task_name>/,,step4.extra.info
https://raw.githubusercontent.com/catid/dora/main/README.md,## Demo,,
https://raw.githubusercontent.com/catid/dora/main/README.md,Install conda: https://docs.conda.io/projects/miniconda/en/latest/index.html,,step1
https://raw.githubusercontent.com/catid/dora/main/README.md,git clone https://github.com/catid/dora.git,,step1.cmd1
https://raw.githubusercontent.com/catid/dora/main/README.md,cd dora,,step1.cmd2
https://raw.githubusercontent.com/catid/dora/main/README.md,conda create -n dora python=3.10 -y && conda activate dora,,step1.cmd3
https://raw.githubusercontent.com/catid/dora/main/README.md,pip install -U -r requirements.txt,,step1.cmd4
https://raw.githubusercontent.com/catid/dora/main/README.md,python dora.py,,step1.cmd5
https://raw.githubusercontent.com/catid/dora/main/README.md,```,,
https://raw.githubusercontent.com/AILab-CVC/YOLO-World/master/README.md,### 1. Installation,,
https://raw.githubusercontent.com/AILab-CVC/YOLO-World/master/README.md,YOLO-World is developed based on `torch==1.11.0` `mmyolo==0.6.0` and `mmdetection==3.0.0`.,,extra.info
https://raw.githubusercontent.com/AILab-CVC/YOLO-World/master/README.md,#### Clone Project ,,step1
https://raw.githubusercontent.com/AILab-CVC/YOLO-World/master/README.md,git clone --recursive https://github.com/AILab-CVC/YOLO-World.git,,step1.cmd1
https://raw.githubusercontent.com/AILab-CVC/YOLO-World/master/README.md,#### Install,,step2
https://raw.githubusercontent.com/AILab-CVC/YOLO-World/master/README.md,pip install torch wheel -q,,step2.cmd1
https://raw.githubusercontent.com/AILab-CVC/YOLO-World/master/README.md,pip install -e .,,step2.cmd2
https://raw.githubusercontent.com/FasterDecoding/BitDelta/main/README.md,1. Clone the repo and,,step1
https://raw.githubusercontent.com/FasterDecoding/BitDelta/main/README.md, navigate to BitDelta:,,step2
https://raw.githubusercontent.com/FasterDecoding/BitDelta/main/README.md,git clone https://github.com/FasterDecoding/BitDelta,,step1.cmd1
https://raw.githubusercontent.com/FasterDecoding/BitDelta/main/README.md,cd BitDelta,,step2.cmd1
https://raw.githubusercontent.com/FasterDecoding/BitDelta/main/README.md,2. Set up environment:,,step3
https://raw.githubusercontent.com/FasterDecoding/BitDelta/main/README.md,conda create -yn bitdelta python=3.9,,step3.cmd1
https://raw.githubusercontent.com/FasterDecoding/BitDelta/main/README.md,conda activate bitdelta,,step3.cmd2
https://raw.githubusercontent.com/FasterDecoding/BitDelta/main/README.md,pip install -e .,,step3.cmd3
https://raw.githubusercontent.com/tensorflow/tensorflow/master/README.md,## Install,,step1
https://raw.githubusercontent.com/tensorflow/tensorflow/master/README.md,See the [TensorFlow install guide](https://www.tensorflow.org/install) for the [pip package](https://www.tensorflow.org/install/pip),,extra.info
https://raw.githubusercontent.com/tensorflow/tensorflow/master/README.md,[Docker container](https://www.tensorflow.org/install/docker) ,,step1.plan1
https://raw.githubusercontent.com/tensorflow/tensorflow/master/README.md,[build from source](https://www.tensorflow.org/install/source),,step1.plan2
https://raw.githubusercontent.com/tensorflow/tensorflow/master/README.md,"To install the current release, which includes support for [CUDA-enabled GPU cards](https://www.tensorflow.org/install/gpu) and (Ubuntu and Windows)",,step2
https://raw.githubusercontent.com/tensorflow/tensorflow/master/README.md,$ pip install tensorflow,,step1.plan3
https://raw.githubusercontent.com/tensorflow/tensorflow/master/README.md,A smaller CPU-only package is also available:,,extra.info1
https://raw.githubusercontent.com/tensorflow/tensorflow/master/README.md,$ pip install tensorflow-cpu,,extra.info1.cmd
https://raw.githubusercontent.com/tensorflow/tensorflow/master/README.md,"To update TensorFlow to the latest version, add `--upgrade` flag to the above commands",,extra.info2
https://raw.githubusercontent.com/tensorflow/tensorflow/master/README.md,*Nightly binaries are available for testing using the,,step1.plan3
https://raw.githubusercontent.com/tensorflow/tensorflow/master/README.md,[tf-nightly](https://pypi.python.org/pypi/tf-nightly) and,,step1.plan3.extra.info1
https://raw.githubusercontent.com/tensorflow/tensorflow/master/README.md,[tf-nightly-cpu](https://pypi.python.org/pypi/tf-nightly-cpu) packages on PyPi.*,,step1.plan3.extra.info2
https://raw.githubusercontent.com/huggingface/transformers/main/README.md,## Installation,,step1
https://raw.githubusercontent.com/huggingface/transformers/main/README.md,### With pip,,step1.plan1.PM1
https://raw.githubusercontent.com/huggingface/transformers/main/README.md,"This repository is tested on Python 3.8+, Flax 0.4.1+, PyTorch 1.11+, and TensorFlow 2.6+.",,step1.plan1.PM1.extra.info1
https://raw.githubusercontent.com/huggingface/transformers/main/README.md,"You should install 🤗 Transformers in a [virtual environment](https://docs.python.org/3/library/venv.html). If you're unfamiliar with Python virtual environments, check out the [user guide](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/).",,step1.plan1.PM1.extra.info2
https://raw.githubusercontent.com/huggingface/transformers/main/README.md,"First, create a virtual environment with the version of Python you're going to use and activate it.",,step1.plan1.PM1
https://raw.githubusercontent.com/huggingface/transformers/main/README.md,"Then, you will need to install at least one of Flax, PyTorch, or TensorFlow.",,step2.plan1.PM1
https://raw.githubusercontent.com/huggingface/transformers/main/README.md,"Please refer to [TensorFlow installation page](https://www.tensorflow.org/install/), [PyTorch installation page](https://pytorch.org/get-started/locally/#start-locally) and/or [Flax](https://github.com/google/flax#quick-install) and [Jax](https://github.com/google/jax#installation) installation pages regarding the specific installation command for your platform.",,step2.plan1.PM1extra.info1
https://raw.githubusercontent.com/huggingface/transformers/main/README.md,"When one of those backends has been installed, 🤗 Transformers can be installed using pip as follows:",,step3
https://raw.githubusercontent.com/huggingface/transformers/main/README.md,```bash,,
https://raw.githubusercontent.com/huggingface/transformers/main/README.md,pip install transformers,,step3.cmd1
https://raw.githubusercontent.com/huggingface/transformers/main/README.md,"If you'd like to play with the examples or need the bleeding edge of the code and can't wait for a new release, you must [install the library from source](https://huggingface.co/docs/transformers/installation#installing-from-source).",,step3.extra.info
https://raw.githubusercontent.com/huggingface/transformers/main/README.md,### With conda,,step1.plan1.PM2
https://raw.githubusercontent.com/huggingface/transformers/main/README.md,🤗 Transformers can be installed using conda as follows:,,step1.plan1.PM2.extra.info
https://raw.githubusercontent.com/huggingface/transformers/main/README.md,conda install conda-forge::transformers,,step1.plan1.PM2.cmd
https://raw.githubusercontent.com/huggingface/transformers/main/README.md,> **_NOTE:_** Installing `transformers` from the `huggingface` channel is deprecated.,,extra.info
https://raw.githubusercontent.com/huggingface/transformers/main/README.md,"Follow the installation pages of Flax, PyTorch or TensorFlow to see how to install them with conda.",,extra.info
https://raw.githubusercontent.com/huggingface/transformers/main/README.md,"> **_NOTE:_**  On Windows, you may be prompted to activate Developer Mode in order to benefit from caching. If this is not an option for you, please let us know in [this issue](https://github.com/huggingface/huggingface_hub/issues/1062).",,extra.info
https://raw.githubusercontent.com/divelab/DIG/dig-stable/README.md,## Installation,,
https://raw.githubusercontent.com/divelab/DIG/dig-stable/README.md,### Install from pip,,plan1
https://raw.githubusercontent.com/divelab/DIG/dig-stable/README.md,"The key dependencies of DIG: Dive into Graphs are PyTorch (>=1.10.0), PyTorch Geometric (>=2.0.0), and RDKit.",,extra.info
https://raw.githubusercontent.com/divelab/DIG/dig-stable/README.md,1. Install [PyTorch](https://pytorch.org/get-started/locally/) (>=1.10.0),,step1.plan1
https://raw.githubusercontent.com/divelab/DIG/dig-stable/README.md,"$ python -c ""import torch; print(torch.__version__)""",,step1.cmd1
https://raw.githubusercontent.com/divelab/DIG/dig-stable/README.md,2. Install [PyG](https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html#) (>=2.0.0),,step2.plan1
https://raw.githubusercontent.com/divelab/DIG/dig-stable/README.md,"$ python -c ""import torch_geometric; print(torch_geometric.__version__)""",,step2.cmd1
https://raw.githubusercontent.com/divelab/DIG/dig-stable/README.md,3. Install DIG: Dive into Graphs.,,step3.plan1
https://raw.githubusercontent.com/divelab/DIG/dig-stable/README.md,pip install dive-into-graphs,,step3.cmd1
https://gitlab.com/ungetym/blender-camera-generator/-/raw/main/README.md?ref_type=heads,### Installation,,
https://gitlab.com/ungetym/blender-camera-generator/-/raw/main/README.md?ref_type=heads,"1. Copy the `CamGen_v2` folder into the Blender [add-on folder](https://docs.blender.org/manual/en/latest/advanced/blender_directory_layout.html#platform-dependent-paths) that is right for your operating system, e.g. for Blender 4.0 under Linux ~/.config/blender/4.0/scripts/addons/",,
https://gitlab.com/ungetym/blender-camera-generator/-/raw/main/README.md?ref_type=heads,2. Open Blender and navigate to `Edit > Preferences > Add-ons`,,
https://gitlab.com/ungetym/blender-camera-generator/-/raw/main/README.md?ref_type=heads,3. Find and activate `Generic: Camera_Generator_v2` the list of available Add-ons. **You will need to press *refresh* in the Add-ons panel if you do not see the Camera_Generator option.**,,
https://gitlab.com/ungetym/blender-camera-generator/-/raw/main/README.md?ref_type=heads,"4. [Optional] To enable experimental lens analysis operations and plotting of the results, additional packages have to be installed for Blender's bundled Python version.",,
https://gitlab.com/ungetym/blender-camera-generator/-/raw/main/README.md?ref_type=heads,   '`$BLENDERPATH/$VERSION/python/bin/python3.10 -m pip install matplotlib PyQt5`',,
https://raw.githubusercontent.com/facebookresearch/jepa/main/README.md,### Setup,,
https://raw.githubusercontent.com/facebookresearch/jepa/main/README.md,"Create a new Conda environment, activate it, and run the [setup.py](setup.py) script:",,
https://raw.githubusercontent.com/facebookresearch/jepa/main/README.md,`python setup.py install`,,
https://raw.githubusercontent.com/facebookresearch/DiT/main/README.md,## Setup,,
https://raw.githubusercontent.com/facebookresearch/DiT/main/README.md,,,
https://raw.githubusercontent.com/facebookresearch/DiT/main/README.md,"First, download and set up the repo:",,
https://raw.githubusercontent.com/facebookresearch/DiT/main/README.md,git clone https://github.com/facebookresearch/DiT.git,,
https://raw.githubusercontent.com/facebookresearch/DiT/main/README.md,cd DiT,,
https://raw.githubusercontent.com/facebookresearch/DiT/main/README.md,We provide an [`environment.yml`](environment.yml) file that can be used to create a Conda environment. If you only want ,,
https://raw.githubusercontent.com/facebookresearch/DiT/main/README.md,"to run pre-trained models locally on CPU, you can remove the `cudatoolkit` and `pytorch-cuda` requirements from the file.",,
https://raw.githubusercontent.com/facebookresearch/DiT/main/README.md,conda env create -f environment.yml,,
https://raw.githubusercontent.com/facebookresearch/DiT/main/README.md,conda activate DiT,,
https://raw.githubusercontent.com/XueyangFeng/ReHAC/main/README.md,## Usage,,
https://raw.githubusercontent.com/XueyangFeng/ReHAC/main/README.md,### Getting Start,,
https://raw.githubusercontent.com/XueyangFeng/ReHAC/main/README.md,You can use following scripts to install related python package through pip:,,
https://raw.githubusercontent.com/XueyangFeng/ReHAC/main/README.md,```,,
https://raw.githubusercontent.com/XueyangFeng/ReHAC/main/README.md,git clone https://github.com/XueyangFeng/ReHAC.git,,
https://raw.githubusercontent.com/XueyangFeng/ReHAC/main/README.md,cd ReHAC,,
https://raw.githubusercontent.com/XueyangFeng/ReHAC/main/README.md,pip install -r requirements.txt,,
https://raw.githubusercontent.com/langchain-ai/langchain/master/README.md,# Quick Install,,
https://raw.githubusercontent.com/langchain-ai/langchain/master/README.md,With pip:,,
https://raw.githubusercontent.com/langchain-ai/langchain/master/README.md,pip install langchain,,
https://raw.githubusercontent.com/langchain-ai/langchain/master/README.md,With conda:,,
https://raw.githubusercontent.com/langchain-ai/langchain/master/README.md,conda install langchain -c conda-forge,,
https://raw.githubusercontent.com/ml-stat-Sustech/TorchCP/master/README.md,## Installation,,
https://raw.githubusercontent.com/ml-stat-Sustech/TorchCP/master/README.md,"TorchCP is developed with Python 3.9 and PyTorch 2.0.1. To install TorchCP, simply run",,
https://raw.githubusercontent.com/ml-stat-Sustech/TorchCP/master/README.md,pip install torchcp,,
https://raw.githubusercontent.com/ml-stat-Sustech/TorchCP/master/README.md,"To install from TestPyPI server, run",,
https://raw.githubusercontent.com/ml-stat-Sustech/TorchCP/master/README.md,pip install --index-url https://test.pypi.org/simple/ --no-deps torchcp,,
https://raw.githubusercontent.com/NUS-HPC-AI-Lab/Neural-Network-Diffusion/main/README.md,## Installation,,
https://raw.githubusercontent.com/NUS-HPC-AI-Lab/Neural-Network-Diffusion/main/README.md,1. Clone the repository:,,
https://raw.githubusercontent.com/NUS-HPC-AI-Lab/Neural-Network-Diffusion/main/README.md,git clone https://github.com/NUS-HPC-AI-Lab/Neural-Network-Diffusion.git,,
https://raw.githubusercontent.com/NUS-HPC-AI-Lab/Neural-Network-Diffusion/main/README.md,2. Create a new Conda environment and activate it: ,,
https://raw.githubusercontent.com/NUS-HPC-AI-Lab/Neural-Network-Diffusion/main/README.md,conda env create -f environment.yaml,,
https://raw.githubusercontent.com/NUS-HPC-AI-Lab/Neural-Network-Diffusion/main/README.md,conda activate pdiff,,
https://raw.githubusercontent.com/NUS-HPC-AI-Lab/Neural-Network-Diffusion/main/README.md,or install necessary package by:,,
https://raw.githubusercontent.com/NUS-HPC-AI-Lab/Neural-Network-Diffusion/main/README.md,pip install -r requirement.txt,,