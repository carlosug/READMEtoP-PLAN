{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python notebook is designed to:\n",
    "# 1. Create a list of GitHub repositories from the awesome list found in the README.md file at https://github.com/jamesmurdza/awesome-ai-devtools\n",
    "# 2. For each GitHub repository in the list, read the README file and extract the installation instructions (e.g., sections titled \"How to install\", code blocks containing \"pip install\", \"git clone .git\", etc.)\n",
    "# 3. Generate a JSON-LD file with the following fields for each repository:\n",
    "#    - field1: URL (the GitHub link of the repository)\n",
    "#    - field2: Text (the extracted installation instructions)\n",
    "#    - field3: Tokens (the individual tokens of the text in field2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "from rdflib import Graph, Literal, RDF, URIRef\n",
    "from rdflib.namespace import FOAF, XSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://github.com/silvanmelchior/IncognitoPilot', 'https://github.com/features/preview', 'https://github.com/smallcloudai/refact', 'https://github.com/codota/TabNine', 'https://github.com/rubberduck-ai/rubberduck-vscode', 'https://github.com/rsaryev/talk-codebase', 'https://github.com/beimzhan/shell-whiz', 'https://github.com/smol-ai/developer', 'https://github.com/paul-gauthier/aider', 'https://github.com/AntonOsika/gpt-engineer', 'https://github.com/0xpayne/gpt-migrate', 'https://github.com/melih-unsal/DemoGPT', 'https://github.com/kuafuai/DevOpsGPT', 'https://github.com/sweepai/sweep', 'https://github.com/mattzcarey/code-review-gpt', 'https://github.com/Codium-ai/pr-agent', 'https://github.com/keerthanpg/SwePT', 'https://github.com/Yuyz0112/vx', 'https://github.com/smol-ai/developer', 'https://github.com/morph-labs/rift', 'https://github.com/kesor/chatgpt-code-plugin']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "\n",
    "def fetch_raw_markdown(url):\n",
    "    response = requests.get(url)\n",
    "    return response.text if response.status_code == 200 else None\n",
    "\n",
    "def extract_github_urls(markdown_content):\n",
    "    # This regex matches GitHub repository URLs\n",
    "    pattern = re.compile(r'https://github\\.com/[a-zA-Z0-9_-]+/[a-zA-Z0-9_-]+')\n",
    "    return pattern.findall(markdown_content)\n",
    "\n",
    "# URL to the raw markdown content of the awesome list\n",
    "raw_url = \"https://raw.githubusercontent.com/jamesmurdza/awesome-ai-devtools/main/README.md\"\n",
    "\n",
    "markdown_content = fetch_raw_markdown(raw_url)\n",
    "if markdown_content:\n",
    "    repos_urls = extract_github_urls(markdown_content)\n",
    "    print(repos_urls)\n",
    "else:\n",
    "    print(\"Failed to fetch the markdown content.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each url found in the repos_urls, extract the installation instructions found in each readme file. For instance, the first url is https://github.com/silvanmelchior/IncognitoPilot; you need to find the readme.md file and extract the installation instructions found in the readme.md. In this case you should extract the line of comments and code text in here https://github.com/silvanmelchior/IncognitoPilot/blob/main/README.md#package-installation-gpt-via-openai-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate JSON-LD\n",
    "def generate_jsonld(repos_data):\n",
    "    g = Graph()\n",
    "    for repo in repos_data:\n",
    "        repo_uri = URIRef(repo['URL'])\n",
    "        g.add((repo_uri, RDF.type, FOAF.Document))\n",
    "        g.add((repo_uri, FOAF.topic, Literal(repo['Text'], datatype=XSD.string)))\n",
    "        # Tokens can be added similarly\n",
    "    g.serialize(destination=\"output.jsonld\", format='json-ld')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fetch_repo_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Main execution\u001b[39;00m\n\u001b[1;32m      2\u001b[0m awesome_list_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/jamesmurdza/awesome-ai-devtools/main/README.md\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m repos_urls \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_repo_list\u001b[49m(awesome_list_url)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(repos_urls)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fetch_repo_list' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Main execution\n",
    "awesome_list_url = \"https://raw.githubusercontent.com/jamesmurdza/awesome-ai-devtools/main/README.md\"\n",
    "repos_urls = fetch_repo_list(awesome_list_url)\n",
    "print(repos_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repos_data = []\n",
    "\n",
    "for repo_url in repos_urls:\n",
    "    readme_content = fetch_readme_content(repo_url)\n",
    "    if readme_content:\n",
    "        instructions = extract_installation_instructions(readme_content)\n",
    "        repos_data.append({\n",
    "            \"URL\": repo_url,\n",
    "            \"Text\": \" \".join(instructions),\n",
    "            \"Tokens\": []  # Tokenization can be added as needed\n",
    "        })\n",
    "\n",
    "generate_jsonld(repos_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "\n",
    "def fetch_readme_content(repo_url):\n",
    "    \"\"\"\n",
    "    Fetches the README content from a GitHub repository.\n",
    "    \"\"\"\n",
    "    # Convert the GitHub repository URL to the raw README.md URL\n",
    "    readme_url = repo_url.replace(\"github.com\", \"raw.githubusercontent.com\") + \"/main/README.md\"\n",
    "    response = requests.get(readme_url)\n",
    "    if response.status_code == 200:\n",
    "        return response.text\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def extract_installation_instructions(readme_content):\n",
    "    \"\"\"\n",
    "    Extracts installation instructions from the README content.\n",
    "    \"\"\"\n",
    "    # Define keywords to search for in the README content\n",
    "    keywords = [\"installation\", \"setup\", \"install\", \"how to\", \"getting started\", \"quick start\"]\n",
    "    # Combine keywords into a regex pattern\n",
    "    pattern = re.compile(\"|\".join(keywords), re.IGNORECASE)\n",
    "    # Split the README content into sections\n",
    "    sections = re.split(r'#+ ', readme_content)\n",
    "    # Filter sections that contain any of the keywords\n",
    "    installation_sections = [section for section in sections if pattern.search(section)]\n",
    "    return installation_sections\n",
    "\n",
    "# Example usage\n",
    "repo_url = \"https://github.com/silvanmelchior/IncognitoPilot\"\n",
    "readme_content = fetch_readme_content(repo_url)\n",
    "if readme_content:\n",
    "    installation_instructions = extract_installation_instructions(readme_content)\n",
    "    print(\"\\n\\n\".join(installation_instructions))\n",
    "else:\n",
    "    print(\"Failed to fetch the README content.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installation instructions for https://github.com/silvanmelchior/IncognitoPilot:\n",
      ":package: Installation (GPT via OpenAI API)\n",
      "\n",
      "This section shows how to install **Incognito Pilot** using a GPT model via OpenAI's API. For\n",
      "\n",
      "- **Code Llama / Llama 2**, check [Installation for Llama 2](/docs/INSTALLATION_LLAMA.md) instead, and for\n",
      "- **GPT on Azure**, check [Installation with Azure](/docs/INSTALLATION_AZURE.md) instead.\n",
      "- If you don't have docker, you can install **Incognito Pilot** on your system directly, using the development setup (see below).\n",
      "\n",
      "Follow these steps:\n",
      "\n",
      "1. Install [docker](https://www.docker.com/).\n",
      "2. Create an empty folder somewhere on your system.\n",
      "   This will be the working directory to which **Incognito Pilot** has access to.\n",
      "   The code interpreter can read your files in this folder and store any results.\n",
      "   In the following, we assume it to be */home/user/ipilot*.\n",
      "3. Create an [OpenAI account](https://platform.openai.com),\n",
      "   add a [credit card](https://platform.openai.com/account/billing/payment-methods)\n",
      "   and create an [API key](https://platform.openai.com/account/api-keys).\n",
      "4. Now, just run the following command (replace your working directory and API key):\n",
      "\n",
      "```shell\n",
      "docker run -i -t \\\n",
      "  -p 3030:80 \\\n",
      "  -e OPENAI_API_KEY=\"sk-your-api-key\" \\\n",
      "  -e ALLOWED_HOSTS=\"localhost:3030\" \\\n",
      "  -v /home/user/ipilot:/mnt/data \\\n",
      "  silvanmelchior/incognito-pilot:latest-slim\n",
      "```\n",
      "\n",
      "In the console, you should now see a URL.\n",
      "Open it, and you should see the **Incognito Pilot** interface.\n",
      "\n",
      "It's also possible to run **Incognito Pilot** with the free trial credits of OpenAI, without adding a credit card.\n",
      "At the moment, this does not include GPT-4 however, so see below how to change the model to GPT-3.5.\n",
      "\n",
      " :rocket: Getting started (GPT)\n",
      "\n",
      "In the **Incognito Pilot** interface, you will see a chat interface, with which you can interact with the model.\n",
      "Let's try it out!\n",
      "\n",
      "1. **Greetings**: Type \"Hi\" and see how the model responds to you.\n",
      "2. **Hello World**: Type \"Print a hello world message for me\".\n",
      "   You will see how the *Code* part of the UI shows you a Python snippet.\n",
      "   As soon as you approve, the code will be executed on your machine (within the docker container).\n",
      "   You will see the result in the *Result* part of the UI.\n",
      "   As soon as you approve it, it will be sent back to the model.\n",
      "   In the case of using an API like here OpenAI's GPT models, this of course also means that this result will be sent to their services.\n",
      "3. **File Access**: Type \"Create a text file with all numbers from 0 to 100\".\n",
      "   After the approval, the model will confirm you the execution.\n",
      "   Check your working directory now (e.g. */home/user/ipilot*): You should see the file!\n",
      "\n",
      "Now you should be ready to use **Incognito Pilot** for your own tasks. Just remember:\n",
      "- Everything you type or every code result you approve is sent to the OpenAI / Azure API\n",
      "- Your data stays and is processed locally\n",
      "\n",
      "One more thing: The version you just used has nearly no packages shipped with the Python interpreter.\n",
      "This means, things like reading images or Excel files will not work.\n",
      "To change this, head back to the console and press Ctrl-C to stop the container.\n",
      "Now re-run the command, but remove the `-slim` suffix from the image.\n",
      "This will download a much larger version, equipped with [many packages](/docker/requirements_full.txt).\n",
      "\n",
      " Change model\n",
      "\n",
      "To use another model than the default one (GPT-4), set the environment variable `LLM`.\n",
      "OpenAI's GPT models have the prefix `gpt:`, so to use GPT-3.5 for example (the original ChatGPT), add the following to the docker run command:\n",
      "\n",
      "```shell\n",
      "-e LLM=\"gpt-openai:gpt-3.5-turbo\"\n",
      "```\n",
      "\n",
      "Please note that GPT-4 is considerably better in the interpreter setup than GPT-3.5.\n",
      "\n",
      " :toolbox: Own dependencies\n",
      "\n",
      "Not happy with the pre-installed packages of the full (aka non-slim) version?\n",
      "Want to add more Python (or Debian) packages to the interpreter?\n",
      "\n",
      "You can easily containerize your own dependencies with **Incognito Pilot**.\n",
      "To do so, create a Dockerfile like this:\n",
      "\n",
      "```dockerfile\n",
      "FROM silvanmelchior/incognito-pilot:latest-slim\n",
      "SHELL [\"/bin/bash\", \"-c\"]\n",
      "\n",
      " uncomment the following line, if you want to install more packages\n",
      " RUN apt update && apt install -y some-package\n",
      "\n",
      "WORKDIR /opt/app\n",
      "\n",
      "COPY requirements.txt .\n",
      "\n",
      "RUN source venv_interpreter/bin/activate && \\\n",
      "    pip3 install -r requirements.txt\n",
      "```\n",
      "\n",
      "Put your dependencies into a *requirements.txt* file and run the following command:\n",
      "\n",
      "```shell\n",
      "docker build --tag incognito-pilot-custom .\n",
      "```\n",
      "\n",
      "Then run the container like this:\n",
      "\n",
      "```shell\n",
      "docker run -i -t \\\n",
      "  ... \\\n",
      "  incognito-pilot-custom\n",
      "```\n",
      "\n",
      " Why not just use ChatGPT to generate the code and run it myself?\n",
      "\n",
      "You can of course do this. There are quite some advantages of using **Incognito Pilot** however:\n",
      "\n",
      "- Incognito Pilot can run code in multiple rounds (e.g. first getting the file name of a csv, then the structure, and then analyze the content).\n",
      "  It can even correct itself, seeing the stack trace of its failed execution.\n",
      "  You can of course also copy back and forth code and result to achieve all of this manually, but it gets cumbersome quite quickly.\n",
      "- You have tons of pre-installed dependencies in Incognito Pilot\n",
      "- The code runs in a sandbox, protecting your computer\n",
      "\n",
      " :wrench: Development\n",
      "\n",
      "Want to contribute to **Incognito Pilot**?\n",
      "Or just install it without docker?\n",
      "Check out the contribution [instruction & guidelines](/CONTRIBUTING.md).\n",
      "\n",
      "\n",
      "Failed to fetch README content for https://github.com/features/preview\n",
      "Installation instructions for https://github.com/smallcloudai/refact:\n",
      "Running Refact Self-Hosted in a Docker Container\n",
      "\n",
      "The easiest way to run the self-hosted server is a pre-build Docker image.\n",
      "\n",
      "Install [Docker with NVidia GPU support](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#docker).\n",
      "On Windows you need to install WSL 2 first, [one guide to do this](https://docs.docker.com/desktop/install/windows-install).\n",
      "\n",
      "Run docker container with following command:\n",
      "```commandline\n",
      "docker run -d --rm --gpus all -p 8008:8008 -v refact-perm-storage:/perm_storage smallcloud/refact_self_hosting:latest\n",
      "```\n",
      "\n",
      "`perm-storage` is a volume that is mounted inside the container. All the configuration files, downloaded weights and logs are stored here.\n",
      "\n",
      "To upgrade the docker, delete it using `docker kill XXX` (the volume `perm-storage` will retain your\n",
      "data), run `docker pull smallcloud/refact_self_hosting` and run it again.\n",
      "\n",
      "Now you can visit http://127.0.0.1:8008 to see the server Web GUI.\n",
      "\n",
      "\n",
      "<details><summary>Docker commands super short refresher</summary>\n",
      "Add your yourself to docker group to run docker without sudo (works for Linux):\n",
      "\n",
      "```commandline\n",
      "sudo usermod -aG docker {your user}\n",
      "```\n",
      "\n",
      "List all containers:\n",
      "\n",
      "```commandline\n",
      "docker ps -a\n",
      "```\n",
      "\n",
      "Start and stop existing containers (stop doesn't remove them):\n",
      "\n",
      "```commandline\n",
      "docker start XXX\n",
      "docker stop XXX\n",
      "```\n",
      "\n",
      "Shows messages from a container:\n",
      "```commandline\n",
      "docker logs -f XXX\n",
      "```\n",
      "\n",
      "Remove a container and all its data (except data inside a volume):\n",
      "```commandline\n",
      "docker rm XXX\n",
      "```\n",
      "\n",
      "Check out or delete a docker volume:\n",
      "```commandline\n",
      "docker volume inspect VVV\n",
      "docker volume rm VVV\n",
      "```\n",
      "</details>\n",
      "\n",
      "See [CONTRIBUTING.md](CONTRIBUTING.md) for installation without a docker container.\n",
      "\n",
      "\n",
      "\n",
      " Custom installation\n",
      "\n",
      "You can also install refact repo without docker:\n",
      "```shell\n",
      "pip install .\n",
      "```\n",
      "If you have a GPU with CUDA capability >= 8.0, you can also install it with flash-attention v2 support:\n",
      "```shell\n",
      "FLASH_ATTENTION_FORCE_BUILD=TRUE MAX_JOBS=4 INSTALL_OPTIONAL=TRUE pip install .\n",
      "```\n",
      "\n",
      "\n",
      "\n",
      "Failed to fetch README content for https://github.com/codota/TabNine\n",
      "Installation instructions for https://github.com/rubberduck-ai/rubberduck-vscode:\n",
      "Quick Install\n",
      "\n",
      "You can install Rubberduck from the\n",
      "\n",
      "- [Visual Studio Code Marketplace](https://marketplace.visualstudio.com/items?itemName=Rubberduck.rubberduck-vscode)\n",
      "- [Open VSX Registry](https://open-vsx.org/extension/Rubberduck/rubberduck-vscode)\n",
      "\n",
      "Rubberduck requires an OpenAI API key. You can get an OpenAI API key from [platform.openai.com/account/api-keys](https://platform.openai.com/account/api-keys) (you'll need to sign up for an account).\n",
      "\n",
      " [Contributing Guide][contributing]\n",
      "\n",
      "Read our [contributing guide][contributing] to learn about our development process, how to propose bugfixes and improvements, and how to build and test your changes.\n",
      "\n",
      "\n",
      "\n",
      "Installation instructions for https://github.com/rsaryev/talk-codebase:\n",
      "Installation\n",
      "\n",
      "Requirement Python 3.8.1 or higher\n",
      "Your project must be in a git repository\n",
      "\n",
      "```bash\n",
      "pip install talk-codebase\n",
      "```\n",
      "\n",
      "After installation, you can use it to chat with your codebase in the current directory by running the following command:\n",
      "\n",
      "```bash\n",
      "talk-codebase chat <path>\n",
      "```\n",
      "\n",
      "Select model type: Local or OpenAI\n",
      "\n",
      "<img width=\"300\" alt=\"select_type\" src=\"https://github.com/rsaryev/talk-codebase/assets/70219513/05196fe5-78ff-44ff-8ca3-0313ccef572a\">\n",
      "\n",
      "OpenAI\n",
      "\n",
      "If you use the OpenAI model, you need an OpenAI API key. You can get it from [here](https://beta.openai.com/). Then you\n",
      "will be offered a choice of available models.\n",
      "\n",
      "<img width=\"300\" alt=\"select\" src=\"https://github.com/rsaryev/talk-codebase/assets/70219513/889ad7c8-a489-4ce8-83af-148b7df09229\">\n",
      "\n",
      "\n",
      "Local\n",
      "\n",
      "<img width=\"696\" alt=\"–°–Ω–∏–º–æ–∫ —ç–∫—Ä–∞–Ω–∞ 2023-07-12 –≤ 03 47 58\" src=\"https://github.com/rsaryev/talk-codebase/assets/70219513/16988911-c605-4570-bfb4-4a34a03cd4a1\">\n",
      "\n",
      "If you want some files to be ignored, add them to .gitignore.\n",
      "\n",
      "\n",
      "\n",
      "Installation instructions for https://github.com/beimzhan/shell-whiz:\n",
      "Installation and setup\n",
      "\n",
      "To install Shell Whiz, run the following command:\n",
      "\n",
      "```bash\n",
      "pip install shell-whiz\n",
      "```\n",
      "\n",
      "This will add the `sw` command to your `PATH`.\n",
      "\n",
      "To use Shell Whiz, you need an API key from OpenAI. Obtain this key by visiting https://platform.openai.com/account/api-keys. Once you have the key, configure Shell Whiz by running the following command:\n",
      "\n",
      "```bash\n",
      "sw config\n",
      "```\n",
      "\n",
      " Upgrading\n",
      "\n",
      "To upgrade Shell Whiz, run the following command:\n",
      "\n",
      "```bash\n",
      "pip install --upgrade shell-whiz\n",
      "```\n",
      "\n",
      "\n",
      "\n",
      "Failed to fetch README content for https://github.com/smol-ai/developer\n",
      "Installation instructions for https://github.com/paul-gauthier/aider:\n",
      "aider is AI pair programming in your terminal\n",
      "\n",
      "Aider is a command line tool that lets you pair program with GPT-3.5/GPT-4,\n",
      "to edit code stored in your local git repository.\n",
      "You can start a new project or work with an existing repo.\n",
      "Aider makes sure edits from GPT are\n",
      "[committed to git](https://aider.chat/docs/faq.html#how-does-aider-use-git)\n",
      "with sensible commit messages.\n",
      "Aider is unique in that it lets you ask for changes to [pre-existing, larger codebases](https://aider.chat/docs/repomap.html).\n",
      "\n",
      "<p align=\"center\">\n",
      "  <img src=\"assets/screencast.svg\" alt=\"aider screencast\">\n",
      "</p>\n",
      "\n",
      "<p align=\"center\">\n",
      "  <a href=\"https://discord.gg/Tv2uQnR88V\">\n",
      "    <img src=\"https://img.shields.io/badge/Join-Discord-blue.svg\"/>\n",
      "  </a>\n",
      "</p>\n",
      "\n",
      "- [Getting started](#getting-started)\n",
      "- [Example chat transcripts](#example-chat-transcripts)\n",
      "- [Features](#features)\n",
      "- [Usage](#usage)\n",
      "- [In-chat commands](#in-chat-commands)\n",
      "- [Tips](#tips)\n",
      "- [GPT-4 vs GPT-3.5](https://aider.chat/docs/faq.html#gpt-4-vs-gpt-35)\n",
      "- [Installation](https://aider.chat/docs/install.html)\n",
      "- [Voice-to-code](https://aider.chat/docs/voice.html)\n",
      "- [FAQ](https://aider.chat/docs/faq.html)\n",
      "- [Discord](https://discord.gg/Tv2uQnR88V)\n",
      "\n",
      " Getting started\n",
      "\n",
      "See the\n",
      "[installation instructions](https://aider.chat/docs/install.html)\n",
      "for more details, but you can\n",
      "get started quickly like this:\n",
      "\n",
      "```\n",
      "$ pip install aider-chat\n",
      "$ export OPENAI_API_KEY=your-key-goes-here\n",
      "$ aider hello.js\n",
      "\n",
      "Using git repo: .git\n",
      "Added hello.js to the chat.\n",
      "\n",
      "hello.js> write a js script that prints hello world\n",
      "```\n",
      "\n",
      " Usage\n",
      "\n",
      "Run the `aider` tool by executing the following command:\n",
      "\n",
      "```\n",
      "aider <file1> <file2> ...\n",
      "```\n",
      "\n",
      "If your pip install did not place the `aider` executable on your path, you can invoke aider like this:\n",
      "\n",
      "```\n",
      "python -m aider.main <file1> <file2>\n",
      "```\n",
      "\n",
      "Replace `<file1>`, `<file2>`, etc., with the paths to the source code files you want to work on.\n",
      "These files will be \"added to the chat session\", so that GPT can see their contents and edit them according to your instructions.\n",
      "\n",
      "You can also just launch `aider` anywhere in a git repo without naming\n",
      "files on the command line.  It will discover all the files in the\n",
      "repo.  You can then add and remove individual files in the chat\n",
      "session with the `/add` and `/drop` chat commands described below.\n",
      "If you or GPT mention one of the repo's filenames in the conversation,\n",
      "aider will ask if you'd like to add it to the chat.\n",
      "\n",
      "Think about the change you want to make and which files will need\n",
      "to be edited -- add those files to the chat.\n",
      "Don't add *all* the files in your repo to the chat.\n",
      "Be selective, and just add the files that GPT will need to edit.\n",
      "If you add a bunch of unrelated files, GPT can get overwhelmed\n",
      "and confused (and it costs more tokens).\n",
      "Aider will automatically\n",
      "share snippets from other, related files with GPT so it can\n",
      "[understand the rest of your code base](https://aider.chat/docs/repomap.html).\n",
      "\n",
      "Aider also has many\n",
      "additional command-line options, environment variables or configuration file\n",
      "to set many options. See `aider --help` for details.\n",
      "\n",
      "\n",
      " Installation\n",
      "\n",
      "See the [installation instructions](https://aider.chat/docs/install.html).\n",
      "\n",
      "\n",
      "\n",
      "Installation instructions for https://github.com/AntonOsika/gpt-engineer:\n",
      "Getting Started\n",
      "\n",
      " Install gpt-engineer\n",
      "\n",
      "For **stable** release:\n",
      "\n",
      "- `python -m pip install gpt-engineer`\n",
      "\n",
      "For **development**:\n",
      "- `git clone https://github.com/gpt-engineer-org/gpt-engineer.git`\n",
      "- `cd gpt-engineer`\n",
      "- `poetry install`\n",
      "- `poetry shell` to activate the virtual environment\n",
      "\n",
      "We actively support Python 3.10 - 3.11. The last version to support python 3.8 - 3.9 was [0.2.6](https://pypi.org/project/gpt-engineer/0.2.6/).\n",
      "\n",
      " Setup API Key\n",
      "\n",
      "Choose **one** of:\n",
      "- Export env variable (you can add this to .bashrc so that you don't have to do it each time you start the terminal)\n",
      "    - `export OPENAI_API_KEY=[your api key]`\n",
      "- .env file:\n",
      "    - Create a copy of `.env.template` named `.env`\n",
      "    - Add your OPENAI_API_KEY in .env\n",
      "- Custom model:\n",
      "    - See [docs](https://gpt-engineer.readthedocs.io/en/latest/open_models.html), supports local model, azure, etc.\n",
      "\n",
      "Check the [Windows README](./WINDOWS_README.md) for windows usage.\n",
      "\n",
      "**Other ways to run:**\n",
      "- Use Docker ([instructions](docker/README.md))\n",
      "- Do everything in your browser:\n",
      "[![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://github.com/gpt-engineer-org/gpt-engineer/codespaces)\n",
      "\n",
      "\n",
      "\n",
      "Installation instructions for https://github.com/0xpayne/gpt-migrate:\n",
      "‚ö°Ô∏è Usage\n",
      "\n",
      "1. Install Docker and ensure that it's running. It's also recommended that you use at least GPT-4, preferably GPT-4-32k.\n",
      "\n",
      " üì¶ Installation using Poetry\n",
      "\n",
      "1. Install Poetry by following the instructions on the [official Poetry website](https://python-poetry.org/docs/#installation).\n",
      "\n",
      "2. Once Poetry is installed, navigate to the project directory and install the project dependencies using the following command:\n",
      "\n",
      "```bash\n",
      "poetry install\n",
      "```\n",
      "\n",
      "This will create a virtual environment and install all the necessary dependencies in that environment.\n",
      "\n",
      "2. Set your [OpenRouter API key](https://openrouter.ai/docs#api-keys) (default) and/or your [OpenAI API key](https://platform.openai.com/account/api-keys) (to use the OpenAI API directly...in this case, set --model to `gpt-4-32k` or your desired model) and install the python requirements:\n",
      "\n",
      "`export OPENROUTER_API_KEY=<your key>`\n",
      "`export OPENAI_API_KEY=<your key>`\n",
      "`pip install -r requirements.txt`\n",
      "\n",
      "3. Run the main script with the target language you want to migrate to:\n",
      "\n",
      "`python main.py --targetlang nodejs`\n",
      "\n",
      "4. (Optional) If you'd like GPT-Migrate to validate the unit tests it creates against your app before it tests the migrated app with them, please have your existing app exposed and use the `--sourceport` flag. For executing this against the benchmark, open a separate terminal, navigate to the `benchmarks/language-pair/source` directory, and run `python app.py` after installing the requirements. It will expose on port 5000. Use this with the `--sourceport` flag.\n",
      "\n",
      "By default, this script will execute the flask-nodejs benchmark. You can specify the language, source directory, and many other things using the options guide below.\n",
      "\n",
      " üí° Options\n",
      "\n",
      "You can customize the behavior of GPT-Migrate by passing the following options to the `main.py` script:\n",
      "\n",
      "- `--model`: The Large Language Model to be used. Default is `\"gpt-4-32k\"`.\n",
      "\n",
      "- `--temperature`: Temperature setting for the AI model. Default is `0`.\n",
      "\n",
      "- `--sourcedir`: Source directory containing the code to be migrated. Default is `\"../benchmarks/flask-nodejs/source\"`.\n",
      "\n",
      "- `--sourcelang`: Source language or framework of the code to be migrated. No default value.\n",
      "\n",
      "- `--sourceentry`: Entrypoint filename relative to the source directory. For instance, this could be an `app.py` or `main.py` file for Python. Default is `\"app.py\"`.\n",
      "\n",
      "- `--targetdir`: Directory where the migrated code will live. Default is `\"../benchmarks/flask-nodejs/target\"`.\n",
      "\n",
      "- `--targetlang`: Target language or framework for migration. Default is `\"nodejs\"`.\n",
      "\n",
      "- `--operating_system`: Operating system for the Dockerfile. Common options are `'linux'` or `'windows'`. Default is `'linux'`.\n",
      "\n",
      "- `--testfiles`: Comma-separated list of files that have functions to be tested. For instance, this could be an `app.py` or `main.py` file for a Python app where your REST endpoints are. Include the full relative path. Default is `\"app.py\"`.\n",
      "\n",
      "- `--sourceport`: (Optional) Port for testing the unit tests file against the original app. No default value. If not included, GPT-Migrate will not attempt to test the unit tests against your original app.\n",
      "\n",
      "- `--targetport`: Port for testing the unit tests file against the migrated app. Default is `8080`.\n",
      "\n",
      "- `--guidelines`: Stylistic or small functional guidelines that you'd like to be followed during the migration. For instance, \"Use tabs, not spaces\". Default is an empty string.\n",
      "\n",
      "- `--step`: Step to run. Options are `'setup'`, `'migrate'`, `'test'`, `'all'`. Default is `'all'`.\n",
      "\n",
      "For example, to migrate a Python codebase to Node.js, you might run:\n",
      "\n",
      "```bash\n",
      "python main.py --sourcedir /path/to/my-python-app --sourceentry app.py --targetdir /path/to/my-nodejs-app --targetlang nodejs\n",
      "```\n",
      "\n",
      "This will take the Python code in `./my-python-app`, migrate it to Node.js, and write the resulting code to `./my-nodejs-app`.\n",
      "\n",
      " üì£ Call to Action\n",
      "\n",
      "We're looking for talented contributors. Whether you have a particular passion about a specific language or framework, want to help in creating a more robust test suite, or generally have interesting ideas on how to make this better, we'd love to have you!\n",
      "\n",
      "\n",
      "\n",
      "Installation instructions for https://github.com/melih-unsal/DemoGPT:\n",
      "üì¶ Using DemoGPT Package\n",
      "\n",
      "The DemoGPT package is now available and can be installed using pip. Run the following command to install the package:\n",
      "\n",
      "```sh\n",
      "pip install demogpt\n",
      "```\n",
      "\n",
      "To use the DemoGPT application, simply type \"demogpt\" into your terminal:\n",
      "\n",
      "```sh\n",
      "demogpt\n",
      "```\n",
      "\n",
      "\n",
      " üìë Table of Contents\n",
      "\n",
      "- [Introduction](#-introduction)\n",
      "- [Architecture](#%EF%B8%8F-architecture)\n",
      "- [Installation](#-installation)\n",
      "- [Usage](#-usage)\n",
      "- [To-Do](#to-do-)\n",
      "- [Contribute](#-contribute)\n",
      "- [License](#-license)\n",
      "\n",
      " üîß Installation\n",
      "\n",
      " For the Package Version\n",
      "\n",
      "You can install the DemoGPT package by running the following command:\n",
      "\n",
      "```sh\n",
      "pip install demogpt\n",
      "```\n",
      "\n",
      " For the Source Code Version\n",
      "\n",
      "\n",
      "1. Clone the repository:\n",
      "    ```sh\n",
      "    git clone https://github.com/melih-unsal/DemoGPT.git\n",
      "    ```\n",
      "2. Navigate into the project directory:\n",
      "    ```sh\n",
      "    cd DemoGPT\n",
      "    ```\n",
      "3. Install DemoGPT: \n",
      "    ```sh\n",
      "    pip install .\n",
      "    ```\n",
      "\n",
      " üì¶ For the Package Version\n",
      "\n",
      "Once the DemoGPT package is installed, you can use it by running the following command in your terminal:\n",
      "\n",
      "```sh\n",
      "demogpt\n",
      "```\n",
      "\n",
      "\n",
      "\n",
      "Failed to fetch README content for https://github.com/kuafuai/DevOpsGPT\n",
      "Installation instructions for https://github.com/sweepai/sweep:\n",
      "<p align=\"center\">\n",
      "    <img src=\"https://github.com/sweepai/sweep/assets/26889185/39d500fc-9276-402c-9ec7-3e61f57ad233\">\n",
      "</p>\n",
      "<p align=\"center\">\n",
      "    <i>Github Issues ‚ü∂&nbsp; Pull Requests! </i>\n",
      "</p>\n",
      "<p align=\"center\">\n",
      "    <a href=\"https://github.com/apps/sweep-ai\">\n",
      "        <img alt=\"Install Sweep Github App\" src=\"https://img.shields.io/badge/Install Sweep-GitHub App-purple?link=https://github.com/apps/sweep-ai\">\n",
      "    </a>\n",
      "    <a href=\"https://discord.gg/sweep\">\n",
      "        <img src=\"https://dcbadge.vercel.app/api/server/sweep?style=flat\" />\n",
      "    </a>\n",
      "    <a href=\"https://hub.docker.com/r/sweepai/sweep\">\n",
      "        <img alt=\"Docker Pulls\" src=\"https://img.shields.io/docker/pulls/sweepai/sweep\" />\n",
      "    </a>\n",
      "    <a href=\"https://docs.sweep.dev/\">\n",
      "        <img alt=\"Docs\" src=\"https://img.shields.io/badge/Docs-docs.sweep.dev-red?link=https%3A%2F%2Fdocs.sweep.dev\">\n",
      "    </a>\n",
      "    <a href=\"https://github.com/sweepai/sweep\">\n",
      "        <img src=\"https://img.shields.io/github/commit-activity/m/sweepai/sweep\" />\n",
      "    </a>\n",
      "    <a href=\"https://uptime.betterstack.com/?utm_source=status_badge\">\n",
      "        <img src=\"https://uptime.betterstack.com/status-badges/v1/monitor/v3bu.svg\" alt=\"Better Stack Badge\">\n",
      "    </a>\n",
      "    <a href=\"https://hub.docker.com/r/sweepai/sweep\">\n",
      "        <img alt=\"Self Host Sweep Docker Image\" src=\"https://img.shields.io/badge/Host Sweep-Docker Image-2496ED?link=https://hub.docker.com/r/sweepai/sweep\">\n",
      "    </a>\n",
      "    <a href=\"https://github.com/sweepai/sweep/actions/workflows/unittest.yml\">\n",
      "        <img src=\"https://github.com/sweepai/sweep/actions/workflows/unittest.yml/badge.svg\" alt=\"Python Unit Tests\">\n",
      "    </a>\n",
      "</p>\n",
      "\n",
      "---\n",
      "\n",
      "<b>Sweep</b> is an AI junior developer that turns bugs and feature requests into code changes. Sweep automatically handles devex improvements like adding typehints/improving test coverage. :robot:\n",
      "\n",
      "[Install Sweep](https://github.com/apps/sweep-ai) and open a Github Issue like: `Sweep: Add typehints to src/utils/github_utils.py` and Sweep will:\n",
      "1. Search through your codebase to find the dependencies of github_utils.py\n",
      "2. Modify the code to add typehints\n",
      "3. **Run and debug your code to write a Pull Request** ‚ö°\n",
      "\n",
      " Getting Started\n",
      "\n",
      " GitHub App\n",
      "Install Sweep by adding the [**Sweep GitHub App**](https://github.com/apps/sweep-ai) to your desired repositories.\n",
      "\n",
      "* For more details, visit our [installation page](https://docs.sweep.dev/getting-started).\n",
      "\n",
      "* Note: Sweep only considers issues with the \"Sweep:\" title on creation and not on update. If you want Sweep to pick up an existing issue, you can add the \"Sweep\" label to the issue.\n",
      "\n",
      "* We focus on Python but support all languages GPT-4 can write. This includes JS/TS, Rust, Go, Java, C Contributing\n",
      "\n",
      "Contributions are welcome and greatly appreciated! To get set up, see [Development](https://github.com/sweepai/sweep#development). For detailed guidelines on how to contribute, please see the [CONTRIBUTING.md](CONTRIBUTING.md) file.\n",
      "\n",
      "\n",
      "<h2 align=\"center\">\n",
      "    Contributors\n",
      "</h2>\n",
      "<p align=\"center\">\n",
      "    Thank you for your contribution!\n",
      "</p>\n",
      "<p align=\"center\">\n",
      "    <a href=\"https://github.com/sweepai/sweep/graphs/contributors\">\n",
      "      <img src=\"https://contrib.rocks/image?repo=sweepai/sweep\" />\n",
      "    </a>\n",
      "</p>\n",
      "<p align=\"center\">\n",
      "    and, of course, Sweep!\n",
      "</p>\n",
      "\n",
      "\n",
      "Installation instructions for https://github.com/mattzcarey/code-review-gpt:\n",
      "Getting Started üí´\n",
      "\n",
      "1. Clone the repository:\n",
      "\n",
      "   ```shell\n",
      "   git clone https://github.com/mattzcarey/code-review-gpt.git\n",
      "   cd code-review-gpt && cd code-review-gpt\n",
      "   ```\n",
      "\n",
      "2. Install dependencies:\n",
      "\n",
      "   ```shell\n",
      "   npm install\n",
      "   ```\n",
      "\n",
      "3. Set up the API key:\n",
      "   - Rename the .env.example file to .env.\n",
      "   - Open the .env file and replace YOUR_API_KEY with your actual OPENAI API key.\n",
      "\n",
      "When used globally you should run `export OPENAI_API_KEY=YOUR_API_KEY` (or similar for your operating system) in your terminal to set the API key.\n",
      "\n",
      "4. Run the application:\n",
      "\n",
      "   ```shell\n",
      "   npm start\n",
      "   ```\n",
      "\n",
      "See the package.json file for all the npm commands you can run.\n",
      "\n",
      "5. Make a PR üéâ\n",
      "\n",
      "We use [release-please](https://github.com/googleapis/release-please) on this project. If you want to create a new release from your PR, please make sure your PR title follows the [Conventional Commits](https://www.conventionalcommits.org/en/v1.0.0/) format. The release-please bot will automatically create a new release for you when your PR is merged.\n",
      "\n",
      "- fix: which represents bug fixes, and correlates to a patch version.\n",
      "- feat: which represents a new feature, and correlates to a SemVer minor.\n",
      "- feat!:, or fix!:, refactor!:, etc., which represent a breaking change (indicated by the !) and will result in a major version.\n",
      "\n",
      " Roadmap (see projects tab) üåè\n",
      "\n",
      "The roadmap shifts the focus to a Github app which can be installed on any repo. This will allow for a more seamless UX and better features including a chatbot to discuss the PR and make suggestions. \n",
      "\n",
      "The code-review-gpt package will continue to be maintained and improved based on the feedback from the Github app.\n",
      "\n",
      "\n",
      "\n",
      "Installation instructions for https://github.com/Codium-ai/pr-agent:\n",
      "Table of Contents\n",
      "- [News and Updates](#news-and-updates)\n",
      "- [Overview](#overview)\n",
      "- [Example results](#example-results)\n",
      "- [Try it now](#try-it-now)\n",
      "- [Installation](#installation)\n",
      "- [PR-Agent Pro üíé](#pr-agent-pro-)\n",
      "- [How it works](#how-it-works)\n",
      "- [Why use PR-Agent?](#why-use-pr-agent)\n",
      "  \n",
      " Overview\n",
      "<div style=\"text-align:left;\">\n",
      "\n",
      "CodiumAI PR-Agent is an open-source tool to help efficiently review and handle pull requests. It automatically analyzes the pull request and can provide several types of commands:\n",
      "\n",
      "|       |                                                                                                                                          | GitHub | Gitlab | Bitbucket |\n",
      "|-------|------------------------------------------------------------------------------------------------------------------------------------------|:------:|:------:|:---------:|\n",
      "| TOOLS | Review                                                                                                                                   |   :white_check_mark:    |   :white_check_mark:    |   :white_check_mark:       |\n",
      "|       | ‚Æë Incremental                                                                                                                            |   :white_check_mark:    |                         |                            |\n",
      "|       | ‚Æë [SOC2 Compliance](https://github.com/Codium-ai/pr-agent/blob/main/docs/REVIEW.md#soc2-ticket-compliance-) üíé                           |   :white_check_mark:    |   :white_check_mark:    |   :white_check_mark:        |\n",
      "|       | Describe                                                                                                                                 |   :white_check_mark:    |   :white_check_mark:    |   :white_check_mark:        |\n",
      "|       | ‚Æë [Inline File Summary](https://github.com/Codium-ai/pr-agent/blob/main/docs/DESCRIBE.md#inline-file-summary-) üíé                        |   :white_check_mark:    |       |          |\n",
      "|       | Improve                                                                                                                                  |   :white_check_mark:    |   :white_check_mark:    |   :white_check_mark:        |\n",
      "|       | ‚Æë Extended                                                                                                                               |   :white_check_mark:    |   :white_check_mark:    |   :white_check_mark:        |\n",
      "|       | Ask                                                                                                                                      |   :white_check_mark:    |   :white_check_mark:    |   :white_check_mark:        |\n",
      "|       | [Custom Suggestions](https://github.com/Codium-ai/pr-agent/blob/main/docs/CUSTOM_SUGGESTIONS.md) üíé                                      |   :white_check_mark:    |   :white_check_mark:    |   :white_check_mark:        |\n",
      "|       | [Test](https://github.com/Codium-ai/pr-agent/blob/main/docs/TEST.md) üíé                                                                  |   :white_check_mark:    |   :white_check_mark:    |   :white_check_mark:        |\n",
      "|       | Reflect and Review                                                                                                                       |   :white_check_mark:    |   :white_check_mark:    |   :white_check_mark:        |\n",
      "|       | Update CHANGELOG.md                                                                                                                      |   :white_check_mark:    |   :white_check_mark:    |   :white_check_mark:        |\n",
      "|       | Find Similar Issue                                                                                                                       |   :white_check_mark:    |                         |                             |\n",
      "|       | [Add PR Documentation](https://github.com/Codium-ai/pr-agent/blob/main/docs/ADD_DOCUMENTATION.md) üíé                                     |   :white_check_mark:    |   :white_check_mark:    |   :white_check_mark:        |\n",
      "|       | [Custom Labels](https://github.com/Codium-ai/pr-agent/blob/main/docs/DESCRIBE.md#handle-custom-labels-from-the-repos-labels-page-gem) üíé |   :white_check_mark:    |   :white_check_mark:    |         |\n",
      "|       | [Analyze](https://github.com/Codium-ai/pr-agent/blob/main/docs/Analyze.md) üíé                                                            |   :white_check_mark:    |   :white_check_mark:    |   :white_check_mark:      |\n",
      "|       |                                                                                                                                          |        |        |      |\n",
      "| USAGE | CLI                                                                                                                                      |   :white_check_mark:    |   :white_check_mark:    |   :white_check_mark:       |\n",
      "|       | App / webhook                                                                                                                            |   :white_check_mark:    |   :white_check_mark:    |  :white_check_mark:     |\n",
      "|       | Tagging bot                                                                                                                              |   :white_check_mark:    |        |           | \n",
      "|       | Actions                                                                                                                                  |   :white_check_mark:    |        |  :white_check_mark:         | \n",
      "|       |                                                                                                                                          |        |        |      |\n",
      "| CORE  | PR compression                                                                                                                           |   :white_check_mark:    |   :white_check_mark:    |   :white_check_mark:       |\n",
      "|       | Repo language prioritization                                                                                                             |   :white_check_mark:    |   :white_check_mark:    |   :white_check_mark:       |\n",
      "|       | Adaptive and token-aware<br />file patch fitting                                                                                         |   :white_check_mark:    |   :white_check_mark:    |   :white_check_mark:     |\n",
      "|       | Multiple models support                                                                                                                  |   :white_check_mark:    |   :white_check_mark:    |   :white_check_mark:       | :white_check_mark: |\n",
      "|       | [Static code analysis](https://github.com/Codium-ai/pr-agent/blob/main/docs/Analyze.md) üíé                                               |   :white_check_mark:    |   :white_check_mark:     |    :white_check_mark:    |\n",
      "|       | [Global configuration](https://github.com/Codium-ai/pr-agent/blob/main/Usage.md#global-configuration-file-) üíé                           |   :white_check_mark:    |   :white_check_mark:     |    :white_check_mark:    |\n",
      "- üíé means this feature is available only in [PR-Agent Pro](https://www.codium.ai/pricing/)\n",
      "- Support for additional git providers is described in [here](./docs/Full_environments.md)\n",
      "___\n",
      "\n",
      "‚Ä£ **Auto Description ([`/describe`](./docs/DESCRIBE.md))**: Automatically generating PR description - title, type, summary, code walkthrough and labels.\n",
      "\\\n",
      "‚Ä£ **Auto Review ([`/review`](./docs/REVIEW.md))**: Adjustable feedback about the PR main theme, type, relevant tests, security issues, score, and various suggestions for the PR content.\n",
      "\\\n",
      "‚Ä£ **Question Answering ([`/ask ...`](./docs/ASK.md))**: Answering free-text questions about the PR.\n",
      "\\\n",
      "‚Ä£ **Code Suggestions ([`/improve`](./docs/IMPROVE.md))**: Committable code suggestions for improving the PR.\n",
      "\\\n",
      "‚Ä£ **Update Changelog ([`/update_changelog`](./docs/UPDATE_CHANGELOG.md))**: Automatically updating the CHANGELOG.md file with the PR changes.\n",
      "\\\n",
      "‚Ä£ **Find Similar Issue ([`/similar_issue`](./docs/SIMILAR_ISSUE.md))**: Automatically retrieves and presents similar issues.\n",
      "\\\n",
      "‚Ä£ **Add Documentation üíé  ([`/add_docs`](./docs/ADD_DOCUMENTATION.md))**: Automatically adds documentation to methods/functions/classes that changed in the PR.\n",
      "\\\n",
      "‚Ä£ **Generate Custom Labels üíé ([`/generate_labels`](./docs/GENERATE_CUSTOM_LABELS.md))**: Automatically suggests custom labels based on the PR code changes.\n",
      "\\\n",
      "‚Ä£ **Analyze üíé ([`/analyze`](./docs/Analyze.md))**: Automatically analyzes the PR, and presents changes walkthrough for each component.\n",
      "\\\n",
      "‚Ä£ **Custom Suggestions üíé ([`/custom_suggestions`](./docs/CUSTOM_SUGGESTIONS.md))**: Automatically generates custom suggestions for improving the PR code, based on specific guidelines defined by the user.\n",
      "\\\n",
      "‚Ä£ **Generate Tests üíé ([`/test component_name`](./docs/TEST.md))**: Automatically generates unit tests for a selected component, based on the PR code changes.\n",
      "\n",
      "See the [Installation Guide](./INSTALL.md) for instructions on installing and running the tool on different git platforms.\n",
      "\n",
      "See the [Usage Guide](./Usage.md) for running the PR-Agent commands via different interfaces, including _CLI_, _online usage_, or by _automatically triggering_ them when a new PR is opened.\n",
      "\n",
      "See the [Tools Guide](./docs/TOOLS_GUIDE.md) for a detailed description of the different tools (tools are run via the commands).\n",
      "\n",
      "\n",
      " Try it now\n",
      "\n",
      "Try the GPT-4 powered PR-Agent instantly on _your public GitHub repository_. Just mention `@CodiumAI-Agent` and add the desired command in any PR comment. The agent will generate a response based on your command.\n",
      "For example, add a comment to any pull request with the following text:\n",
      "```\n",
      "@CodiumAI-Agent /review\n",
      "```\n",
      "and the agent will respond with a review of your PR\n",
      "\n",
      "![Review generation process](https://www.codium.ai/images/demo-2.gif)\n",
      "\n",
      "\n",
      "To set up your own PR-Agent, see the [Installation](#installation) section below.\n",
      "Note that when you set your own PR-Agent or use CodiumAI hosted PR-Agent, there is no need to mention `@CodiumAI-Agent ...`. Instead, directly start with the command, e.g., `/ask ...`.\n",
      "\n",
      "---\n",
      "\n",
      " Installation\n",
      "To use your own version of PR-Agent, you first need to acquire two tokens:\n",
      "\n",
      "1. An OpenAI key from [here](https://platform.openai.com/), with access to GPT-4.\n",
      "2. A GitHub personal access token (classic) with the repo scope.\n",
      "\n",
      "There are several ways to use PR-Agent:\n",
      "\n",
      "- [Method 1: Use Docker image (no installation required)](INSTALL.md#method-1-use-docker-image-no-installation-required)\n",
      "- [Method 2: Run from source](INSTALL.md#method-2-run-from-source)\n",
      "- [Method 3: Run as a GitHub Action](INSTALL.md#method-3-run-as-a-github-action)\n",
      "- [Method 4: Run as a polling server](INSTALL.md#method-4-run-as-a-polling-server)\n",
      "  - Request reviews by tagging your GitHub user on a PR\n",
      "- [Method 5: Run as a GitHub App](INSTALL.md#method-5-run-as-a-github-app)\n",
      "  - Allowing you to automate the review process on your private or public repositories\n",
      "- [Method 6: Deploy as a Lambda Function](INSTALL.md#method-6---deploy-as-a-lambda-function)\n",
      "- [Method 7: AWS CodeCommit](INSTALL.md#method-7---aws-codecommit-setup)\n",
      "- [Method 8: Run a GitLab webhook server](INSTALL.md#method-8---run-a-gitlab-webhook-server)\n",
      "- [Method 9: Run as a Bitbucket Pipeline](INSTALL.md#method-9-run-as-a-bitbucket-pipeline)\n",
      "\n",
      " PR-Agent Pro üíé\n",
      "[PR-Agent Pro](https://www.codium.ai/pricing/) is a hosted version of PR-Agent, provided by CodiumAI. It is available for a monthly fee, and provides the following benefits:\n",
      "1. **Fully managed** - We take care of everything for you - hosting, models, regular updates, and more. Installation is as simple as signing up and adding the PR-Agent app to your GitHub\\BitBucket repo.\n",
      "2. **Improved privacy** - No data will be stored or used to train models. PR-Agent Pro will employ zero data retention, and will use an OpenAI account with zero data retention.\n",
      "3. **Improved support** - PR-Agent Pro users will receive priority support, and will be able to request new features and capabilities.\n",
      "4. **Extra features** -In addition to the benefits listed above, PR-Agent Pro will emphasize more customization, and the usage of static code analysis, in addition to LLM logic, to improve results. It has the following additional features:\n",
      "    - [**SOC2 compliance check**](https://github.com/Codium-ai/pr-agent/blob/main/docs/REVIEW.md#soc2-ticket-compliance-)\n",
      "    - [**PR documentation**](https://github.com/Codium-ai/pr-agent/blob/main/docs/ADD_DOCUMENTATION.md)\n",
      "    - [**Custom labels**](https://github.com/Codium-ai/pr-agent/blob/main/docs/DESCRIBE.md#handle-custom-labels-from-the-repos-labels-page-gem)\n",
      "    - [**Global configuration**](https://github.com/Codium-ai/pr-agent/blob/main/Usage.md#global-configuration-file-)\n",
      "    - [**Analyze PR components**](https://github.com/Codium-ai/pr-agent/blob/main/docs/Analyze.md)\n",
      "    - **Custom Code Suggestions** [WIP]\n",
      "    - **Chat on Specific Code Lines** [WIP]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Installation instructions for https://github.com/keerthanpg/SwePT:\n",
      "Usage\n",
      "```\n",
      "python swept.py -h                                                                                              \n",
      "usage: swept.py [-h] -f FILE -i INSTRUCTION [-r REPO] [-d] [-pr]\n",
      "\n",
      "Edit a section of code, PR with changes.\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  -f FILE, --file FILE  location of a file\n",
      "  -i INSTRUCTION, --instruction INSTRUCTION\n",
      "                        instruction on how to edit the file\n",
      "  -r REPO, --repo REPO  location to git repo\n",
      "  -d, --diff            show diff\n",
      "  -pr, --pull-request   add change, commit, push and raise a PR\n",
      "\n",
      "```\n",
      "\n",
      "\n",
      "\n",
      "Failed to fetch README content for https://github.com/Yuyz0112/vx\n",
      "Failed to fetch README content for https://github.com/smol-ai/developer\n",
      "Installation instructions for https://github.com/morph-labs/rift:\n",
      "[Download for VSCode](https://marketplace.visualstudio.com/items?itemName=Morph.rift-vscode)\n",
      "\n",
      "Rift is open-source infrastructure for AI-native development environments. Rift makes your IDE *agentic*. Software will soon be written mostly by AI software engineers that work alongside you. Codebases will soon be living, spatial artifacts that *maintain context*, *listen to*, *anticipate*, *react to*, and *execute* your every intent. The [Rift Code Engine](./rift-engine/) implements an AI-native extension of the [language server protocol](https://microsoft.github.io/language-server-protocol/). The [Rift VSCode extension](./editors/rift-vscode) implements a client and end-user interface which is the first step into that future.\n",
      "\n",
      "https://github.com/morph-labs/rift/assets/13114790/726f35ed-4959-4f69-9a80-fd903b26f909\n",
      "\n",
      "- [Discord](https://discord.gg/wa5sgWMfqv)\n",
      "- [Features](#features)\n",
      "  - Conversational Code Editing\n",
      "  - Codebase-wide Edits\n",
      "  - Contextual Codebase Generation\n",
      "  - Auto Docstring Generation\n",
      "- [Tips](#tips)\n",
      "- [Getting Started](#getting-started)\n",
      "- [Manual Installation](#manual-installation)\n",
      "- [The Road Ahead](#the-road-ahead)\n",
      "- [Contributing](#contributing)\n",
      "- [Feedback](#feedback)\n",
      "\n",
      "\n",
      "\n",
      " Tips\n",
      "- Press Command+M to focus the Rift Omnibar.\n",
      "  - Once focused, you can either engage with the current chat or use a slash-command (e.g. `/aider`) to spawn a new agent.\n",
      "- Each instance of a Rift Chat or Code Edit agent will remain attached to the open file / selection you used to spawn it.\n",
      "  - To switch to a new file or request a code edit on a new selection, spawn a new agent by pressing Command+M and running a slash-command (e.g. `/edit`)\n",
      "  - Both Rift Chat and Code Edit see a window around your cursor or selection in the currently active editor window. To tell them about other resources in your codebase, mention them with `@`.\n",
      "  - Code Edit \n",
      "- You can `@`-mention files and directories to tell your agents about other parts of the codebase.\n",
      "  - `@`-mentioning files currently only works with Aider if those files are tracked by git.\n",
      "- Currently, Rift works best when the active workspace directory is the same as the root directory of the `git` project.\n",
      "- Command+Shift+P -> \"Rift: Start Server\" restarts the server if it has been auto-installed.\n",
      "\n",
      "\n",
      " Getting Started\n",
      "Install the VSCode extension from the VSCode Marketplace. By default, the extension will attempt to automatically start the Rift Code Engine every time the extension is activated. During this process, if a `rift` executable is not found in a virtual environment under `~/.morph`, the extension will ask you to attempt an automatic installation of a Python environment and the Rift Code Engine. To disable this behavior, such as for development, go to the VSCode settings, search for \"rift\", and set `rift.autostart` to `false`.\n",
      "\n",
      "When `rift.autostart` is `true`, the extension will attempt to automatically start the Rift Code Engine. You can set `rift.riftPath` to change the path of the Rift executable, which may be necessary due to interactions with WSL on Windows.\n",
      "\n",
      "When `rift.autostart` is `false`, the extension will display a loading indicator while it waits for a server instance to connect to `rift.riftServerPort` (default 7797). In this scenario, you will have to start the Rift server instance manually by running it in a terminal, e.g. with\n",
      "\n",
      "```bash\n",
      "source ~/.morph/env/bin/activate\n",
      "rift --port 7797\n",
      "```\n",
      "\n",
      "Upon installation, when one changes the 'Code Edit Model' in the settings to our Rift Coder 7B model, it will automatically install an 8-bit quantized version of the model. [The raw model can be found here](https://huggingface.co/morph-labs/rift-coder-v0-7b-gguf).\n",
      "\n",
      "\n",
      "If the automatic installation of the Rift Code Engine fails, follow the below instructions for manual installation.\n",
      "\n",
      " Manual Installation\n",
      "**Rift Code Engine**:\n",
      "- Set up a Python virtual environment for Python 3.10 or higher.\n",
      "  - On Mac OSX:\n",
      "    - Install [homebrew](https://brew.sh).\n",
      "    - `brew install python@3.10`\n",
      "    - `mkdir -p ~/.morph/ && cd ~/.morph/ && python3.10 -m venv env`\n",
      "    - `source ./env/bin/activate`\n",
      "  - On Linux:\n",
      "    - On Ubuntu:\n",
      "      - `sudo apt install software-properties-common -y`\n",
      "      - `sudo add-apt-repository ppa:deadsnakes/ppa`\n",
      "      - `sudo apt install python3.10 && sudo apt install python3.10-venv`\n",
      "      - `mkdir -p ~/.morph/ && cd ~/.morph/ && python3.10 -m venv env`\n",
      "      - `source ./env/bin/activate`\n",
      "    - On Arch:\n",
      "      - `yay -S python310`\n",
      "      - `mkdir -p ~/.morph/ && cd ~/.morph/ && python3.10 -m venv env`\n",
      "      - `source ./env/bin/activate`\n",
      "  - On Windows:\n",
      "    - We recommend that you use [WSL](https://learn.microsoft.com/en-us/windows/wsl/install) with Ubuntu. Once inside a WSL shell, follow the Ubuntu installation instructions above.\n",
      "    - Make sure **inbound connections over port 7797 from WSL to Windows** are allowed (e.g. try following this [guide](https://www.nextofwindows.com/allow-server-running-inside-wsl-to-be-accessible-outside-windows-10-host) but for port 7797 instead of 3000).\n",
      "    - On Windows we recommend that users disable `rift.autostart` in VSCode and run Rift manually as `~/.morph/env/bin/rift` after following the installation instructions below.\n",
      "- Install Rift. We recommend that you `pip install` Rift in a dedicated Python >=3.10 virtual environment from this repository.\n",
      "  - Make sure that `which pip` returns a path whose prefix matches the location of a virtual environment, such as the one installed above.\n",
      "  <!-- - Using `pip` and PyPI: -->\n",
      "  <!--   - `pip install --upgrade 'pyrift[all]'` -->\n",
      "  <!--     - `[all]` is required to pull in direct dependencies needed for third-party agents like Aider, Smol Dev, and GPT Engineer. -->\n",
      "  - using `pip` from GitHub:\n",
      "    - `pip install \"git+https://github.com/morph-labs/rift.git@main#egg=pyrift&subdirectory=rift-engine\"`\n",
      "  - From source:\n",
      "    - `cd ~/.morph/ && git clone git@github.com:morph-labs/rift && cd ./rift/rift-engine/ && pip install -e .`\n",
      "      \n",
      "**Rift VSCode Extension** (via `code --install-extension`, change the executable as needed):\n",
      "- From the repository root: `cd ./editors/rift-vscode && npm i && bash reinstall.sh`. Make sure your OpenAI API key is set in the VSCode settings (open with `Ctrl + ,` then search for \"rift\").\n",
      "\n",
      "\n",
      "\n",
      "Installation instructions for https://github.com/kesor/chatgpt-code-plugin:\n",
      "Installation\n",
      "\n",
      "1. Clone the repository: `git clone https://github.com/kesor/chatgpt-code-plugin.git`\n",
      "2. Navigate to the project directory: `cd chatgpt-code-plugin`\n",
      "3. Install the dependencies: `npm install`\n",
      "4. Build project: `npm run build`\n",
      "5. Start the server: `BASE_PATH=/home/myuser/src/awesome-project  npm start`\n",
      "6. Add the API into ChatGPT Plus plugins' \"Developer your own plugin\" interface (`http://localhost:3000`)\n",
      "\n",
      " How to Contribute\n",
      "\n",
      "1. Fork the repository\n",
      "2. Create a new branch for each feature or bugfix\n",
      "3. Write your code\n",
      "4. Write tests for your code\n",
      "5. Run the tests and make sure they pass\n",
      "6. Submit a pull request\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "\n",
    "def fetch_raw_markdown(url):\n",
    "    \"\"\"\n",
    "    Fetches the raw markdown content from a URL.\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    return response.text if response.status_code == 200 else None\n",
    "\n",
    "def extract_github_urls(markdown_content):\n",
    "    \"\"\"\n",
    "    Extracts GitHub repository URLs from markdown content.\n",
    "    \"\"\"\n",
    "    pattern = re.compile(r'https://github\\.com/[a-zA-Z0-9_-]+/[a-zA-Z0-9_-]+')\n",
    "    return pattern.findall(markdown_content)\n",
    "\n",
    "def fetch_readme_content(repo_url):\n",
    "    \"\"\"\n",
    "    Fetches the README content from a GitHub repository.\n",
    "    \"\"\"\n",
    "    readme_url = repo_url.replace(\"github.com\", \"raw.githubusercontent.com\") + \"/main/README.md\"\n",
    "    response = requests.get(readme_url)\n",
    "    return response.text if response.status_code == 200 else None\n",
    "\n",
    "def extract_installation_instructions(readme_content):\n",
    "    \"\"\"\n",
    "    Extracts installation instructions from the README content.\n",
    "    \"\"\"\n",
    "    keywords = [\"installation\", \"setup\", \"install\", \"how to\", \"getting started\", \"quick start\"]\n",
    "    pattern = re.compile(\"|\".join(keywords), re.IGNORECASE)\n",
    "    sections = re.split(r'#+ ', readme_content)\n",
    "    installation_sections = [section for section in sections if pattern.search(section)]\n",
    "    return installation_sections\n",
    "\n",
    "# Main execution\n",
    "awesome_list_url = \"https://raw.githubusercontent.com/jamesmurdza/awesome-ai-devtools/main/README.md\"\n",
    "markdown_content = fetch_raw_markdown(awesome_list_url)\n",
    "if markdown_content:\n",
    "    repos_urls = extract_github_urls(markdown_content)\n",
    "    for repo_url in repos_urls:\n",
    "        readme_content = fetch_readme_content(repo_url)\n",
    "        if readme_content:\n",
    "            installation_instructions = extract_installation_instructions(readme_content)\n",
    "            print(f\"Installation instructions for {repo_url}:\\n{' '.join(installation_instructions)}\\n\")\n",
    "        else:\n",
    "            print(f\"Failed to fetch README content for {repo_url}\")\n",
    "else:\n",
    "    print(\"Failed to fetch the markdown content of the awesome list.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import json\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def fetch_raw_markdown(url):\n",
    "    response = requests.get(url)\n",
    "    return response.text if response.status_code == 200 else None\n",
    "\n",
    "def extract_github_urls(markdown_content):\n",
    "    pattern = re.compile(r'https://github\\.com/[a-zA-Z0-9_-]+/[a-zA-Z0-9_-]+')\n",
    "    return pattern.findall(markdown_content)\n",
    "\n",
    "def fetch_readme_content(repo_url):\n",
    "    readme_url = repo_url.replace(\"github.com\", \"raw.githubusercontent.com\") + \"/main/README.md\"\n",
    "    response = requests.get(readme_url)\n",
    "    return response.text if response.status_code == 200 else None\n",
    "\n",
    "def extract_installation_instructions(readme_content):\n",
    "    keywords = [\"installation\", \"setup\", \"install\", \"how to\", \"getting started\", \"quick start\"]\n",
    "    pattern = re.compile(\"|\".join(keywords), re.IGNORECASE)\n",
    "    sections = re.split(r'#+ ', readme_content)\n",
    "    installation_sections = [section for section in sections if pattern.search(section)]\n",
    "    return installation_sections\n",
    "\n",
    "def tokenize_text(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "# Create an heuristic classifier to cluster the repo_url by complexity of the installation instructions: \n",
    "# complexity = 0 if the installation instructions contain in token and text: \"pip install\", \"package manager install\",\n",
    "# complexity = 1 if the installation instructions contain: \"container\", \"docker container\", \"docker componse up\"\n",
    "# complexity = 2 if the installation instructions contain: \"from source\", \"git clone\", \".git\"\n",
    "# append the heuristic classifier to the repos_data\n",
    "\n",
    "\n",
    "# Main execution\n",
    "awesome_list_url = \"https://raw.githubusercontent.com/jamesmurdza/awesome-ai-devtools/main/README.md\"\n",
    "markdown_content = fetch_raw_markdown(awesome_list_url)\n",
    "repos_data = []\n",
    "\n",
    "if markdown_content:\n",
    "    repos_urls = extract_github_urls(markdown_content)\n",
    "    for repo_url in repos_urls:\n",
    "        readme_content = fetch_readme_content(repo_url)\n",
    "        if readme_content:\n",
    "            installation_instructions = extract_installation_instructions(readme_content)\n",
    "            instructions_text = \" \".join(installation_instructions)\n",
    "            tokens = tokenize_text(instructions_text)\n",
    "\n",
    "            # Heuristic classifier\n",
    "            complexity = -1  # Default complexity\n",
    "            if any(word in tokens for word in [\"pip install\", \"package manager install\"]):\n",
    "                complexity = 0\n",
    "            elif any(word in instructions_text for word in [\"container\", \"docker container\", \"docker compose up\"]):\n",
    "                complexity = 1\n",
    "            elif any(word in instructions_text for word in [\"from source\", \"git clone\", \".git\"]):\n",
    "                complexity = 2\n",
    "\n",
    "            repos_data.append({\n",
    "                \"url\": repo_url,\n",
    "                \"text\": instructions_text,\n",
    "                \"tokens\": tokens,\n",
    "                \"level complexity\": complexity\n",
    "            })\n",
    "else:\n",
    "    print(\"Failed to fetch the markdown content of the awesome list.\")\n",
    "\n",
    "# Output to a JSON file\n",
    "with open('output.json', 'w') as outfile:\n",
    "    json.dump(repos_data, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File output2.json does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m columns_long_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokens\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel complexity\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      3\u001b[0m columns_short_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokens\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 4\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_json\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutput2.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/json/_json.py:733\u001b[0m, in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_axes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m orient \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    731\u001b[0m     convert_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m json_reader \u001b[38;5;241m=\u001b[39m \u001b[43mJsonReader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    735\u001b[0m \u001b[43m    \u001b[49m\u001b[43morient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_default_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_default_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    742\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprecise_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecise_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_unit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    744\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    745\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    748\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    753\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize:\n\u001b[1;32m    754\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m json_reader\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/json/_json.py:818\u001b[0m, in \u001b[0;36mJsonReader.__init__\u001b[0;34m(self, filepath_or_buffer, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines, chunksize, compression, nrows, storage_options, encoding_errors)\u001b[0m\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlines:\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows can only be passed if lines=True\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 818\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data_from_filepath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocess_data(data)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/json/_json.py:874\u001b[0m, in \u001b[0;36mJsonReader._get_data_from_filepath\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m    866\u001b[0m     filepath_or_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n\u001b[1;32m    867\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[1;32m    868\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(filepath_or_buffer, \u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m filepath_or_buffer\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file_exists(filepath_or_buffer)\n\u001b[1;32m    873\u001b[0m ):\n\u001b[0;32m--> 874\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_or_buffer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    876\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m filepath_or_buffer\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File output2.json does not exist"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "columns_long_list = ['url', 'text', 'tokens', 'level complexity']\n",
    "columns_short_list = ['url', 'text', 'tokens']\n",
    "df = pd.read_json('output.json')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "level complexity\n",
       "-1    5\n",
       " 1    2\n",
       " 2    8\n",
       "Name: tokens, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['level complexity'])['tokens'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>token_len</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>level complexity</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">-1</th>\n",
       "      <th>0.50</th>\n",
       "      <td>107.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.70</th>\n",
       "      <td>519.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.80</th>\n",
       "      <td>671.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.90</th>\n",
       "      <td>768.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.95</th>\n",
       "      <td>816.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>0.50</th>\n",
       "      <td>745.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.70</th>\n",
       "      <td>894.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.80</th>\n",
       "      <td>969.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.90</th>\n",
       "      <td>1043.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.95</th>\n",
       "      <td>1080.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2</th>\n",
       "      <th>0.50</th>\n",
       "      <td>277.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.70</th>\n",
       "      <td>625.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.80</th>\n",
       "      <td>1001.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.90</th>\n",
       "      <td>1432.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.95</th>\n",
       "      <td>1669.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       token_len\n",
       "level complexity                \n",
       "-1               0.50     107.00\n",
       "                 0.70     519.80\n",
       "                 0.80     671.40\n",
       "                 0.90     768.20\n",
       "                 0.95     816.60\n",
       " 1               0.50     745.50\n",
       "                 0.70     894.50\n",
       "                 0.80     969.00\n",
       "                 0.90    1043.50\n",
       "                 0.95    1080.75\n",
       " 2               0.50     277.00\n",
       "                 0.70     625.10\n",
       "                 0.80    1001.00\n",
       "                 0.90    1432.40\n",
       "                 0.95    1669.70"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['token_len'] = df.tokens.apply(lambda x: len(x))\n",
    "query_len_summary = df.groupby('level complexity')['token_len'].quantile([.5, .7, .8, .9, .95])\n",
    "display(pd.DataFrame(query_len_summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>level complexity</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">-1</th>\n",
       "      <th>0.50</th>\n",
       "      <td>107.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.70</th>\n",
       "      <td>519.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.80</th>\n",
       "      <td>671.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.90</th>\n",
       "      <td>768.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.95</th>\n",
       "      <td>816.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>0.50</th>\n",
       "      <td>745.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.70</th>\n",
       "      <td>894.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.80</th>\n",
       "      <td>969.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.90</th>\n",
       "      <td>1043.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.95</th>\n",
       "      <td>1080.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2</th>\n",
       "      <th>0.50</th>\n",
       "      <td>277.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.70</th>\n",
       "      <td>625.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.80</th>\n",
       "      <td>1001.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.90</th>\n",
       "      <td>1432.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.95</th>\n",
       "      <td>1669.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          text\n",
       "level complexity              \n",
       "-1               0.50   107.00\n",
       "                 0.70   519.80\n",
       "                 0.80   671.40\n",
       "                 0.90   768.20\n",
       "                 0.95   816.60\n",
       " 1               0.50   745.50\n",
       "                 0.70   894.50\n",
       "                 0.80   969.00\n",
       "                 0.90  1043.50\n",
       "                 0.95  1080.75\n",
       " 2               0.50   277.00\n",
       "                 0.70   625.10\n",
       "                 0.80  1001.00\n",
       "                 0.90  1432.40\n",
       "                 0.95  1669.70"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['text'] = df.tokens.apply(lambda x: len(x))\n",
    "query_len_summary = df.groupby('level complexity')['text'].quantile([.5, .7, .8, .9, .95])\n",
    "display(pd.DataFrame(query_len_summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Token  Frequency\n",
      "0     :        379\n",
      "1     `        338\n",
      "2     .        268\n",
      "3   the        243\n",
      "4     *        211\n",
      "5     ,        180\n",
      "6     |        180\n",
      "7     (        168\n",
      "8     )        168\n",
      "9     -        152\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Assuming df is your DataFrame and 'field3' is the column with tokens\n",
    "# Step 1: Aggregate Tokens\n",
    "all_tokens = sum(df['tokens'].tolist(), [])\n",
    "\n",
    "# Step 2: Count Frequencies\n",
    "token_counts = Counter(all_tokens)\n",
    "\n",
    "\n",
    "\n",
    "# Step 3: Summarize Most Frequent Tokens\n",
    "most_common_tokens = token_counts.most_common(10)  # Adjust the number to get more or fewer tokens\n",
    "\n",
    "# Convert the most common tokens to a DataFrame for a nicer display\n",
    "summary_df = pd.DataFrame(most_common_tokens, columns=['Token', 'Frequency'])\n",
    "\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Empty DataFrame\n",
      "Columns: [Token, Frequency]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Define the specific tokens you're interested in\n",
    "import re\n",
    "specific_tokens = [token for token in summary_df['Token'] if re.search(r'docker', token, re.IGNORECASE)]\n",
    "print(specific_tokens)\n",
    "# Filter the DataFrame for rows where the 'Token' column contains any of the specific tokens\n",
    "filtered_df = summary_df[summary_df['Token'].isin(specific_tokens)]\n",
    "\n",
    "print(filtered_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
