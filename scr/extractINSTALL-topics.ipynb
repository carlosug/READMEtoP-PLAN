{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A jupter notebook that crawl Readme.md files from paperwithcode using python\n",
    "# 1 Script to get the text from installation instructions of a readme file available in paperwithcode. For each file:\n",
    "# 2. It extracts the content (code comments and text comments) from the section \"Installation\" from the readme. Please extract the part of text that relates or match with the following: |installation|setup|install|how|Getting started/quick start|\n",
    "# 3. Create a dictionary with all the links and text per repository and output a csv file containing: url, text, tokenization of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "\n",
    "def getRepostitoryTopics(url, GitHub_Token, not_found):\n",
    "    header = {'Authorization': 'Bearer ' + GitHub_Token}\n",
    "    reposUrl = f\"https://api.github.com/repos/{url}\"\n",
    "    reposr = requests.get(reposUrl, headers = header)\n",
    "    reposj = reposr.json()\n",
    "    try:\n",
    "        topics = reposj[\"topics\"]\n",
    "        return (not_found, topics)\n",
    "    except:\n",
    "        return (not_found + 1, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_dict = {}\n",
    "GitHub_Token = \"YOUR-TOKEN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "listTopics = ['LLM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repositories_by_topic(topic):\n",
    "    header = {'Authorization': 'Bearer ' + GitHub_Token}\n",
    "    reposUrl = f\"https://api.github.com/search/repositories?q=topic:{topic}&per_page=50\"\n",
    "    reposr = requests.get(reposUrl, headers = header)\n",
    "    reposj = reposr.json()\n",
    "    return reposj[\"items\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_with_topics = {}\n",
    "for topic in listTopics:\n",
    "    repositories_json = get_repositories_by_topic(topic)\n",
    "    for repository in repositories_json:\n",
    "        topics = repository[\"topics\"]\n",
    "        combined_topics_string = '\\t'.join(topics)\n",
    "        if(not \"LLM\" in combined_topics_string):\n",
    "            urls_with_topics[repository[\"html_url\"]] = topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'https://github.com/ollama/ollama': ['go', 'golang', 'llama', 'llama2', 'llm', 'llms', 'mistral', 'ollama'], 'https://github.com/geekan/MetaGPT': ['agent', 'gpt', 'hacktoberfest', 'llm', 'metagpt', 'multi-agent'], 'https://github.com/StanGirard/quivr': ['ai', 'api', 'chatbot', 'chatgpt', 'database', 'docker', 'frontend', 'html', 'javascript', 'llm', 'openai', 'postgresql', 'privacy', 'rag', 'react', 'rest-api', 'security', 'typescript', 'vector', 'ycombinator'], 'https://github.com/run-llama/llama_index': ['agents', 'application', 'data', 'fine-tuning', 'framework', 'llamaindex', 'llm', 'rag', 'vector-database'], 'https://github.com/milvus-io/milvus': ['anns', 'cloud-native', 'distributed', 'embedding-database', 'embedding-similarity', 'embedding-store', 'faiss', 'golang', 'hnsw', 'image-search', 'llm', 'nearest-neighbor-search', 'tensor-database', 'vector-database', 'vector-search', 'vector-similarity', 'vector-store'], 'https://github.com/JushBJJ/Mr.-Ranedeer-AI-Tutor': ['ai', 'education', 'gpt-4', 'llm'], 'https://github.com/mlabonne/llm-course': ['course', 'large-language-models', 'llm', 'machine-learning', 'roadmap'], 'https://github.com/chatchat-space/Langchain-Chatchat': ['chatbot', 'chatchat', 'chatglm', 'chatglm-6b', 'chatglm2-6b', 'chatgpt', 'embedding', 'faiss', 'fastchat', 'gpt', 'knowledge-base', 'langchain', 'langchain-chatchat', 'langchain-chatglm', 'llama', 'llm', 'milvus', 'pgvector', 'streamlit', 'text2vec'], 'https://github.com/zhayujie/chatgpt-on-wechat': ['ai', 'chatgpt', 'dingtalk', 'feishu-bot', 'gemini', 'gpt-4', 'linkai', 'llm', 'openai', 'python3', 'qwen', 'rag', 'wechat', 'wechat-bot', 'wenxinyiyan', 'xunfei-spark'], 'https://github.com/FlowiseAI/Flowise': ['artificial-intelligence', 'chatgpt', 'javascript', 'large-language-models', 'llm', 'low-code', 'no-code', 'react', 'typescript'], 'https://github.com/mindsdb/mindsdb': ['ai', 'ai-agents', 'artificial-intelligence', 'auto-gpt', 'chatbot', 'database', 'forecasting', 'gpt', 'gpt4all', 'hacktoberfest', 'huggingface', 'llm', 'machine-learning', 'ml', 'mongodb', 'mysql', 'postgres', 'semantic-search', 'timeseries'], 'https://github.com/microsoft/unilm': ['beit', 'beit-3', 'deepnet', 'document-ai', 'foundation-models', 'kosmos', 'kosmos-1', 'layoutlm', 'layoutxlm', 'llm', 'minilm', 'mllm', 'multimodal', 'nlp', 'pre-trained-model', 'textdiffuser', 'trocr', 'unilm', 'xlm-e'], 'https://github.com/microsoft/semantic-kernel': ['ai', 'artificial-intelligence', 'llm', 'openai', 'sdk'], 'https://github.com/ymcui/Chinese-LLaMA-Alpaca': ['alpaca', 'alpaca-2', 'large-language-models', 'llama', 'llama-2', 'llm', 'lora', 'nlp', 'plm', 'pre-trained-language-models', 'quantization'], 'https://github.com/mudler/LocalAI': ['ai', 'alpaca', 'api', 'api-rest', 'bloom', 'containers', 'coqui', 'falcon', 'gpt-neox', 'gpt4all', 'guanaco', 'kubernetes', 'llama', 'llm', 'mamba', 'musicgen', 'rwkv', 'stable-diffusion', 'tts', 'vicuna'], 'https://github.com/mlc-ai/mlc-llm': ['language-model', 'llm', 'machine-learning-compilation', 'tvm'], 'https://github.com/THUDM/ChatGLM2-6B': ['chatglm', 'chatglm-6b', 'large-language-models', 'llm'], 'https://github.com/langgenius/dify': ['ai', 'backend-as-a-service', 'gpt', 'gpt-4', 'langchain', 'llama2', 'llm', 'openai', 'orchestration', 'python', 'rag'], 'https://github.com/vllm-project/vllm': ['gpt', 'inference', 'llama', 'llm', 'llm-serving', 'llmops', 'mlops', 'model-serving', 'pytorch', 'transformer'], 'https://github.com/TransformerOptimus/SuperAGI': ['agents', 'agi', 'ai', 'artificial-general-intelligence', 'artificial-intelligence', 'autonomous-agents', 'gpt-4', 'hacktoberfest', 'llm', 'llmops', 'nextjs', 'openai', 'pinecone', 'python', 'superagi'], 'https://github.com/cocktailpeanut/dalai': ['ai', 'llama', 'llm'], 'https://github.com/huggingface/peft': ['adapter', 'diffusion', 'llm', 'lora', 'parameter-efficient-learning', 'python', 'pytorch', 'transformers'], 'https://github.com/botpress/botpress': ['agent', 'ai', 'botpress', 'chatbot', 'chatgpt', 'gpt', 'gpt-4', 'langchain', 'llm', 'nlp', 'openai', 'prompt'], 'https://github.com/hiyouga/LLaMA-Factory': ['agent', 'baichuan', 'chatglm', 'fine-tuning', 'generative-ai', 'gpt', 'instruction-tuning', 'language-model', 'large-language-models', 'llama', 'llm', 'lora', 'mistral', 'mixture-of-experts', 'peft', 'qlora', 'quantization', 'qwen', 'rlhf', 'transformers'], 'https://github.com/PaddlePaddle/PaddleNLP': ['bert', 'compression', 'distributed-training', 'document-intelligence', 'embedding', 'ernie', 'information-extraction', 'llama', 'llm', 'neural-search', 'nlp', 'paddlenlp', 'pretrained-models', 'question-answering', 'search-engine', 'semantic-analysis', 'sentiment-analysis', 'transformers', 'uie'], 'https://github.com/ludwig-ai/ludwig': ['computer-vision', 'data-centric', 'data-science', 'deep', 'deep-learning', 'deeplearning', 'fine-tuning', 'learning', 'llama', 'llama2', 'llm', 'llm-training', 'machine-learning', 'machinelearning', 'mistral', 'ml', 'natural-language', 'natural-language-processing', 'neural-network', 'pytorch'], 'https://github.com/getumbrel/llama-gpt': ['ai', 'chatgpt', 'code-llama', 'codellama', 'gpt', 'gpt-4', 'gpt4all', 'llama', 'llama-2', 'llama-cpp', 'llama2', 'llamacpp', 'llm', 'localai', 'openai', 'self-hosted'], 'https://github.com/eosphoros-ai/DB-GPT': ['agents', 'bgi', 'database', 'gpt', 'gpt-4', 'langchain', 'llm', 'private', 'rag', 'security', 'vicuna'], 'https://github.com/gventuri/pandas-ai': ['ai', 'csv', 'data', 'data-analysis', 'data-science', 'gpt-3', 'gpt-4', 'llm', 'pandas', 'sql'], 'https://github.com/h2oai/h2ogpt': ['ai', 'chatgpt', 'embeddings', 'generative', 'gpt', 'gpt4all', 'llama2', 'llm', 'mixtral', 'pdf', 'private', 'privategpt', 'vectorstore'], 'https://github.com/labring/FastGPT': ['gpt', 'gpt-35-turbo', 'gpt-4', 'gpt35', 'llm', 'nextjs', 'openai', 'rag', 'react'], 'https://github.com/eugeneyan/open-llms': ['commercial', 'large-language-models', 'llm', 'llms'], 'https://github.com/ShishirPatil/gorilla': ['api', 'api-documentation', 'chatgpt', 'claude-api', 'gpt-4-api', 'llm', 'openai-api', 'openai-functions'], 'https://github.com/QwenLM/Qwen': ['chinese', 'flash-attention', 'large-language-models', 'llm', 'natural-language-processing', 'pretrained-models'], 'https://github.com/mlc-ai/web-llm': ['chatgpt', 'deep-learning', 'language-model', 'llm', 'tvm', 'webgpu', 'webml'], 'https://github.com/nebuly-ai/nebuly': ['ai', 'analytics', 'artificial-intelligence', 'deeplearning', 'large-language-models', 'llm'], 'https://github.com/LlamaFamily/Llama2-Chinese': ['finetune', 'llama', 'llama2', 'llm', 'lora', 'pretrain'], 'https://github.com/bentoml/OpenLLM': ['ai', 'bentoml', 'falcon', 'fine-tuning', 'llama', 'llama2', 'llm', 'llm-inference', 'llm-ops', 'llm-serving', 'llmops', 'mistral', 'ml', 'mlops', 'model-inference', 'mpt', 'open-source-llm', 'openllm', 'stablelm', 'vicuna'], 'https://github.com/cpacker/MemGPT': ['chat', 'chatbot', 'gpt', 'gpt-4', 'llm', 'llm-agent'], 'https://github.com/RUCAIBox/LLMSurvey': ['chain-of-thought', 'chatgpt', 'in-context-learning', 'instruction-tuning', 'large-language-models', 'llm', 'llms', 'natural-language-processing', 'pre-trained-language-models', 'pre-training', 'rlhf'], 'https://github.com/activeloopai/deeplake': ['ai', 'computer-vision', 'cv', 'data-science', 'data-version-control', 'datalake', 'datasets', 'deep-learning', 'image-processing', 'langchain', 'large-language-models', 'llm', 'machine-learning', 'ml', 'mlops', 'python', 'pytorch', 'tensorflow', 'vector-database', 'vector-search'], 'https://github.com/stas00/ml-engineering': ['ai', 'bash', 'large-language-models', 'llm', 'machine-learning', 'machine-learning-engineering', 'make', 'mlops', 'python', 'pytorch', 'scalability', 'slurm', 'transformers'], 'https://github.com/embedchain/embedchain': ['ai', 'application', 'chatbots', 'chatgpt', 'embeddings', 'llm', 'python', 'rag', 'vector-database'], 'https://github.com/microsoft/TypeChat': ['ai', 'llm', 'natural-language', 'types'], 'https://github.com/mistralai/mistral-src': ['llm', 'llm-inference', 'mistralai'], 'https://github.com/microsoft/promptflow': ['ai', 'ai-application-development', 'ai-applications', 'chatgpt', 'gpt', 'llm', 'prompt', 'prompt-engineering'], 'https://github.com/TheR1D/shell_gpt': ['chatgpt', 'cheat-sheet', 'cli', 'commands', 'gpt-3', 'gpt-4', 'linux', 'llm', 'openai', 'productivity', 'python', 'shell', 'terminal'], 'https://github.com/rasbt/LLMs-from-scratch': ['chatgpt', 'gpt', 'large-language-models', 'llm', 'python', 'pytorch'], 'https://github.com/sweepai/sweep': ['ai', 'code-assistant', 'code-search', 'developer-tools', 'gen-ai', 'github-app', 'gpt-35-turbo', 'gpt-4-32k', 'llm'], 'https://github.com/continuedev/continue': ['ai', 'chatgpt', 'copilot', 'developer-tools', 'intellij', 'jetbrains', 'llm', 'open-source', 'openai', 'pycharm', 'software-development', 'visual-studio-code', 'vscode']}\n"
     ]
    }
   ],
   "source": [
    "print(urls_with_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import json\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def fetch_readme_content(repo_url):\n",
    "    readme_url = repo_url.replace(\"github.com\", \"raw.githubusercontent.com\") + \"/main/README.md\"\n",
    "    response = requests.get(readme_url)\n",
    "    return response.text if response.status_code == 200 else None\n",
    "\n",
    "def extract_installation_instructions(readme_content):\n",
    "    keywords = [\"installation\", \"setup\", \"install\", \"how to\", \"getting started\", \"quick start\"]\n",
    "    pattern = re.compile(\"|\".join(keywords), re.IGNORECASE)\n",
    "    sections = re.split(r'#+ ', readme_content)\n",
    "    installation_sections = [section for section in sections if pattern.search(section)]\n",
    "    return installation_sections\n",
    "\n",
    "def tokenize_text(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "def classify_complexity(text):\n",
    "    complexity = -1  # Default complexity\n",
    "    if any(word in text for word in [\"pip install\", \"package manager install\"]):\n",
    "        complexity = 0\n",
    "    elif any(word in text for word in [\"container\", \"docker container\", \"docker compose up\"]):\n",
    "        complexity = 1\n",
    "    elif any(word in text for word in [\"from source\", \"git clone\", \".git\"]):\n",
    "        complexity = 2\n",
    "    return complexity\n",
    "\n",
    "# Iterate through the URLs and perform the tasks\n",
    "output_data = []\n",
    "\n",
    "for url, topics in urls_with_topics.items():\n",
    "    readme_url = url.replace(\"github.com\", \"raw.githubusercontent.com\") + \"/main/README.md\"  # Define readme_url for each repository\n",
    "    readme_content = fetch_readme_content(url)\n",
    "    if readme_content:\n",
    "        installation_instructions = extract_installation_instructions(readme_content)\n",
    "        for instruction in installation_instructions:\n",
    "            tokens = tokenize_text(instruction)\n",
    "            complexity = classify_complexity(instruction)\n",
    "            output_data.append({\n",
    "                \"url\": url,\n",
    "                \"readme_url\": readme_url,\n",
    "                \"topic\": topics,\n",
    "                \"text\": instruction,\n",
    "                \"token\": tokens,\n",
    "                \"level of complexity\": complexity\n",
    "            })\n",
    "\n",
    "# Output to a JSON file\n",
    "with open('data/corpus-topic.json', 'w') as outfile:\n",
    "    json.dump(output_data, outfile, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
