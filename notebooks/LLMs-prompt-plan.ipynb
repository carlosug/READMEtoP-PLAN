{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gpt4all openai -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example for validation ground_true**\n",
    "\n",
    "```json\n",
    "           {\n",
    "                \"id\": \"6\",\n",
    "                \"name\": \"PFischbeck/parameter-fitting-experiments\",\n",
    "                \"url\": \"https://raw.githubusercontent.com/PFischbeck/parameter-fitting-experiments/main/Readme.md\",\n",
    "                \"n_plans\": 2,\n",
    "                \"plan_nodes\": [\n",
    "                    {\n",
    "                        \"type\": \"Source\",\n",
    "                        \"plan_step\": [\n",
    "                            \"Step 1: Make sure you have Python, Pip and R installed.\",\n",
    "                            \"Step 2: Install the `pygirgs` package at https://github.com/PFischbeck/pygirgs.\",\n",
    "                            \"Step 3: Install the R dependencies (used for plots).\",\n",
    "                            \"Step 4: Checkout the repository.\",\n",
    "                            \"Step 5: Install the python dependencies.\",\n",
    "                            \"Step 6: Download the file at https://doi.org/10.5281/zenodo.10629451.\",\n",
    "                            \"Step 7: Extract the content\",\n",
    "                            \"Step 8: Place it into the folder `input_data/konect`\"\n",
    "                        ],\n",
    "                        \"commands\": [\n",
    "                            \"\",\n",
    "                            \"\",\n",
    "                            \"R -e 'install.packages(c(ggplot2\", \"reshape2\", \"plyr\", \"dplyr\", \"scales), repos=https://cloud.r-project.org/\",\n",
    "                            \"\",\n",
    "                            \"pip3 install -r requirements.txt\",\n",
    "                            \"\",\n",
    "                            \"\",\n",
    "                            \"\"\n",
    "                        ]\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"Binary\",\n",
    "                        \"plan_step\": [\n",
    "                            \"Step 1(Optional):Download the file `output-data.zip` from (https://doi.org/10.5281/zenodo.10629451)\",\n",
    "                            \"Step 2: extract its contents into the folder `output_data`.\"\n",
    "                        ]\n",
    "                    }\n",
    "                ],\n",
    "                \"readme_instructions\": \"\",\n",
    "                \"type\": \"easy\"\n",
    "            },\n",
    "``````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai\n",
    "import config\n",
    "api_key = config.API_KEY\n",
    "\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. - TYPE OF PLANS PROMPT\n",
    "\n",
    "#### Baseline Zero Shot\n",
    "```py\n",
    "prompt_TEXT = \"\"\" Given a INSTALL_TEXT, detect the class of plan for the installation of a software.\"\"\"\n",
    "prompt_URL =  \"\"\" Given a INSTALL_TEXT, detect the class of plan for the installation of a software.\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**GEMMA: Gemini-based open model**\n",
    "\n",
    "ref:\n",
    "[https://storage.googleapis.com/deepmind-media/gemma/gemma-report.pdf](https://storage.googleapis.com/deepmind-media/gemma/gemma-report.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a URL (no labels), Natural language response\n",
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "    base_url=\"https://api-inference.huggingface.co/v1\",\n",
    "    api_key= api_key # your key hf\n",
    ")\n",
    "MODEL = \"google/gemma-7b-it\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code_completion(messages, max_tokens=512, model=MODEL):\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=messages,\n",
    "        model=model,\n",
    "        max_tokens=max_tokens,\n",
    "        # stop=[\n",
    "        #     \"<step>\"\n",
    "        # ],\n",
    "        # frequency_penalty=1,\n",
    "        # presence_penalty=1,\n",
    "        # top_p=0.7,\n",
    "        # n=10,\n",
    "        # temperature=1,\n",
    "    )\n",
    "\n",
    "    return chat_completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = config.API_KEY\n",
    "SYSTEM_PROMPT = \"You are a smart and intelligent Named Entity Recognition (NER) system. I will provide you some task to identify entities in a text\"\n",
    "USER_PROMPT_1 = \"Detect the TYPE of plan for the installation of a software in the README_INSTALLATION.\"\n",
    "ASSISTANT_PROMPT_1 = \"Sure, I'm ready to help you with your NER task. Please provide me with the necessary information\"\n",
    "GUIDELINES_PROMPT = (\n",
    "    \"Entity Definition:\\n\"\n",
    "    \"1. README_INSTALLATION: a excerpt of the text found in a readme file of a research software tool\"\n",
    "    \"2. TYPE: represents the concept of a installation method type as a plan, which is composed of steps, which must be executed in a given order. A installation method is an instance of the Plan concept. There are four type of plans: binary, package manager, source and container. A research software readme installation instruction could refer to one or multiple methods\\n\"\n",
    "    \"3. PLAN_STEP: represents a list of planned action(s) as part of a Plan to be executed by an Agent. These are a list of indivisible sequence of actions that must executed without interruption. Step within a Plan could be linked to one specific executable operation, or refer to a group of operations. A Step then could invoke more than one action. Each sentence in a readme is an instance of the Step concept.\\n\"\n",
    "    \"4. TECHNOLOGY: repesents the concept of a particular operating sytem or package management correspoding to a particular set of PLAN_STEPs in a specific TYPE.\\n\"\n",
    "    \"5. N_PLANS: count the number of unique plan TYPE\"\n",
    "    \"\\n\"\n",
    "    \"Output Format:\\n\"\n",
    "    \"{{'TYPE': [name of the TYPE plans present], 'PLAN_STEP': [list of steps], 'TECHNOLOGY': [name of the technology used for that specific TYPE], 'N_PLANS': [number of unique plan TYPE]}}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, the class of plan for the installation of the software in the text of the README is:\n",
      "\n",
      "**Package Manager**\n",
      "\n",
      "The text describes an installation plan that uses a package manager to install dependencies.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "        {\"role\": \"user\", \"content\": \"Behave as an expert labeler. \\\n",
    "          Given a README, detect the class of plan for the installation of a software in the text of the. \\n Definition:\\n 1. README_INSTALLATION: a excerpt of the text found in a readme file of a research software tool \\n 2. TYPE: represents the concept of a installation method type as a plan, which is composed of steps, which must be executed in a given order. A installation method is an instance of the Plan concept. There are four type of plans: binary, package manager, source and container. A research software readme installation instruction could refer to one or multiple methods\\n 3. PLAN_STEP: represents a list of planned action(s) as part of a Plan to be executed by an Agent. These are a list of indivisible sequence of actions that must executed without interruption. Step within a Plan could be linked to one specific executable operation, or refer to a group of operations. A Step then could invoke more than one action. Each sentence in a readme is an instance of the Step concept.\\n 4. TECHNOLOGY: repesents the concept of a particular operating sytem or package management correspoding to a particular set of PLAN_STEPs in a specific TYPE.\\n 5. N_PLANS: count the number of unique plan TYPE \\n README = # Installation - Make sure you have Python, Pip and R installed. - Checkout this repository - Install the python dependencies with ```pip3 install -r requirements.txt``` - Install the `pygirgs` package at https://github.com/PFischbeck/pygirgs \\ - Install the R dependencies (used for plots) with  ```R -e install.packages(c(ggplot2, reshape2, plyr, dplyr, scales), repos=https://cloud.r-project.org/) Download the file `konect-data.zip` from [Zenodo](https://doi.org/10.5281/zenodo.10629451) and extract its contents into the folder `input_data/konect` Optional: Download the file `output-data.zip` from [Zenodo](https://doi.org/10.5281/zenodo.10629451) and extract its contents into the folder `output_data`. This way, you can access all experiment results without running them yourself. The Output Format in JSON file:\\n {{'TYPE': [name of the TYPE plans present], 'PLAN_STEP': [list of steps], 'TECHNOLOGY': [name of the technology used for that specific TYPE], 'N_PLANS': [number of unique plan TYPE]}} \\\n",
    "         \"},\n",
    "]\n",
    "\n",
    "chat_completion = get_code_completion(messages)\n",
    "            \n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**URL:**  raw.githubusercontent.com/PFischbeck/parameter-fitting-experiments/main/Readme.md\n",
      "\n",
      "**Class of plan:** Software installation plan\n",
      "\n",
      "**Reasoning:**\n",
      "\n",
      "The text of the URL contains the following clues that indicate it is for a software installation plan:\n",
      "\n",
      "* **.md** file extension, which is commonly used for Markdown files, which are often used to document software installation instructions.\n",
      "* **\"Readme.md\"** file name, which is a convention for the main documentation file for a project.\n",
      "* **\"parameter-fitting-experiments\"** repository name, which suggests the software is related to data science or machine learning.\n",
      "* **\"Install\"** word in the URL, which is a common keyword used in installation instructions.\n",
      "\n",
      "**Therefore, based on the text of the URL, the class of plan for the installation of software in this case is software installation plan.**<eos>"
     ]
    }
   ],
   "source": [
    "# Given a URL (no labels), Natural language response\n",
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "    base_url=\"https://api-inference.huggingface.co/v1\",\n",
    "    api_key= api_key # your key hf\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"google/gemma-7b-it\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Behave as an expert labeler. \\\n",
    "          Given a URL, detect the class of plan for the installation of a software in the text of the URL. URL = https://raw.githubusercontent.com/PFischbeck/parameter-fitting-experiments/main/Readme.md\"},        \n",
    "    ],\n",
    "    stream=True,\n",
    "    max_tokens=500\n",
    ")\n",
    "\n",
    "for message in chat_completion:\n",
    "    print(message.choices[0].delta.content, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the label for the plan class of the installation of the software in the text of the URL:\n",
      "\n",
      "URL:  https://raw.githubusercontent.com/PFischbeck/parameter-fitting-experiments/main/Readme.md\n",
      "\n",
      "The text of the URL does not describe any software installation process or plan details, therefore I cannot detect the class of plan for the installation of the software in the text of the URL.<eos>"
     ]
    }
   ],
   "source": [
    "# Given a URL (with labels), natural language\n",
    "client = OpenAI(\n",
    "    base_url=\"https://api-inference.huggingface.co/v1\",\n",
    "    api_key= api_key\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"google/gemma-7b-it\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Behave as an expert labeler. \\\n",
    "          Given a URL, detect the class of plan for the installation of a software in the text of the URL. \\\n",
    "         The label can only be 1 of the 4 class of plans which are binary, package manager, container and source.\\\n",
    "         URL = https://raw.githubusercontent.com/PFischbeck/parameter-fitting-experiments/main/Readme.md\"},        \n",
    "    ],\n",
    "    stream=True,\n",
    "    max_tokens=500\n",
    ")\n",
    "\n",
    "for message in chat_completion:\n",
    "    print(message.choices[0].delta.content, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Plan Class Detection\n",
      "\n",
      "Based on the provided text, the class of the plan for installing software is **shell script**. \n",
      "\n",
      "Here's why:\n",
      "\n",
      "* **INSTALL_TEXT** clearly describes a process of installing software via shell commands.\n",
      "* The text primarily focuses on installing Python, Pip, R, `pygirgs`, and dependencies.\n",
      "* The text does not involve any steps related to other types of software installation methods, such as graphical interfaces or package managers.\n",
      "* Therefore, based on the content and purpose of the text, it is most likely to be a shell script plan.<eos>"
     ]
    }
   ],
   "source": [
    "# Given a INSTALL_TEXT (no labels), natural language\n",
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "    base_url=\"https://api-inference.huggingface.co/v1\",\n",
    "    api_key= api_key\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"google/gemma-7b-it\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Behave as an expert labeler. \\\n",
    "          Given a INSTALL_TEXT, detect the class of plan for the installation of a software. \\\n",
    "         INSTALL_TEXT = # Installation - Make sure you have Python, Pip and R installed. - Checkout this repository - Install the python dependencies with \\\n",
    "         ```pip3 install -r requirements.txt``` \\\n",
    "         - Install the `pygirgs` package at https://github.com/PFischbeck/pygirgs \\\n",
    "         - Install the R dependencies (used for plots) with \\\n",
    "         ```R -e 'install.packages(c(ggplot2, reshape2, plyr, dplyr, scales), repos=https://cloud.r-project.org/)'``` \\\n",
    "         - Download the file `konect-data.zip` from [Zenodo](https://doi.org/10.5281/zenodo.10629451) and extract its contents into the folder `input_data/konect` \\\n",
    "         - Optional: Download the file `output-data.zip` from [Zenodo](https://doi.org/10.5281/zenodo.10629451) and extract its contents into the folder `output_data`. This way, you can access all experiment results without running them yourself.\"},        \n",
    "    ],\n",
    "    stream=True,\n",
    "    max_tokens=500,\n",
    ")\n",
    "\n",
    "for message in chat_completion:\n",
    "    print(message.choices[0].delta.content, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**INSTALL_TEXT:**\n",
      "\n",
      "# Installation - Make sure you have Python, Pip and R installed. - Checkout this repository - Install the python dependencies with `pip3 install -r requirements.txt` - Install the `pygirgs` package at https://github.com/PFischbeck/pygirgs - Install the R dependencies (used for plots) with `R -e 'install.packages(c(ggplot2, reshape2, plyr, dplyr, scales), repos=https://cloud.r-project.org/)'` - Download the file `konect-data.zip` from [Zenodo](https://doi.org/10.5281/zenodo.10629451) and extract its contents into the folder `input_data/konect` - Optional: Download the file `output-data.zip` from [Zenodo](https://doi.org/10.5281/zenodo.10629451) and extract its contents into the folder `output_data`. This way, you can access all experiment results without running them yourself.\n",
      "\n",
      "**Class of plan:**\n",
      "\n",
      "This text describes a plan that involves installing software dependencies using `pip` and `R` package manager. Therefore, the class of plan is **package manager**.<eos>"
     ]
    }
   ],
   "source": [
    "# Given a Install_text (with labels), natural language response\n",
    "client = OpenAI(\n",
    "    base_url=\"https://api-inference.huggingface.co/v1\",\n",
    "    api_key= \"\"\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"google/gemma-7b-it\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Behave as an expert labeler. \\\n",
    "          Given a INSTALL_TEXT, print the INSTALL_TEXT and detect the class of plan for the installation of a software. \\\n",
    "         The label can only be 1 of the 4 class of plans which are binary, package manager, container and source. \\\n",
    "         INSTALL_TEXT = # Installation - Make sure you have Python, Pip and R installed. - Checkout this repository - Install the python dependencies with \\\n",
    "         ```pip3 install -r requirements.txt``` \\\n",
    "         - Install the `pygirgs` package at https://github.com/PFischbeck/pygirgs \\\n",
    "         - Install the R dependencies (used for plots) with \\\n",
    "         ```R -e 'install.packages(c(ggplot2, reshape2, plyr, dplyr, scales), repos=https://cloud.r-project.org/)'``` \\\n",
    "         - Download the file `konect-data.zip` from [Zenodo](https://doi.org/10.5281/zenodo.10629451) and extract its contents into the folder `input_data/konect` \\\n",
    "         - Optional: Download the file `output-data.zip` from [Zenodo](https://doi.org/10.5281/zenodo.10629451) and extract its contents into the folder `output_data`. This way, you can access all experiment results without running them yourself.\"},        \n",
    "    ],\n",
    "    stream=True,\n",
    "    max_tokens=500,\n",
    ")\n",
    "\n",
    "for message in chat_completion:\n",
    "    print(message.choices[0].delta.content, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Mistral orca-2 Model**\n",
    "\n",
    "ref: [mistral-7b-openorca.gguf2.Q4_0.gguf](mistral-7b-openorca.gguf2.Q4_0.gguf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gpt4all._pyllmodel:LLModel.prompt_model -- prompt:\n",
      "### System:\n",
      "You are an AI assistant that follows instruction extremely well. Help as much as you can.\n",
      "\n",
      "### User:\n",
      "Behave as an expert labeler. \\ Given the indicated URL, detect the class of plan for the installation of a software in the text of the URL.    The output can only be 1 of the 4 class of plans which are binary, package manager, container and source.     URL: https://raw.githubusercontent.com/PFischbeck/parameter-fitting-experiments/main/Readme.md\n",
      "### Response:\n",
      "\n",
      "===/LLModel.prompt_model -- prompt/===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESPONSE  The URL indicates that the installation plan is for a software that uses a package manager. Therefore, the output is \"package manager\".\n"
     ]
    }
   ],
   "source": [
    "from gpt4all import GPT4All\n",
    "model = GPT4All(\"orca-mini-3b-gguf2-q4_0.gguf\")\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "with model.chat_session():\n",
    "    prompt = 'Behave as an expert labeler. \\ Given the indicated URL, detect the class of plan for the installation of a software in the text of the URL.\\\n",
    "    The output can only be 1 of the 4 class of plans which are binary, package manager, container and source. \\\n",
    "    URL: https://raw.githubusercontent.com/PFischbeck/parameter-fitting-experiments/main/Readme.md'\n",
    "    # print(\"PROMPT: \", prompt)\n",
    "    response = model.generate(prompt=prompt, temp=0)\n",
    "    print(\"RESPONSE\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gpt4all._pyllmodel:LLModel.prompt_model -- prompt:\n",
      "### System:\n",
      "You are an AI assistant that follows instruction extremely well. Help as much as you can.\n",
      "\n",
      "### User:\n",
      "Behave as an expert labeler. \\ Given the indicated INSTALL_TEXT, please identify the class of plan of installation.    The output can only be 1 of the 4 class of plans which are binary, package manager, container and source.     INSTALL_TEXT = # Installation - Make sure you have Python, Pip and R installed. - Checkout this repository - Install the python dependencies with          ```pip3 install -r requirements.txt```          - Install the `pygirgs` package at https://github.com/PFischbeck/pygirgs          - Install the R dependencies (used for plots) with  ```R -e install.packages(c(ggplot2, reshape2, plyr, dplyr, scales), repos=https://cloud.r-project.org/)           Download the file `konect-data.zip` from [Zenodo](https://doi.org/10.5281/zenodo.10629451) and extract its contents into the folder `input_data/konect`             Optional: Download the file `output-data.zip` from [Zenodo](https://doi.org/10.5281/zenodo.10629451) and extract its contents into the folder `output_data`. This way, you can access all experiment results without running them yourself.\n",
      "### Response:\n",
      "\n",
      "===/LLModel.prompt_model -- prompt/===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT:  Behave as an expert labeler. \\ Given the indicated INSTALL_TEXT, please identify the class of plan of installation.    The output can only be 1 of the 4 class of plans which are binary, package manager, container and source.     INSTALL_TEXT = # Installation - Make sure you have Python, Pip and R installed. - Checkout this repository - Install the python dependencies with          ```pip3 install -r requirements.txt```          - Install the `pygirgs` package at https://github.com/PFischbeck/pygirgs          - Install the R dependencies (used for plots) with  ```R -e install.packages(c(ggplot2, reshape2, plyr, dplyr, scales), repos=https://cloud.r-project.org/)           Download the file `konect-data.zip` from [Zenodo](https://doi.org/10.5281/zenodo.10629451) and extract its contents into the folder `input_data/konect`             Optional: Download the file `output-data.zip` from [Zenodo](https://doi.org/10.5281/zenodo.10629451) and extract its contents into the folder `output_data`. This way, you can access all experiment results without running them yourself.\n",
      "Response  The class of plan of installation is package manager.\n"
     ]
    }
   ],
   "source": [
    "from gpt4all import GPT4All\n",
    "model = GPT4All(\"orca-mini-3b-gguf2-q4_0.gguf\")\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "with model.chat_session():\n",
    "    prompt = 'Behave as an expert labeler. \\ Given the indicated INSTALL_TEXT, please identify the class of plan of installation.\\\n",
    "    The output can only be 1 of the 4 class of plans which are binary, package manager, container and source. \\\n",
    "    INSTALL_TEXT = # Installation - Make sure you have Python, Pip and R installed. - Checkout this repository - Install the python dependencies with \\\n",
    "         ```pip3 install -r requirements.txt``` \\\n",
    "         - Install the `pygirgs` package at https://github.com/PFischbeck/pygirgs \\\n",
    "         - Install the R dependencies (used for plots) with  ```R -e install.packages(c(ggplot2, reshape2, plyr, dplyr, scales), repos=https://cloud.r-project.org/) \\\n",
    "          Download the file `konect-data.zip` from [Zenodo](https://doi.org/10.5281/zenodo.10629451) and extract its contents into the folder `input_data/konect` \\\n",
    "            Optional: Download the file `output-data.zip` from [Zenodo](https://doi.org/10.5281/zenodo.10629451) and extract its contents into the folder `output_data`. This way, you can access all experiment results without running them yourself.'\n",
    "         \n",
    "    print(\"PROMPT: \", prompt)\n",
    "    response = model.generate(prompt=prompt, temp=0)\n",
    "    print(\"Response\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One Shot Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chain of Thought Prompting**\n",
    "\n",
    "\n",
    "In addition to the four experiments above, we look at a fifth experiment using a state tracking chain of thought prompting technique in a natural language one shot setting. Within this configuration, we provide an annotated example where each action is annotated with the state prior to the action, the reason for why the action is applicable in the prior state, and the resulting state after applying the action. After the example, a meta-explanation about plan correctness is provided. The LLM is then asked to return a response making the same state tracking and justification annotations that were included in the example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. - LIST OF STEPS PROMPT\n",
    "\n",
    "#### Baseline Zero Shot\n",
    "```py\n",
    "prompt = \"\"\" Provide a detailed list of the Steps in the given Research Software which refers to \"[software-name]\" plan, including any optional or commands for each Step? \"\"\"\n",
    "```\n",
    "\n",
    "#### One Shot Learning:\n",
    "\n",
    "The prompt additionally contains an example instance of a research software installation plan (consisting of a description of the initial step and the end) and the corresponding plan (which ends with a tag, referred to as the plan-end tag, that denotes the end of the plan). The prompt is formatted in natural language (or **JSON/RDF format**?)\n",
    "\n",
    "**JSON**\n",
    "\n",
    "```py\n",
    "prompt = \"\"\"\\nGiven a TEXT, I want you generate task steps and plan type of installation.\\\n",
    "    The format must in a strict JSON format : {[{\"plan_type\": \"detect the method of installation\", \"task_steps\": [a ordered list of steps to install], \"commands\": [ a concise list of commands for the tool.  \\\n",
    "    If you do not find software installation steps in the TEXT, return \"none\".\\\n",
    "    Annotate the following TEXT  \"\"\"\n",
    "        prompt += \"\"\"\\n\\n# REQUIREMENTS #: \\n1. the generated task steps and plan types allign with # RESEARCH SOFTWARE TOOL # perfectly. Task name must be detected from the README file; \\n2. the task steps should strictly aligned with the plan type, and the number of task steps should be same with the readmes;  \\n4.  RESEARCH SOFTWARE TOOL command should be align with the input-type field of # TASK LIST #;\"\"\"\n",
    "```\n",
    "\n",
    "**ONTOLOGY**\n",
    "\n",
    "```py\n",
    "\n",
    "prompt = \"\"\" Here is the complete definition of the procedural RDF ontology in TTL format which defines Plans and Steps and relationships between each other:\n",
    "\n",
    "@prefix p-plan: <http://purl.org/net/p-plan#> .\n",
    "@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\n",
    "@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
    "@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n",
    "@prefix prov: <http://www.w3.org/ns/prov#> .\n",
    "@prefix bpmn: <http://www.w3.org/ns/bpmn#> .\n",
    "\n",
    "[.....]\n",
    "\n",
    "\n",
    "Using the provided ontology, please create specific instances and data about plans representing the steps and  for the [-] software installation procedure. Include relationships such as 'isStepOfPlan' to model the hierarchy of main steps and their substeps. Additionally, create the RDF graph that represents the defined individuals and their relationships.  Refer to the RDF graph as Context, please provide an Answer to the Question below.\"\"\"\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**GEMMA: Gemini-based open model**\n",
    "\n",
    "ref:\n",
    "[https://storage.googleapis.com/deepmind-media/gemma/gemma-report.pdf](https://storage.googleapis.com/deepmind-media/gemma/gemma-report.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- Baseline Zero Shot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Installation Steps for Parameter Fitting Experiments (URL: raw.githubusercontent.com/PFischbeck/parameter-fitting-experiments/main/Readme.md)\n",
      "\n",
      "**1. Set Up Environment:**\n",
      "- Python 3.6+\n",
      "- Jupyter Notebook or PyCharm\n",
      "- TensorFlow 2.0+\n",
      "\n",
      "**2. Install Dependencies:**\n",
      "- pip install tensorflow-gpu tf-keras keras-applications pyyaml tqdm matplotlib\n",
      "\n",
      "**3. Clone Repository:**\n",
      "- If you haven't already, clone the repository:\n",
      "```\n",
      "git clone git@github.com:PFischbeck/parameter-fitting-experiments.git\n",
      "```\n",
      "\n",
      "**4. Create a Virtual Environment:**\n",
      "- To isolate dependencies for the project, create a virtual environment and activate it.\n",
      "\n",
      "**5. Prepare Data:**\n",
      "- You may need to download the data used in the experiments. Download the data from the provided URL or mirror and place it in the `data` folder within the project directory.\n",
      "\n",
      "**6. Run the Experiment:**\n",
      "- After activating the virtual environment, navigate to the `experiments` folder in the project directory.\n",
      "- Select a specific experiment script from the available options. Some common scripts are:\n",
      "  - `parameter_tuning_cifar10_cnn.py` : Tuning a CNN model for CIFAR-10 dataset\n",
      "  - `parameter_tuning_imagenet_resnet.py` : Tuning a ResNet model for ImageNet dataset\n",
      "- Run the script using the following command:\n",
      "```\n",
      "python script.py\n",
      "```\n",
      "\n",
      "**Note:** The specific steps and commands may vary slightly depending on the chosen environment and script. Please refer to the readme file and the script itself for the most up-to-date instructions.<eos>"
     ]
    }
   ],
   "source": [
    "# Given a URL, Natural language response\n",
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "    base_url=\"https://api-inference.huggingface.co/v1\",\n",
    "    api_key= api_key\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"google/gemma-7b-it\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Behave as an expert labeler. \\\n",
    "          Given a URL, I want you generate a list of steps for the plan of installation. Please indicate the number of the steps. URL = https://raw.githubusercontent.com/PFischbeck/parameter-fitting-experiments/main/Readme.md\"},        \n",
    "    ],\n",
    "    stream=True,\n",
    "    max_tokens=500\n",
    ")\n",
    "\n",
    "for message in chat_completion:\n",
    "    print(message.choices[0].delta.content, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"PLAN_STEP\": [\n",
      "    \"Make sure you have Python, Pip and R installed.\",\n",
      "    \"Checkout this repository\",\n",
      "    \"Install the python dependencies with ```pip3 install -r requirements.txt```\",\n",
      "    \"Install the `pygirgs` package at https://github.com/PFischbeck/pygirgs\",\n",
      "    \"Install the R dependencies (used for plots) with  ```R -e install.packages(c(ggplot2, reshape2, plyr, dplyr, scales), repos=https://cloud.r-project.org/)\",\n",
      "    \"Download the file `konect-data.zip` from [Zenodo](https://doi.org/10.5281/zenodo.10629451) and extract its contents into the folder `input_data/konect`\",\n",
      "    \"Optional: Download the file `output-data.zip` from [Zenodo](https://doi.org/10.5281/zenodo.10629451) and extract its contents into the folder `output_data`\"\n",
      "  ],\n",
      "  \"NUM_STEP\": 8\n",
      "}\n",
      "```\n",
      "\n",
      "**Explanation:**\n",
      "\n",
      "- The `PLAN_STEP` list includes each step in the installation plan.\n",
      "- The number of unique steps is 8.\n",
      "- Each step is a separate action to be performed in sequence.\n",
      "- Some steps involve installing packages or downloading files, while others provide instructions for installing software or extracting files.<eos>"
     ]
    }
   ],
   "source": [
    "# given a URL, JSON object response\n",
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "    base_url=\"https://api-inference.huggingface.co/v1\",\n",
    "    api_key= api_key\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"google/gemma-7b-it\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Behave as an expert labeler. \\\n",
    "          Given a README_TEXT, \\\n",
    "          I want you generate a list of steps for the plan of installation. \\\n",
    "          Please indicate the number of the steps. The RESPONSE Format for your response should be in JSON file as following: \\\n",
    "         \\n {{'PLAN_STEP': [`Step 1: give a number of the step. Each step separated with commas], {{`NUM_STEP`: [count of unique steps]}}}} \\n \\\n",
    "         Definition:\\n 1. README_INSTALLATION: a excerpt of the text found in a readme file of a research software tool \\n 2.PLAN_STEP: represents a list of planned action(s) in sequential orden as part of a installation plan to be executed by an Agent. These are a list of indivisible sequence of actions that must executed without interruption. Step within a Plan could be linked to one specific executable operation, or refer to a group of operations. A Step then could invoke more than one action. Each sentence in a readme is an instance of the Step concept.\\n \\\n",
    "         3. N_PLANS: count the number of unique plan TYPE \\n. \\\n",
    "         Here is the README_TEXT = # Installation - Make sure you have Python, Pip and R installed. - Checkout this repository - Install the python dependencies with ```pip3 install -r requirements.txt``` - Install the `pygirgs` package at https://github.com/PFischbeck/pygirgs \\ - Install the R dependencies (used for plots) with  ```R -e install.packages(c(ggplot2, reshape2, plyr, dplyr, scales), repos=https://cloud.r-project.org/) Download the file `konect-data.zip` from [Zenodo](https://doi.org/10.5281/zenodo.10629451) and extract its contents into the folder `input_data/konect` Optional: Download the file `output-data.zip` from [Zenodo](https://doi.org/10.5281/zenodo.10629451) and extract its contents into the folder `output_data`. This way, you can access all experiment results without running them yourself.\"},\n",
    "    ],\n",
    "    stream=True,\n",
    "    max_tokens=500,\n",
    "    response_format={\"type\": \"json_object\"},\n",
    ")\n",
    "\n",
    "for message in chat_completion:\n",
    "    print(message.choices[0].delta.content, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\"plan_nodes\": [\n",
      "    {\n",
      "      \"num_steps\": \"4\",\n",
      "      \"plan_step\": [\n",
      "        \"Step 1: Make sure you have Python, Pip and R installed.\",\n",
      "        \"Step 2: Checkout this repository\",\n",
      "        \"Step 3: Install the python dependencies with `pip3 install -r requirements.txt`\",\n",
      "        \"Step 4: Install the `pygirgs` package and R dependencies (used for plots) with  ```R -e install.packages(c(ggplot2, reshape2, plyr, dplyr, scales), repos=https://cloud.r-project.org/)` \"\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```<eos>"
     ]
    }
   ],
   "source": [
    "# given a URL, JSON object response\n",
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "    base_url=\"https://api-inference.huggingface.co/v1\",\n",
    "    api_key= api_key\n",
    ")\n",
    "\n",
    "example_json = {\n",
    "  \"plan_nodes\": [\n",
    "                    {\n",
    "                        \"num_steps\": \"# total count number of unique steps\",\n",
    "                        \"plan_step\": [\n",
    "                            \"Step 1: # describe step 1:.\",\n",
    "                            \"Step 2: # describe step 2.\"\n",
    "                        ]\n",
    "                    }\n",
    "                ]\n",
    "}\n",
    "\n",
    "prompt= \"Given a README_TEXT, I want you generate a valid JSON output with the list of steps for the plan of installation. \\\n",
    "README_TEXT = # Installation - Make sure you have Python, Pip and R installed. - Checkout this repository - Install the python dependencies with ```pip3 install -r requirements.txt``` - Install the `pygirgs` package at https://github.com/PFischbeck/pygirgs \\ - Install the R dependencies (used for plots) with  ```R -e install.packages(c(ggplot2, reshape2, plyr, dplyr, scales), repos=https://cloud.r-project.org/) Download the file `konect-data.zip` from [Zenodo](https://doi.org/10.5281/zenodo.10629451) and extract its contents into the folder `input_data/konect` Optional: Download the file `output-data.zip` from [Zenodo](https://doi.org/10.5281/zenodo.10629451) and extract its contents into the folder `output_data`. This way, you can access all experiment results without running them yourself.\"\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"google/gemma-7b-it\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Provide output in valid JSON. The data schema should be like this:\"+json.dumps(example_json)},\n",
    "        { \"role\": \"system\", \"content\": prompt}\n",
    "    ],\n",
    "    stream=True,\n",
    "    max_tokens=500,\n",
    "    response_format={\"type\": \"json_object\"},\n",
    ")\n",
    "\n",
    "for message in chat_completion:\n",
    "    print(message.choices[0].delta.content, end=\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated JSON: {\n",
      "    \"plan_step\": [\n",
      "        \"```json\",\n",
      "        \"{'plan_nodes': [{'num_steps': 'float, # count number of unique steps', 'plan_step': [\",\n",
      "        \"'Make sure you have Python, Pip and R installed.',\",\n",
      "        \"'Checkout this repository',\",\n",
      "        \"'Install the python dependencies with `pip3 install -r requirements.txt`',\",\n",
      "        \"'Install the `pygirgs` package at <github.com/PFischbeck/pygirgs>',\",\n",
      "        \"'Install the R dependencies (used for plots) with  `R --vanilla CMD INSTALL ggplot2 reshape2 plyr dplyr scales`',\",\n",
      "        \"'Download the file `konect-data.zip` from [Zenodo](doi.org/10.5281/zenodo.10629451) and extract its contents into the folder `input_data/konect`',\",\n",
      "        \"'Optional: Download the file `output-data.zip` from [Zenodo](doi.org/10.5281/zenodo.10629451) and extract its contents into the folder `output_data`\",\n",
      "        \"]}]}\",\n",
      "        \"```\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "    base_url=\"https://api-inference.huggingface.co/v1\",\n",
    "    api_key= api_key\n",
    ")\n",
    "\n",
    "example_json = {\n",
    "  \"plan_nodes\": [\n",
    "                    {\n",
    "                        \"num_steps\": \"float, # count number of unique steps\",\n",
    "                        \"plan_step\": []\n",
    "                    }\n",
    "                ]\n",
    "}\n",
    "\n",
    "README_TEXT = \"# Installation - Make sure you have Python, Pip and R installed. - Checkout this repository - Install the python dependencies with `pip3 install -r requirements.txt ` - Install the `pygirgs` package at <https://github.com/PFischbeck/pygirgs> - Install the R dependencies (used for plots) with  `R --vanilla CMD INSTALL ggplot2 reshape2 plyr dplyr scales ` - Download the file `konect-data.zip` from [Zenodo](https://doi.org/10.5281/zenodo.10629451) and extract its contents into the folder `input_data/konect` \\nOptional: Download the file `output-data.zip` from [Zenodo](https://doi.org/10.5281/zenodo.10629451) and extract its contents into the folder `output_data`. This way, you can access all experiment results without running them yourself.\"\n",
    "\n",
    "# def create_json_response(plan_node):\n",
    "#     return {\n",
    "#       \"plan_nodes\": [\n",
    "#           {\n",
    "#               \"num_steps\": (plan_node[\"plan_step\"]),\n",
    "#               \"plan_step\": plan_node[\"plan_step\"]\n",
    "#           }\n",
    "#       ]\n",
    "#     }\n",
    "\n",
    "def extract_steps(text):\n",
    "    response = client.chat.completions.create(\n",
    "      model=\"google/gemma-7b-it\",\n",
    "      messages=[\n",
    "          {\"role\": \"user\", \"content\": \"You are a helpful assistant that extracts installation steps from a given README text.\"},\n",
    "          {\"role\": \"system\", \"content\": f\"Extract the installation in a JSON format as {example_json} steps from the following README text:\\n{text}\"}\n",
    "      ],\n",
    "    # stream=True,\n",
    "    max_tokens=500,\n",
    "    response_format={\"type\": \"json_object\"},  \n",
    "    )\n",
    "\n",
    "\n",
    "    steps = response.choices[0].message.content.strip().split('\\n')\n",
    "    plan_step = [step.strip() for step in steps if step.strip()]\n",
    "    return {\"plan_step\": plan_step}\n",
    "\n",
    "\n",
    "plan_node = extract_steps(README_TEXT)\n",
    "# final_json = create_json_response(plan_node)\n",
    "\n",
    "print(\"Generated JSON:\", json.dumps(plan_node, indent=4))\n",
    "\n",
    "\n",
    "with open('outputfile.json', 'w') as outf:\n",
    "    json.dump(plan_node, outf, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## JSON object for installing research software from the text:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"total_steps\": 6,\n",
      "  \"steps\": [\n",
      "    \"Make sure you have Python, Pip and R installed.\",\n",
      "    \"Checkout this repository\",\n",
      "    \"Install the python dependencies with `pip3 install -r requirements.txt`\",\n",
      "    \"Install the `pygirgs` package at https://github.com/PFischbeck/pygirgs\",\n",
      "    \"Install the R dependencies (used for plots) with `R -e 'install.packages(c(ggplot2, reshape2, plyr, dplyr, scales), repos=https://cloud.r-project.org/)'\",\n",
      "    \"Download the file `konect-data.zip` from [Zenodo](https://doi.org/10.5281/zenodo.10629451) and extract its contents into the folder `input_data/konect`. This way, you can access all experiment results without running them yourself. The file `output-data.zip` can be optionally downloaded and extracted into the folder `output_data`.\"\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "**Total number of steps:** 6<eos>"
     ]
    }
   ],
   "source": [
    "# Given a INSTALL_TEXT, JSON object response\n",
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "    base_url=\"https://api-inference.huggingface.co/v1\",\n",
    "    api_key= api_key\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"google/gemma-7b-it\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Behave as an expert labeler. \\\n",
    "          Given a INSTALL_TEXT, generate an example json object describing the Steps of installation of the Research Software. Please indicate the total number of the Steps. \\\n",
    "         INSTALL_TEXT = # Installation - Make sure you have Python, Pip and R installed. - Checkout this repository - Install the python dependencies with \\\n",
    "         ```pip3 install -r requirements.txt``` \\\n",
    "         - Install the `pygirgs` package at https://github.com/PFischbeck/pygirgs \\\n",
    "         - Install the R dependencies (used for plots) with \\\n",
    "         ```R -e 'install.packages(c(ggplot2, reshape2, plyr, dplyr, scales), repos=https://cloud.r-project.org/)'``` \\\n",
    "         - Download the file `konect-data.zip` from [Zenodo](https://doi.org/10.5281/zenodo.10629451) and extract its contents into the folder `input_data/konect` \\\n",
    "         - Optional: Download the file `output-data.zip` from [Zenodo](https://doi.org/10.5281/zenodo.10629451) and extract its contents into the folder `output_data`. This way, you can access all experiment results without running them yourself.\"},        \n",
    "    ],\n",
    "    stream=True,\n",
    "    max_tokens=500,\n",
    "    response_format={\"type\": \"json_object\"},\n",
    ")\n",
    "\n",
    "for message in chat_completion:\n",
    "    print(message.choices[0].delta.content, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mistral orca-2 Model**\n",
    "\n",
    "ref: [mistral-7b-openorca.gguf2.Q4_0.gguf](mistral-7b-openorca.gguf2.Q4_0.gguf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gpt4all._pyllmodel:LLModel.prompt_model -- prompt:\n",
      "You are an expert label.\n",
      "Be terse.\n",
      "\n",
      "### Instruction:\n",
      " Given a TEXT, I want you generate task steps and plan type of installation.    The format must in a strict JSON format : {[{\"plan_type\": \"detect the method of installation\", \"task_steps\": [a ordered list of steps to install], \"commands\": [ a concise list of commands for the tool.      If you do not find software installation steps in the TEXT, return \"none\".    Annotate the following TEXT: # Installation ### Dependencies Initialize git submodules with `` git submodule init git submodule update```     Install the specific versions of every package from `requirements.txt` in a new conda environment:    conda create --name gsft python=3.9     conda activate gsft    pip install -r requirements.txt    To ensure that Python paths are properly defined, update the `~/.bashrc` by adding the following lines    export GSFT_PATH=/path_to_gsfc    export PYTHONPATH=$PYTHONPATH:/$GSFT_PATH\n",
      "### Response:\n",
      "\n",
      "===/LLModel.prompt_model -- prompt/===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT:   Given a TEXT, I want you generate task steps and plan type of installation.    The format must in a strict JSON format : {[{\"plan_type\": \"detect the method of installation\", \"task_steps\": [a ordered list of steps to install], \"commands\": [ a concise list of commands for the tool.      If you do not find software installation steps in the TEXT, return \"none\".    Annotate the following TEXT: # Installation ### Dependencies Initialize git submodules with `` git submodule init git submodule update```     Install the specific versions of every package from `requirements.txt` in a new conda environment:    conda create --name gsft python=3.9     conda activate gsft    pip install -r requirements.txt    To ensure that Python paths are properly defined, update the `~/.bashrc` by adding the following lines    export GSFT_PATH=/path_to_gsfc    export PYTHONPATH=$PYTHONPATH:/$GSFT_PATH\n",
      "Response  {[{\"plan_type\": \"software installation\", \"task_steps\": [\n",
      "\"Determine the specific version of Python to install from `requirements.txt`\",\n",
      "\"Download and install the specified Python package using pip\",\n",
      "\"Install any necessary packages such as NumPy, Pandas or Matplotlib\",\n",
      "\"Create a conda environment named 'gsft' with Python 3.9\",\n",
      "\"Activate the conda environment\",\n",
      "\"Update the `~/.bashrc` to define Python paths properly by adding lines such as `export GSFT_PATH=/path_to_gsfc` and `export PYTHONPATH=$PYTHONPATH:/$GSFT_PATH`\"]]} \n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from gpt4all import GPT4All\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "model = GPT4All(\"orca-mini-3b-gguf2-q4_0.gguf\")\n",
    "with model.chat_session('You are an expert label.\\nBe terse.',\n",
    "                        '### Instruction:\\n{0}\\n### Response:\\n'):\n",
    "    prompt = ' Given a TEXT, I want you generate task steps and plan type of installation.\\\n",
    "    The format must in a strict JSON format : {[{\"plan_type\": \"detect the method of installation\", \"task_steps\": [a ordered list of steps to install], \"commands\": [ a concise list of commands for the tool.  \\\n",
    "    If you do not find software installation steps in the TEXT, return \"none\".\\\n",
    "    Annotate the following TEXT: # Installation ### Dependencies Initialize git submodules with `` git submodule init git submodule update``` \\\n",
    "    Install the specific versions of every package from `requirements.txt` in a new conda environment:\\\n",
    "    conda create --name gsft python=3.9 \\\n",
    "    conda activate gsft\\\n",
    "    pip install -r requirements.txt\\\n",
    "    To ensure that Python paths are properly defined, update the `~/.bashrc` by adding the following lines\\\n",
    "    export GSFT_PATH=/path_to_gsfc\\\n",
    "    export PYTHONPATH=$PYTHONPATH:/$GSFT_PATH'\n",
    "    print(\"PROMPT: \", prompt)\n",
    "    response = model.generate(prompt=prompt, temp=0.6)\n",
    "    print(\"Response\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT:  Behave as an expert labeler. \\ Given a URL, I want you generate task steps and plan type of installation.    The format must in a strict JSON format : {\"task_steps\": [ step description of one or more steps ], \"plan_nodes\": [{\"plan_type\": \"detect the method of installation\", \"commands\": [ a concise list of commands for the tool.     URL: https://raw.githubusercontent.com/PFischbeck/parameter-fitting-experiments/main/Readme.md\n",
      "Response  {\n",
      "\"task_steps\": [\n",
      " {\"step\": \"Detect the method of installation\",\n",
      " \"commands\": [\"sudo apt-get update && sudo apt-get install pf-script\"]\n",
      "}\n",
      "],\n",
      "\"plan_nodes\": [\n",
      " {\"plan_type\": \"Installation Plan\",\n",
      " \"instructions\": [\n",
      " \"1. Download the latest version of the package manager for your operating system from the official website.\",\n",
      " \"2. Open the terminal and run the command `sudo apt-get update` to check if there are any updates available.\",\n",
      " \"3. Run the command `sudo apt-get install pf-script` to download and install the package manager.\"\n",
      " ]}\n",
      "]\n",
      "}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gpt4all._pyllmodel:LLModel.prompt_model -- prompt:\n",
      "### System:\n",
      "You are an AI assistant that follows instruction extremely well. Help as much as you can.\n",
      "\n",
      "### User:\n",
      "Behave as an expert labeler. \\ Given a URL, I want you generate task steps and plan type of installation.    The format must in a strict JSON format : {\"task_steps\": [ step description of one or more steps ], \"plan_nodes\": [{\"plan_type\": \"detect the method of installation\", \"commands\": [ a concise list of commands for the tool.     URL: https://raw.githubusercontent.com/PFischbeck/parameter-fitting-experiments/main/Readme.md\n",
      "### Response:\n",
      "\n",
      "===/LLModel.prompt_model -- prompt/===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response  {\n",
      "\"task_steps\": [\n",
      " {\"step\": \"Detect the method of installation\",\n",
      " \"commands\": [\"sudo apt-get update && sudo apt-get install pf-script\"]\n",
      "}\n",
      "],\n",
      "\"plan_nodes\": [\n",
      " {\"plan_type\": \"Installation Plan\",\n",
      " \"instructions\": [\n",
      " \"1. Download the latest version of the package manager for your operating system from the official website.\",\n",
      " \"2. Open the terminal and run the command `sudo apt-get update` to check if there are any updates available.\",\n",
      " \"3. Run the command `sudo apt-get install pf-script` to download and install the package manager.\"\n",
      " ]}\n",
      "]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from gpt4all import GPT4All\n",
    "model = GPT4All(\"orca-mini-3b-gguf2-q4_0.gguf\")\n",
    "with model.chat_session():\n",
    "    prompt = 'Behave as an expert labeler. \\ Given a URL, I want you generate task steps and plan type of installation.\\\n",
    "    The format must in a strict JSON format : {\"task_steps\": [ step description of one or more steps ], \"plan_nodes\": [{\"plan_type\": \"detect the method of installation\", \"commands\": [ a concise list of commands for the tool. \\\n",
    "    URL: https://raw.githubusercontent.com/PFischbeck/parameter-fitting-experiments/main/Readme.md'\n",
    "    # print(\"PROMPT: \", prompt)\n",
    "    response = model.generate(prompt=prompt, temp=0)\n",
    "    print(\"Response\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. - TYPE OF PLANS PROMPTS\n",
    "\n",
    "#### Baseline-  Zero Shot\n",
    "```py\n",
    "prompt = \"\"\" Classify the text into LABELS [source, binary, container, and package manager]\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_response_from_gemma' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/PFischbeck/parameter-fission-examples/main/Readme.md\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgive me the type of plans\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# replace with your query\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mget_response_from_gemma\u001b[49m(question, url)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(json\u001b[38;5;241m.\u001b[39mdumps(response, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_response_from_gemma' is not defined"
     ]
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/PFischbeck/parameter-fission-examples/main/Readme.md\"\n",
    "question = \"give me the type of plans\"  # replace with your query\n",
    "response = get_response_from_gemma(question, url)\n",
    "print(json.dumps(response, indent=2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
