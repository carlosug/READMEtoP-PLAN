{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## - LIST OF STEPS PROMPT\n",
    "\n",
    "#### Baseline Zero Shot\n",
    "```py\n",
    "prompt = \"\"\" Provide a detailed list of the Steps in the given Research Software which refers to \"[software-name]\" plan, including the total count of all the Step? \"\"\"\n",
    "```\n",
    "\n",
    "#### One Shot Learning:\n",
    "\n",
    "The prompt additionally contains an example instance of a research software installation plan (consisting of a description of the initial step and the end) and the corresponding plan (which ends with a tag, referred to as the plan-end tag, that denotes the end of the plan). The prompt is formatted in natural language (or **JSON/RDF format**?)\n",
    "\n",
    "**JSON**\n",
    "\n",
    "```py\n",
    "prompt = \"\"\"\\nGiven a TEXT, I want you generate task steps and plan type of installation.\\\n",
    "    The format must in a strict JSON format : {[{\"plan_type\": \"detect the method of installation\", \"task_steps\": [a ordered list of steps to install], \"commands\": [ a concise list of commands for the tool.  \\\n",
    "    If you do not find software installation steps in the TEXT, return \"none\".\\\n",
    "    Annotate the following TEXT  \"\"\"\n",
    "        prompt += \"\"\"\\n\\n# REQUIREMENTS #: \\n1. the generated task steps and plan types allign with # RESEARCH SOFTWARE TOOL # perfectly. Task name must be detected from the README file; \\n2. the task steps should strictly aligned with the plan type, and the number of task steps should be same with the readmes;  \\n4.  RESEARCH SOFTWARE TOOL command should be align with the input-type field of # TASK LIST #;\"\"\"\n",
    "```\n",
    "\n",
    "**ONTOLOGY**\n",
    "\n",
    "```py\n",
    "\n",
    "prompt = \"\"\" Here is the complete definition of the procedural RDF ontology in TTL format which defines Plans and Steps and relationships between each other:\n",
    "\n",
    "@prefix p-plan: <http://purl.org/net/p-plan#> .\n",
    "@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\n",
    "@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
    "@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n",
    "@prefix prov: <http://www.w3.org/ns/prov#> .\n",
    "@prefix bpmn: <http://www.w3.org/ns/bpmn#> .\n",
    "\n",
    "[.....]\n",
    "\n",
    "\n",
    "Using the provided ontology, please create specific instances and data about plans representing the steps and  for the [-] software installation procedure. Include relationships such as 'isStepOfPlan' to model the hierarchy of main steps and their substeps. Additionally, create the RDF graph that represents the defined individuals and their relationships.  Refer to the RDF graph as Context, please provide an Answer to the Question below.\"\"\"\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gpt4all openai -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example for validation ground_true**\n",
    "\n",
    "```json\n",
    "            {\n",
    "                \"id\": \"6\",\n",
    "                \"name\": \"PFischbeck/parameter-fitting-experiments\",\n",
    "                \"url\": \"https://raw.githubusercontent.com/PFischbeck/parameter-fitting-experiments/main/Readme.md\",\n",
    "                \"n_plans\": 2,\n",
    "                \"plan_nodes\": [\n",
    "                    {\n",
    "                        \"type\": \"Source\",\n",
    "                        \"plan_step\": [\n",
    "                            \"Step 1: Make sure you have Python, Pip and R installed.\",\n",
    "                            \"Step 2: Checkout this repository.\",\n",
    "                            \"Step 3: Install the python dependencies with.\",\n",
    "                            \"Step 4: Install the pygirgs package at https://github.com/PFischbeck/pygirgs.\",\n",
    "                            \"Step 5: Install the R dependencies (used for plots) with\",\n",
    "                            \"Step 6: Download the file at https://doi.org/10.5281/zenodo.10629451 and extract the content\",\n",
    "                            \"Step optional: Download the file output-data.zip from Zenodo and extract its contents into the folder output_data. This way, you can access all experiment results without running them yourself.\"\n",
    "                        ],\n",
    "                        \"operating_system\": []\n",
    "                    }\n",
    "                ],\n",
    "                \"readme_instructions\": \"\",\n",
    "                \"skip_content\": \"\"\n",
    "            },\n",
    "``````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai\n",
    "import config\n",
    "api_key = config.API_KEY\n",
    "\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. - TYPE OF PLANS PROMPT\n",
    "\n",
    "#### Baseline Zero Shot\n",
    "```py\n",
    "prompt_TEXT = \"\"\" Given a INSTALL_TEXT, detect the class of plan for the installation of a software.\"\"\"\n",
    "prompt_URL =  \"\"\" Given a INSTALL_TEXT, detect the class of plan for the installation of a software.\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**GEMMA: Gemini-based open model**\n",
    "\n",
    "ref:\n",
    "[https://storage.googleapis.com/deepmind-media/gemma/gemma-report.pdf](https://storage.googleapis.com/deepmind-media/gemma/gemma-report.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a URL (no labels), Natural language response\n",
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "    base_url=\"https://api-inference.huggingface.co/v1\",\n",
    "    api_key= api_key # your key hf\n",
    ")\n",
    "MODEL = \"google/gemma-7b-it\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code_completion(messages, max_tokens=512, model=MODEL):\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=messages,\n",
    "        model=model,\n",
    "        max_tokens=max_tokens,\n",
    "        # stop=[\n",
    "        #     \"<step>\"\n",
    "        # ],\n",
    "        # frequency_penalty=1,\n",
    "        # presence_penalty=1,\n",
    "        # top_p=0.7,\n",
    "        # n=10,\n",
    "        # temperature=1,\n",
    "    )\n",
    "\n",
    "    return chat_completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = config.API_KEY\n",
    "SYSTEM_PROMPT = \"You are a smart and intelligent Named Entity Recognition (NER) system. I will provide you some task to identify entities in a text\"\n",
    "USER_PROMPT_1 = \"Detect the TYPE of plan for the installation of a software in the README_INSTALLATION.\"\n",
    "ASSISTANT_PROMPT_1 = \"Sure, I'm ready to help you with your NER task. Please provide me with the necessary information\"\n",
    "GUIDELINES_PROMPT = (\n",
    "    \"Entity Definition:\\n\"\n",
    "    \"1. README_INSTALLATION: a excerpt of the text found in a readme file of a research software tool\"\n",
    "    \"2. TYPE: represents the concept of a installation method type as a plan, which is composed of steps, which must be executed in a given order. A installation method is an instance of the Plan concept. There are four type of plans: binary, package manager, source and container. A research software readme installation instruction could refer to one or multiple methods\\n\"\n",
    "    \"3. PLAN_STEP: represents a list of planned action(s) as part of a Plan to be executed by an Agent. These are a list of indivisible sequence of actions that must executed without interruption. Step within a Plan could be linked to one specific executable operation, or refer to a group of operations. A Step then could invoke more than one action. Each sentence in a readme is an instance of the Step concept.\\n\"\n",
    "    \"4. TECHNOLOGY: repesents the concept of a particular operating sytem or package management correspoding to a particular set of PLAN_STEPs in a specific TYPE.\\n\"\n",
    "    \"5. N_PLANS: count the number of unique plan TYPE\"\n",
    "    \"\\n\"\n",
    "    \"Output Format:\\n\"\n",
    "    \"{{'TYPE': [name of the TYPE plans present], 'PLAN_STEP': [list of steps], 'TECHNOLOGY': [name of the technology used for that specific TYPE], 'N_PLANS': [number of unique plan TYPE]}}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text provided is describing a software installation process. Based on the text, the class of plan for the installation of the software in this particular README is **binary**.\n",
      "\n",
      "The text mentions \"TYPE: binary\" and \"binary\" is one of the four types of plans in the software installation process defined in the text.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "        {\"role\": \"user\", \"content\": \"Behave as an expert labeler. \\\n",
    "          Given a README, detect the class of plan for the installation of a software in the text of the. \\n Definition:\\n 1. README_INSTALLATION: a excerpt of the text found in a readme file of a research software tool \\n 2. TYPE: represents the concept of a installation method type as a plan, which is composed of steps, which must be executed in a given order. A installation method is an instance of the Plan concept. There are four type of plans: binary, package manager, source and container. A research software readme installation instruction could refer to one or multiple methods\\n 3. PLAN_STEP: represents a list of planned action(s) as part of a Plan to be executed by an Agent. These are a list of indivisible sequence of actions that must executed without interruption. Step within a Plan could be linked to one specific executable operation, or refer to a group of operations. A Step then could invoke more than one action. Each sentence in a readme is an instance of the Step concept.\\n 4. TECHNOLOGY: repesents the concept of a particular operating sytem or package management correspoding to a particular set of PLAN_STEPs in a specific TYPE.\\n 5. N_PLANS: count the number of unique plan TYPE \\n README = # Installation - Make sure you have Python, Pip and R installed. - Checkout this repository - Install the python dependencies with ```pip3 install -r requirements.txt``` - Install the `pygirgs` package at https://github.com/PFischbeck/pygirgs \\ - Install the R dependencies (used for plots) with  ```R -e install.packages(c(ggplot2, reshape2, plyr, dplyr, scales), repos=https://cloud.r-project.org/) Download the file `konect-data.zip` from [Zenodo](https://doi.org/10.5281/zenodo.10629451) and extract its contents into the folder `input_data/konect` Optional: Download the file `output-data.zip` from [Zenodo](https://doi.org/10.5281/zenodo.10629451) and extract its contents into the folder `output_data`. This way, you can access all experiment results without running them yourself. The Output Format in JSON file:\\n {{'TYPE': [name of the TYPE plans present], 'PLAN_STEP': [list of steps], 'TECHNOLOGY': [name of the technology used for that specific TYPE], 'N_PLANS': [number of unique plan TYPE]}} \\\n",
    "         \"},\n",
    "]\n",
    "\n",
    "chat_completion = get_code_completion(messages)\n",
    "            \n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Mistral orca-2 Model**\n",
    "\n",
    "ref: [mistral-7b-openorca.gguf2.Q4_0.gguf](mistral-7b-openorca.gguf2.Q4_0.gguf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One Shot Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chain of Thought Prompting**\n",
    "\n",
    "\n",
    "In addition to the four experiments above, we look at a fifth experiment using a state tracking chain of thought prompting technique in a natural language one shot setting. Within this configuration, we provide an annotated example where each action is annotated with the state prior to the action, the reason for why the action is applicable in the prior state, and the resulting state after applying the action. After the example, a meta-explanation about plan correctness is provided. The LLM is then asked to return a response making the same state tracking and justification annotations that were included in the example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**GEMMA: Gemini-based open model**\n",
    "\n",
    "ref:\n",
    "[https://storage.googleapis.com/deepmind-media/gemma/gemma-report.pdf](https://storage.googleapis.com/deepmind-media/gemma/gemma-report.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- Baseline Zero Shot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Number of Steps:** 4\n",
      "\n",
      "**Plan of Installation for Parameter Fitting Experiments**\n",
      "\n",
      "**URL:** raw.githubusercontent.com/PFischbeck/parameter-fitting-experiments/main/Readme.md\n",
      "\n",
      "**1. Obtain Python and Libraries:**\n",
      "\n",
      "- Ensure you have Python 3.6 or later installed.\n",
      "- Install the necessary Python libraries: pandas, numpy, sklearn, matplotlib, seaborn.\n",
      "\n",
      "**2. Set Up Virtual Environment (Optional):**\n",
      "\n",
      "- Create a virtual environment for the project (optional, but recommended).\n",
      "- Activate the virtual environment (if created).\n",
      "\n",
      "**3. Clone the Repository:**\n",
      "\n",
      "- Clone the parameter-fitting-experiments repository: `git clone git@github.com:PFischbeck/parameter-fitting-experiments.git`\n",
      "\n",
      "**4. Install Dependencies:**\n",
      "\n",
      "- Navigate to the `requirements.txt` file in the root directory.\n",
      "- Install the dependencies listed in the file: `pip install -r requirements.txt`\n"
     ]
    }
   ],
   "source": [
    "# Given a URL, Natural language response\n",
    "messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Behave as an expert labeler. \\\n",
    "          Given a URL, I want you generate a list of steps for the plan of installation. Please indicate the number of the steps. URL = https://raw.githubusercontent.com/PFischbeck/parameter-fitting-experiments/main/Readme.md\"},        \n",
    "    ]\n",
    "    # stream=True,\n",
    "    # max_tokens=500\n",
    "\n",
    "chat_completion = get_code_completion(messages)\n",
    "            \n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"PLAN_STEP\": [\"Step 1: Ensure Python, Pip and R are installed.\", \"Step 2: Checkout this repository.\", \"Step 3: Install Python dependencies (e.g. `pip3 install -r requirements.txt`)\", \"Step 4: Install the `pygirgs` package.\", \"Step 5: Install R dependencies (used for plots) with  ```R -e install.packages(c(ggplot2, reshape2, plyr, dplyr, scales), repos=https://cloud.r-project.org/)`, \"Step 6: Download and extract `konect-data.zip` into `input_data/konect` folder.\", \"Optional: Download and extract `output-data.zip` into `output_data` folder.],\n",
      "  \"NUM_STEP\": 7\n",
      "}\n",
      "```\n",
      "\n",
      "**Number of steps:** 7\n",
      "\n",
      "**Explanation:**\n",
      "\n",
      "The README_TEXT describes an installation plan with a total of 7 steps. Each step is clearly defined and described. The steps include ensuring required software dependencies are installed, checking out the repository, installing Python and R dependencies, downloading and extracting data files, and optional steps for downloading additional data.<eos>"
     ]
    }
   ],
   "source": [
    "# given a URL, JSON object response\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"google/gemma-7b-it\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Behave as an expert labeler. \\\n",
    "          Given a README_TEXT, \\\n",
    "          I want you generate a list of steps for the plan of installation. \\\n",
    "          Please indicate the number of the steps. The RESPONSE Format for your response should be in JSON file as following: \\\n",
    "         \\n {{'PLAN_STEP': [`Step 1`: give a number of the step. Each step separated with commas], {{`NUM_STEP`: [count of unique steps]}}}} \\n \\\n",
    "         Definition:\\n 1. README_INSTALLATION: a excerpt of the text found in a readme file of a research software tool \\n 2.PLAN_STEP: represents a list of planned action(s) in sequential orden as part of a installation plan. These are a list of indivisible sequence of actions that must executed without interruption. Step within a Plan could be linked to one specific executable operation, or refer to a group of operations. A Step then could invoke more than one action. \\n \\\n",
    "         Here is the README_TEXT = # Installation - Make sure you have Python, Pip and R installed. - Checkout this repository - Install the python dependencies with ```pip3 install -r requirements.txt``` - Install the `pygirgs` package at https://github.com/PFischbeck/pygirgs \\ - Install the R dependencies (used for plots) with  ```R -e install.packages(c(ggplot2, reshape2, plyr, dplyr, scales), repos=https://cloud.r-project.org/) Download the file `konect-data.zip` from [Zenodo](https://doi.org/10.5281/zenodo.10629451) and extract its contents into the folder `input_data/konect` Optional: Download the file `output-data.zip` from [Zenodo](https://doi.org/10.5281/zenodo.10629451) and extract its contents into the folder `output_data`. This way, you can access all experiment results without running them yourself.\"},\n",
    "    ],\n",
    "    stream=True,\n",
    "    max_tokens=500,\n",
    "    response_format={\"type\": \"json_object\"},\n",
    ")\n",
    "\n",
    "for message in chat_completion:\n",
    "    print(message.choices[0].delta.content, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # given a URL, JSON object response\n",
    "# from openai import OpenAI\n",
    "# client = OpenAI(\n",
    "#     base_url=\"https://api-inference.huggingface.co/v1\",\n",
    "#     api_key= api_key\n",
    "\n",
    "example_json = {\n",
    "  \"plan_nodes\": [\n",
    "                    {\n",
    "                        \"num_steps\": \"# total count number of unique steps\",\n",
    "                        \"plan_step\": [\n",
    "                            \"`# Step 1:` a string to represent the concept of a step in a method or plan. Each atomic activity is an instance of the Step. This step indicates the initial step in a plan\",\n",
    "                            \"# `Step 2:` a string to represent the concept of a step in a procedure or plan. It associates a step with the next step that must be performed\",\n",
    "                            \"# `Step n:`a string to represent the concept of a step in a procedure or plan. It associates a plan with its last step. This indicates the final step in a plan.\"\n",
    "                        ]\n",
    "                    }\n",
    "                ]\n",
    "}\n",
    "\n",
    "\n",
    "prompt= \"Given a , I want you generate a valid JSON output with the list of steps for the plan of installation. \\\n",
    "README_TEXT = # Installation - Make sure you have Python, Pip and R installed. - Checkout this repository - Install the python dependencies with ```pip3 install -r requirements.txt``` - Install the `pygirgs` package at https://github.com/PFischbeck/pygirgs \\ - Install the R dependencies (used for plots) with  ```R -e install.packages(c(ggplot2, reshape2, plyr, dplyr, scales), repos=https://cloud.r-project.org/) Download the file `konect-data.zip` from [Zenodo](https://doi.org/10.5281/zenodo.10629451) and extract its contents into the folder `input_data/konect` Optional: Download the file `output-data.zip` from [Zenodo](https://doi.org/10.5281/zenodo.10629451) and extract its contents into the folder `output_data`. This way, you can access all experiment results without running them yourself.\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"google/gemma-7b-it\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Provide output in valid JSON. The data schema should be like this:\"+json.dumps(example_json)},\n",
    "        { \"role\": \"system\", \"content\": prompt}\n",
    "    ],\n",
    "    stream=True,\n",
    "    max_tokens=500,\n",
    "    response_format={\"type\": \"json_object\"},\n",
    ")\n",
    "# messages = []\n",
    "# for message in chat_completion:\n",
    "#     print(message.choices[0].delta.content, end=\"\")\n",
    "#     messages.append(message.choices[0].delta.content)\n",
    "\n",
    "with open('output.json', 'w') as f:\n",
    "    for chunk in response:\n",
    "        f.write(chunk.choices[0].delta.content)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai\n",
    "import config\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import urllib.request\n",
    "import base64\n",
    "\n",
    "def call_api(url):\n",
    "    time.sleep(1)\n",
    "    url = url.replace(' ', '+')\n",
    "    print(url)\n",
    "\n",
    "    req = urllib.request.Request(url) \n",
    "    with urllib.request.urlopen(req) as response:\n",
    "        call = response.read()\n",
    "\n",
    "    return call\n",
    "\n",
    "def get_prompt_header(mask):\n",
    "    '''\n",
    "    mask: [1/0 x 6], denotes whether each prompt component is used\n",
    "\n",
    "    output: prompt\n",
    "    '''\n",
    "    # url = 'https://api.github.com/repos/torvalds/linux/readme'\n",
    "    # call = call_api(url)\n",
    "    # readme = json.loads(call)['download_url']\n",
    "    # print(readme)\n",
    "    # decoded_readme = base64.b64decode(readme).decode('utf-8')\n",
    "    decoded_readme = \"# Installation - Make sure you have Python, Pip and R installed. - Checkout this repository - Install the python dependencies with ```pip3 install -r requirements.txt``` - Install the `pygirgs` package at https://github.com/PFischbeck/pygirgs \\ - Install the R dependencies (used for plots) with  ```R -e install.packages(c(ggplot2, reshape2, plyr, dplyr, scales), repos=https://cloud.r-project.org/) Download the file `konect-data.zip` from [Zenodo](https://doi.org/10.5281/zenodo.10629451) and extract its contents into the folder `input_data/konect` Optional: Download the file `output-data.zip` from [Zenodo](https://doi.org/10.5281/zenodo.10629451) and extract its contents into the folder `output_data`. This way, you can access all experiment results without running them yourself.\"\n",
    "    prompt = ''\n",
    "    prompt += 'Hello. Your task is to analyze a README file and answer a question about it.\\n'\n",
    "    prompt += f'Here is the README file for the Linux kernel: {decoded_readme}\\n\\n'\n",
    "\n",
    "    if mask[0]:\n",
    "        prompt += 'Question: How many steps do you see in the README for building the Linux kernel?\\n'\n",
    "        prompt += 'Answer: '\n",
    "\n",
    "    return prompt\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # rough number of characters in the prompt\n",
    "    mask = [1, 0, 0, 0, 0, 0]\n",
    "    prompt = get_prompt_header(mask)\n",
    "    openai.api_key = config.API_KEY\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"google/gemma-7b-it\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"Provide output in valid JSON. The data schema should be like this:\"+json.dumps(example_json)},\n",
    "            { \"role\": \"system\", \"content\": prompt}\n",
    "        ],\n",
    "        stream=True,\n",
    "        max_tokens=500,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "    with open('response2.json', 'w') as f:\n",
    "        for chunk in response:\n",
    "            json.dumps(chunk.choices[0].delta.content, indent=4)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['```json', '{', '\"plan_nodes\": [', '{', '\"num_steps\": \"# total count number of unique steps\",', '\"plan_step\": [', '\"# Step 1:\",', '\"a string to represent the concept of a step in a method or plan. Each atomic activity is an instance of the Step. This step indicates the initial step in a plan\",', '\"# `Step 2:`\",', '\"a string to represent the concept of a step in a procedure or plan. It associates a step with the next step that must be performed\",', '\"# `Step n:`\",', '\"a string to represent the concept of a step in a procedure or plan. It associates a plan with its last step. This indicates the final step in a plan\"', ']', '}', ']', '}', '```']\n",
      "{'plan_step': ['```json', '{', '\"plan_nodes\": [', '{', '\"num_steps\": \"# total count number of unique steps\",', '\"plan_step\": [', '\"# Step 1:\",', '\"a string to represent the concept of a step in a method or plan. Each atomic activity is an instance of the Step. This step indicates the initial step in a plan\",', '\"# `Step 2:`\",', '\"a string to represent the concept of a step in a procedure or plan. It associates a step with the next step that must be performed\",', '\"# `Step n:`\",', '\"a string to represent the concept of a step in a procedure or plan. It associates a plan with its last step. This indicates the final step in a plan\"', ']', '}', ']', '}', '```']}\n",
      "Generated JSON: {\n",
      "    \"plan_step\": [\n",
      "        \"```json\",\n",
      "        \"{\",\n",
      "        \"\\\"plan_nodes\\\": [\",\n",
      "        \"{\",\n",
      "        \"\\\"num_steps\\\": \\\"# total count number of unique steps\\\",\",\n",
      "        \"\\\"plan_step\\\": [\",\n",
      "        \"\\\"# Step 1:\\\",\",\n",
      "        \"\\\"a string to represent the concept of a step in a method or plan. Each atomic activity is an instance of the Step. This step indicates the initial step in a plan\\\",\",\n",
      "        \"\\\"# `Step 2:`\\\",\",\n",
      "        \"\\\"a string to represent the concept of a step in a procedure or plan. It associates a step with the next step that must be performed\\\",\",\n",
      "        \"\\\"# `Step n:`\\\",\",\n",
      "        \"\\\"a string to represent the concept of a step in a procedure or plan. It associates a plan with its last step. This indicates the final step in a plan\\\"\",\n",
      "        \"]\",\n",
      "        \"}\",\n",
      "        \"]\",\n",
      "        \"}\",\n",
      "        \"```\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "    base_url=\"https://api-inference.huggingface.co/v1\",\n",
    "    api_key= api_key\n",
    ")\n",
    "\n",
    "# example_json = {\n",
    "#   \"plan_nodes\": [\n",
    "#                     {\n",
    "#                         \"num_steps\": \"float, # count number of unique steps\",\n",
    "#                         \"plan_step\": []\n",
    "#                     }\n",
    "#                 ]\n",
    "# }\n",
    "\n",
    "README_TEXT = \"### **Installation** \\n 1.  Prepare for the running environment. You can use the docker image provided by [`OpenPCDet`](https://github.com/open-mmlab/OpenPCDet). Our experiments are based on the docker provided by Voxel-R-CNN and we use NVIDIA Tesla V100 to train our Aydiv. \\n 2. Prepare for the data. /n Convert Argoverse 2 (or) waymo open Dataset into kitti format [`converter`](https://github.com/sanjay-810/AYDIV_ICRA/tree/main/data_converter/convert) /n Please prepare dataset as [`OpenPCDet`](https://github.com/open-mmlab/OpenPCDet).  /n To generate depth_pseudo_rgbseguv_twise by yourself with depth_dense_twise as follows: /n 3. Setup.\"\n",
    "\n",
    "def create_json_response(plan_node):\n",
    "    return {\n",
    "      \"plan_nodes\": [\n",
    "          {\n",
    "              \"num_steps\": (plan_node[\"plan_step\"]),\n",
    "              \"plan_step\": plan_node[\"plan_step\"]\n",
    "          }\n",
    "      ]\n",
    "    }\n",
    "\n",
    "example_json = {\n",
    "  \"plan_nodes\": [\n",
    "                    {\n",
    "                        \"num_steps\": \"# total count number of unique steps\",\n",
    "                        \"plan_step\": [\n",
    "                            \"`# Step 1:` a string to represent the concept of a step in a method or plan. Each atomic activity is an instance of the Step. This step indicates the initial step in a plan\",\n",
    "                            \"# `Step 2:` a string to represent the concept of a step in a procedure or plan. It associates a step with the next step that must be performed\",\n",
    "                            \"# `Step n:`a string to represent the concept of a step in a procedure or plan. It associates a plan with its last step. This indicates the final step in a plan.\"\n",
    "                        ]\n",
    "                    }\n",
    "                ]\n",
    "}\n",
    "\n",
    "def extract_steps(text):\n",
    "    response = client.chat.completions.create(\n",
    "      model=\"google/gemma-7b-it\",\n",
    "      messages=[\n",
    "          {\"role\": \"user\", \"content\": \"Provide output in valid JSON. The data schema should be like this\"+json.dumps(example_json)},\n",
    "          {\"role\": \"system\", \"content\": \"Provide output in valid JSON. The data schema should be like this\"+json.dumps(example_json)}\n",
    "      ],\n",
    "    # stream=True,\n",
    "    max_tokens=500,\n",
    "    response_format={\"type\": \"json_object\"},  \n",
    "    )\n",
    "\n",
    "\n",
    "    steps = response.choices[0].message.content.strip().split('\\n')\n",
    "    plan_step = [step.strip() for step in steps if step.strip()]\n",
    "    print(plan_step)\n",
    "    return {\"plan_step\": plan_step}\n",
    "\n",
    "\n",
    "plan_node = extract_steps(README_TEXT)\n",
    "print(plan_node)\n",
    "# final_json = create_json_response(plan_node)\n",
    "\n",
    "print(\"Generated JSON:\", json.dumps(plan_node, indent=4))\n",
    "\n",
    "\n",
    "with open('outputfile.json', 'w') as outf:\n",
    "    json.dump(plan_node, outf, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## JSON object for installing research software from the text:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"total_steps\": 6,\n",
      "  \"steps\": [\n",
      "    \"Make sure you have Python, Pip and R installed.\",\n",
      "    \"Checkout this repository\",\n",
      "    \"Install the python dependencies with `pip3 install -r requirements.txt`\",\n",
      "    \"Install the `pygirgs` package at https://github.com/PFischbeck/pygirgs\",\n",
      "    \"Install the R dependencies (used for plots) with `R -e 'install.packages(c(ggplot2, reshape2, plyr, dplyr, scales), repos=https://cloud.r-project.org/)'\",\n",
      "    \"Download the file `konect-data.zip` from [Zenodo](https://doi.org/10.5281/zenodo.10629451) and extract its contents into the folder `input_data/konect`. This way, you can access all experiment results without running them yourself. The file `output-data.zip` can be optionally downloaded and extracted into the folder `output_data`.\"\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "**Total number of steps:** 6<eos>"
     ]
    }
   ],
   "source": [
    "# Given a INSTALL_TEXT, JSON object response\n",
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "    base_url=\"https://api-inference.huggingface.co/v1\",\n",
    "    api_key= api_key\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"google/gemma-7b-it\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Behave as an expert labeler. \\\n",
    "          Given a INSTALL_TEXT, generate an example json object describing the Steps of installation of the Research Software. Please indicate the total number of the Steps. \\\n",
    "         INSTALL_TEXT = # Installation - Make sure you have Python, Pip and R installed. - Checkout this repository - Install the python dependencies with \\\n",
    "         ```pip3 install -r requirements.txt``` \\\n",
    "         - Install the `pygirgs` package at https://github.com/PFischbeck/pygirgs \\\n",
    "         - Install the R dependencies (used for plots) with \\\n",
    "         ```R -e 'install.packages(c(ggplot2, reshape2, plyr, dplyr, scales), repos=https://cloud.r-project.org/)'``` \\\n",
    "         - Download the file `konect-data.zip` from [Zenodo](https://doi.org/10.5281/zenodo.10629451) and extract its contents into the folder `input_data/konect` \\\n",
    "         - Optional: Download the file `output-data.zip` from [Zenodo](https://doi.org/10.5281/zenodo.10629451) and extract its contents into the folder `output_data`. This way, you can access all experiment results without running them yourself.\"},        \n",
    "    ],\n",
    "    stream=True,\n",
    "    max_tokens=500,\n",
    "    response_format={\"type\": \"json_object\"},\n",
    ")\n",
    "\n",
    "for message in chat_completion:\n",
    "    print(message.choices[0].delta.content, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mistral orca-2 Model**\n",
    "\n",
    "ref: [mistral-7b-openorca.gguf2.Q4_0.gguf](mistral-7b-openorca.gguf2.Q4_0.gguf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gpt4all._pyllmodel:LLModel.prompt_model -- prompt:\n",
      "You are an expert label.\n",
      "Be terse.\n",
      "\n",
      "### Instruction:\n",
      " Given a TEXT, I want you generate task steps and plan type of installation.    The format must in a strict JSON format : {[{\"plan_type\": \"detect the method of installation\", \"task_steps\": [a ordered list of steps to install], \"commands\": [ a concise list of commands for the tool.      If you do not find software installation steps in the TEXT, return \"none\".    Annotate the following TEXT: # Installation ### Dependencies Initialize git submodules with `` git submodule init git submodule update```     Install the specific versions of every package from `requirements.txt` in a new conda environment:    conda create --name gsft python=3.9     conda activate gsft    pip install -r requirements.txt    To ensure that Python paths are properly defined, update the `~/.bashrc` by adding the following lines    export GSFT_PATH=/path_to_gsfc    export PYTHONPATH=$PYTHONPATH:/$GSFT_PATH\n",
      "### Response:\n",
      "\n",
      "===/LLModel.prompt_model -- prompt/===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT:   Given a TEXT, I want you generate task steps and plan type of installation.    The format must in a strict JSON format : {[{\"plan_type\": \"detect the method of installation\", \"task_steps\": [a ordered list of steps to install], \"commands\": [ a concise list of commands for the tool.      If you do not find software installation steps in the TEXT, return \"none\".    Annotate the following TEXT: # Installation ### Dependencies Initialize git submodules with `` git submodule init git submodule update```     Install the specific versions of every package from `requirements.txt` in a new conda environment:    conda create --name gsft python=3.9     conda activate gsft    pip install -r requirements.txt    To ensure that Python paths are properly defined, update the `~/.bashrc` by adding the following lines    export GSFT_PATH=/path_to_gsfc    export PYTHONPATH=$PYTHONPATH:/$GSFT_PATH\n",
      "Response  {[{\"plan_type\": \"software installation\", \"task_steps\": [\n",
      "\"Determine the specific version of Python to install from `requirements.txt`\",\n",
      "\"Download and install the specified Python package using pip\",\n",
      "\"Install any necessary packages such as NumPy, Pandas or Matplotlib\",\n",
      "\"Create a conda environment named 'gsft' with Python 3.9\",\n",
      "\"Activate the conda environment\",\n",
      "\"Update the `~/.bashrc` to define Python paths properly by adding lines such as `export GSFT_PATH=/path_to_gsfc` and `export PYTHONPATH=$PYTHONPATH:/$GSFT_PATH`\"]]} \n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from gpt4all import GPT4All\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "model = GPT4All(\"orca-mini-3b-gguf2-q4_0.gguf\")\n",
    "with model.chat_session('You are an expert label.\\nBe terse.',\n",
    "                        '### Instruction:\\n{0}\\n### Response:\\n'):\n",
    "    prompt = ' Given a TEXT, I want you generate task steps and plan type of installation.\\\n",
    "    The format must in a strict JSON format : {[{\"plan_type\": \"detect the method of installation\", \"task_steps\": [a ordered list of steps to install], \"commands\": [ a concise list of commands for the tool.  \\\n",
    "    If you do not find software installation steps in the TEXT, return \"none\".\\\n",
    "    Annotate the following TEXT: # Installation ### Dependencies Initialize git submodules with `` git submodule init git submodule update``` \\\n",
    "    Install the specific versions of every package from `requirements.txt` in a new conda environment:\\\n",
    "    conda create --name gsft python=3.9 \\\n",
    "    conda activate gsft\\\n",
    "    pip install -r requirements.txt\\\n",
    "    To ensure that Python paths are properly defined, update the `~/.bashrc` by adding the following lines\\\n",
    "    export GSFT_PATH=/path_to_gsfc\\\n",
    "    export PYTHONPATH=$PYTHONPATH:/$GSFT_PATH'\n",
    "    print(\"PROMPT: \", prompt)\n",
    "    response = model.generate(prompt=prompt, temp=0.6)\n",
    "    print(\"Response\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT:  Behave as an expert labeler. \\ Given a URL, I want you generate task steps and plan type of installation.    The format must in a strict JSON format : {\"task_steps\": [ step description of one or more steps ], \"plan_nodes\": [{\"plan_type\": \"detect the method of installation\", \"commands\": [ a concise list of commands for the tool.     URL: https://raw.githubusercontent.com/PFischbeck/parameter-fitting-experiments/main/Readme.md\n",
      "Response  {\n",
      "\"task_steps\": [\n",
      " {\"step\": \"Detect the method of installation\",\n",
      " \"commands\": [\"sudo apt-get update && sudo apt-get install pf-script\"]\n",
      "}\n",
      "],\n",
      "\"plan_nodes\": [\n",
      " {\"plan_type\": \"Installation Plan\",\n",
      " \"instructions\": [\n",
      " \"1. Download the latest version of the package manager for your operating system from the official website.\",\n",
      " \"2. Open the terminal and run the command `sudo apt-get update` to check if there are any updates available.\",\n",
      " \"3. Run the command `sudo apt-get install pf-script` to download and install the package manager.\"\n",
      " ]}\n",
      "]\n",
      "}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gpt4all._pyllmodel:LLModel.prompt_model -- prompt:\n",
      "### System:\n",
      "You are an AI assistant that follows instruction extremely well. Help as much as you can.\n",
      "\n",
      "### User:\n",
      "Behave as an expert labeler. \\ Given a URL, I want you generate task steps and plan type of installation.    The format must in a strict JSON format : {\"task_steps\": [ step description of one or more steps ], \"plan_nodes\": [{\"plan_type\": \"detect the method of installation\", \"commands\": [ a concise list of commands for the tool.     URL: https://raw.githubusercontent.com/PFischbeck/parameter-fitting-experiments/main/Readme.md\n",
      "### Response:\n",
      "\n",
      "===/LLModel.prompt_model -- prompt/===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response  {\n",
      "\"task_steps\": [\n",
      " {\"step\": \"Detect the method of installation\",\n",
      " \"commands\": [\"sudo apt-get update && sudo apt-get install pf-script\"]\n",
      "}\n",
      "],\n",
      "\"plan_nodes\": [\n",
      " {\"plan_type\": \"Installation Plan\",\n",
      " \"instructions\": [\n",
      " \"1. Download the latest version of the package manager for your operating system from the official website.\",\n",
      " \"2. Open the terminal and run the command `sudo apt-get update` to check if there are any updates available.\",\n",
      " \"3. Run the command `sudo apt-get install pf-script` to download and install the package manager.\"\n",
      " ]}\n",
      "]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from gpt4all import GPT4All\n",
    "model = GPT4All(\"orca-mini-3b-gguf2-q4_0.gguf\")\n",
    "with model.chat_session():\n",
    "    prompt = 'Behave as an expert labeler. \\ Given a URL, I want you generate task steps and plan type of installation.\\\n",
    "    The format must in a strict JSON format : {\"task_steps\": [ step description of one or more steps ], \"plan_nodes\": [{\"plan_type\": \"detect the method of installation\", \"commands\": [ a concise list of commands for the tool. \\\n",
    "    URL: https://raw.githubusercontent.com/PFischbeck/parameter-fitting-experiments/main/Readme.md'\n",
    "    # print(\"PROMPT: \", prompt)\n",
    "    response = model.generate(prompt=prompt, temp=0)\n",
    "    print(\"Response\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. - TYPE OF PLANS PROMPTS\n",
    "\n",
    "#### Baseline-  Zero Shot\n",
    "```py\n",
    "prompt = \"\"\" Classify the text into LABELS [source, binary, container, and package manager]\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_response_from_gemma' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/PFischbeck/parameter-fission-examples/main/Readme.md\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgive me the type of plans\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# replace with your query\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mget_response_from_gemma\u001b[49m(question, url)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(json\u001b[38;5;241m.\u001b[39mdumps(response, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_response_from_gemma' is not defined"
     ]
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/PFischbeck/parameter-fission-examples/main/Readme.md\"\n",
    "question = \"give me the type of plans\"  # replace with your query\n",
    "response = get_response_from_gemma(question, url)\n",
    "print(json.dumps(response, indent=2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
