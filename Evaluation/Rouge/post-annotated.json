{
    "1": {
        "Source": [
            "1.  To download and install SICStus Prolog (it is needed), follow the instructions at https://sicstus.sics.se/download4.html.",
            "2.  Then, you can download DALI and test it by running an example DALI MAS:",
            "1.  To download and install SICStus Prolog (it is needed), follow the instructions at https://sicstus.sics.se/download4.html.",
            "2.  Then, you can download DALI and test it by running an example DALI MAS:",
            "3.  Unzip the repository, go to the folder DALI/Examples/basic, and test if DALI works by duble clicking startmas.bat file (this will launch an example DALI MAS)."
        ]
    },
    "2": {
        "Source": [
            "Please refer to the `setup.py` file for installation instructions."
        ]
    },
    "3": {
        "Source": [
            "Step 1: Download the dataset folder from onedrive by [data.zip](https://portland-my.sharepoint.com/:u:/g/personal/liuhui3-c_my_cityu_edu_hk/EfApQlFP3PhFjUW4527STo0BALMdP16zs-HPMNgwQVFWsA?e=zoHlW2). Unzip this folder into the project  directory.",
            "Step 2: Place you OpenAI key into the file named api_key.txt. "
        ]
    },
    "4": {
        "Container": [
            "Clone this repository and its submodules.",
            "When starting a container, remember to mount the code, dataset, and output directories to proper locations in the container:",
            "(Inside Container) Go to the root directory of this repository and build STEAM-ICP"
        ]
    },
    "5": {
        "Source": [
            "- Make sure you have Python, Pip and R installed.",
            "- Checkout this repository",
            "- Install the python dependencies with",
            "- Install the `pygirgs` package at https://github.com/PFischbeck/pygirgs",
            "- Install the R dependencies (used for plots) with",
            "- Download the file `konect-data.zip` from [Zenodo](https://doi.org/10.5281/zenodo.10629451) and extract its contents into the folder `input_data/konect`",
            "- Optional: Download the file `output-data.zip` from [Zenodo](https://doi.org/10.5281/zenodo.10629451) and extract its contents into the folder `output_data`. This way, you can access all experiment results without running them yourself."
        ]
    },
    "6": {
        "Source": [
            "pip install -r requirements.txt"
        ]
    },
    "7": {
        "Source": [
            "### Dependencies \n Initialize git submodules with",
            "### Python environment \n Install the specific versions of every package from `requirements.txt` in a new conda environment:",
            "To ensure that Python paths are properly defined, update the `~/.bashrc` by adding the following lines"
        ]
    },
    "8": {
        "Source": [
            "The project can be installed by running the following command in your terminal:"
        ]
    },
    "9": {
        "Source": [
            "Download VIGA \n Download VIGA with Git from GitHub",
            "1. download taxdmp.zip [Index of /pub/taxonomy (nih.gov)](https://ftp.ncbi.nlm.nih.gov/pub/taxonomy/) and unzip taxdmp.zip and put it in ./db/",
            "2. download `prot.accession2taxid` file from https://ftp.ncbi.nlm.nih.gov/pub/taxonomy/accession2taxid/",
            "3. download `RefSeqVirusProtein` file from",
            "4. download `nr` file from",
            "5. Use Diamond v2.0.11.149 to create two separate databases as the indexing libraries in the current version are incompatible with each other.",
            "6. In order to set up a reference database for DIAMOND, the makedb command needs to be executed with the following command line:",
            "Installing Some Software Using Conda",
            "#### Manual Installation of MetaCompass",
            "Python Dependencies \n Base on python 3.6.8"
        ]
    },
    "10": {
        "Binary": [
            "Installation instructions for Linux (Ubuntu and Pop!_OS): download the Linux zip file and, from the command window, run a bash command for the install.sh file, in the corresponding installation folder.",
            "Installation instructions for Mac OS: download the Mac zip file and copy the NRN-EZ app to the Applications folder.",
            "Installation instructions for Windows: download the Win zip file and run the installation wizard."
        ]
    },
    "11": {
        "Source": [
            "1. Create a Python virtual environment with Conda:",
            "2. Install PyTorch `v2.1.0` with compatible cuda version, following instructions from [PyTorch Installation Page](https://pytorch.org/get-started/locally/). For example with cuda 11:",
            "3. Install the following Python dependencies to run the codes.",
            "4. Login to your huggingface account for downloading models"
        ]
    },
    "12": {
        "Source": [
            "Please first install the required packages by:",
            "Replace the placeholder with your key in `config.py`:"
        ]
    },
    "13": {
        "Container": [
            "First, install Docker on your machine. Then move to the original directory `learning_to_fly` and build the Docker image:",
            "If desired you can also build the container for building the firmware:",
            "After that you can run it using e.g.:",
            "Navigate to [https://0.0.0.0:8000](https://0.0.0.0:8000) with your browser, and you should see something like in the screenshot above (after starting the training).",
            "Navigate to [https://0.0.0.0:6006](https://0.0.0.0:6006) with your browser to investigate the Tensorboard logs."
        ],
        "Source": [
            "Clone this repository:",
            "Then instantiate the `RLtools` submodule:",
            "Then instantiate some dependencies of `RLtools` (for conveniences like checkpointing, Tensorboard logging, testing, etc.):",
            "#### Install dependencies on Ubuntu",
            "#### Install dependencies on macOS",
            "Going back to the main directory (`learning_to_fly`), we can now configure the build of the code:",
            "Finally, we can build the targets:",
            "After successfully building the targets, we can run the code (in the original directory `learning_to_fly`):",
            "If not already installed:",
            "Then from the original directory `learning_to_fly`:",
            "To run the training with the UI, we download the JavaScript dependencies in the form of the two files `three.module.js` and `OrbitControls.js`:",
            "After that we can execute the UI binary from the root folder:",
            "Now you should be able to navigate to [http://0.0.0.0:8000](http://0.0.0.0:8000) in your browser and start the training."
        ]
    },
    "14": {
        "Source": [
            "Install the requirements with:",
            "or set up TPU VM with:"
        ]
    },
    "15": {
        "Source": [
            "### \ud83d\udee0\ufe0f Step 1: Installation"
        ]
    },
    "16": {
        "Source": [
            "#### Clone Project",
            "#### Install"
        ]
    },
    "17": {
        "package manager": [
            " To install the current release, which includes support for [CUDA-enabled GPU cards](https://www.tensorflow.org/install/gpu) *(Ubuntu and Windows)*:",
            "A smaller CPU-only package is also available:",
            " Other devices (DirectX and MacOS-metal) are supported using [Device plugins](https://www.tensorflow.org/install/gpu_plugins#available_devices)."
        ],
        "Binary": [
            "*Nightly binaries are available for testing using the [tf-nightly](https://pypi.python.org/pypi/tf-nightly) and [tf-nightly-cpu](https://pypi.python.org/pypi/tf-nightly-cpu) packages on PyPi.*"
        ]
    },
    "18": {
        "package manager": [
            "First, create a virtual environment with the version of Python you're going to use and activate it.",
            "Then, you will need to install at least one of Flax, PyTorch, or TensorFlow.",
            "When one of those backends has been installed, \ud83e\udd17 Transformers can be installed using pip as follows:",
            "If you'd like to play with the examples or need the bleeding edge of the code and can't wait for a new release, you must [install the library from source](https://huggingface.co/docs/transformers/installation#installing-from-source).",
            "\ud83e\udd17 Transformers can be installed using conda as follows:",
            "Follow the installation pages of Flax, PyTorch or TensorFlow to see how to install them with conda."
        ]
    },
    "19": {
        "package manager": [
            "1. Install [PyTorch](https://pytorch.org/get-started/locally/) (>=1.10.0)",
            "2. Install [PyG](https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html#) (>=2.0.0)",
            "3. Install DIG: Dive into Graphs."
        ],
        "Source": [
            "If you want to try the latest features that have not been released yet, you can install dig from source."
        ]
    },
    "20": {
        "package manager": [
            "With pip:",
            "With conda:"
        ]
    },
    "21": {
        "Source": [
            "1. Copy the `CamGen_v2` folder into the Blender [add-on folder](https://docs.blender.org/manual/en/latest/advanced/blender_directory_layout.html#platform-dependent-paths) that is right for your operating system, e.g. for Blender 4.0 under Linux ~/.config/blender/4.0/scripts/addons/",
            "2. Open Blender and navigate to `Edit > Preferences > Add-ons`",
            "3. Find and activate `Generic: Camera_Generator_v2` the list of available Add-ons. **You will need to press *refresh* in the Add-ons panel if you do not see the Camera_Generator option.**",
            "4. [Optional] To enable experimental lens analysis operations and plotting of the results, additional packages have to be installed for Blender's bundled Python version."
        ]
    },
    "22": {
        "Source": [
            "First, download and set up the repo:",
            "if you only want to run pre-trained models locally on CPU, you can remove the `cudatoolkit` and `pytorch-cuda` requirements from the file."
        ]
    },
    "23": {
        "package manager": [
            "To install TorchCP, simply run",
            "To install from TestPyPI server, run"
        ]
    },
    "24": {
        "Source": [
            "1. Clone the repository:",
            "2. Create a new Conda environment and activate it:",
            "or install necessary package by:"
        ]
    },
    "25": {
        "Container": [
            "1.  Prepare for the running environment."
        ]
    },
    "26": {
        "Source": [
            "1. Clone the repo and navigate to BitDelta:",
            "2. Set up environment:"
        ]
    },
    "27": {
        "Source": [
            "First, install the requirement packages declared by `requirements.txt`. ",
            "Modify [settings/example.json](./settings/example.json) on your desired processing procedure.",
            "Copy raw data to input_path in `settings/example.json`. And make sure the output_path not exists, otherwise the output path will be overwritten.",
            "Then the processing pipeline will generate an `debug_report.json` into /path/to/report_path defined in `settings/example.json`.",
            "After running the processing pipeline, the cleaned data will be merged as a `.jsonl` file, while there is just one record in a line."
        ]
    },
    "28": {
        "Source": [
            "Check out and install this repository:"
        ]
    },
    "29": {
        "Source": [
            "### Create a virtual environment and activate it.",
            "### Dependencies"
        ]
    },
    "30": {
        "Source": [
            "## Installing dependence",
            "In the following steps, make sure you have activated the GDPO environment."
        ]
    },
    "31": {
        "package manager": [
            "To install ISL, simply use Julia's package manager.",
            "To reproduce the enviroment for compiling the repository:"
        ]
    },
    "32": {
        "Source": [
            "### Setup Venv \n The order of the following instructions is important! 1. Use Conda or Pip to create a venv for python 3.11, we are using conda for this example:",
            "2. Go to <a href=`https://pytorch.org/get-started/locally/`>https://pytorch.org/get-started/locally/</a> and install a correct pytorch version for your machine in your venv",
            "3. Confirm that your pytorch package is working! Try calling these commands:",
            "This should show your GPU and it's usage."
        ]
    },
    "33": {
        "Source": [
            "You can install the development version from GitHub with:"
        ]
    }
}